diff --git a/gslib/__init__.py b/gslib/__init__.py
index 10c8d9a..902d1a0 100644
--- a/gslib/__init__.py
+++ b/gslib/__init__.py
@@ -28,8 +28,8 @@ import pkgutil
 import sys
 import tempfile
 
-if not (2, 6) <= sys.version_info[:3] < (3,):
-  sys.exit('gsutil requires python 2.6 or 2.7.')
+if not (2, 7) <= sys.version_info[:3] < (3,):
+  sys.exit('gsutil requires python 2.7.')
 
 import gslib.exception  # pylint: disable=g-import-not-at-top
 
diff --git a/gslib/__main__.py b/gslib/__main__.py
index b7e1cd3..fb1f236 100644
--- a/gslib/__main__.py
+++ b/gslib/__main__.py
@@ -75,7 +75,6 @@ from gslib.util import GetBotoConfigFileList
 from gslib.util import GetCertsFile
 from gslib.util import GetCleanupFiles
 from gslib.util import GetGsutilClientIdAndSecret
-from gslib.util import GsutilStreamHandler
 from gslib.util import ProxyInfoFromEnvironmentVar
 from gslib.util import UTF8
 from gslib.sig_handling import GetCaughtSignals
@@ -188,7 +187,7 @@ def _ConfigureLogging(level=logging.INFO):
   log_format = '%(levelname)s %(asctime)s %(filename)s] %(message)s'
   date_format = '%m%d %H:%M:%S.%f'
   formatter = GsutilFormatter(fmt=log_format, datefmt=date_format)
-  handler = GsutilStreamHandler()
+  handler = logging.StreamHandler()
   handler.setFormatter(formatter)
   root_logger = logging.getLogger()
   root_logger.addHandler(handler)
@@ -234,8 +233,8 @@ def main():
   global debug
   global test_exception_traces
 
-  if not (2, 6) <= sys.version_info[:3] < (3,):
-    raise CommandException('gsutil requires python 2.6 or 2.7.')
+  if not (2, 7) <= sys.version_info[:3] < (3,):
+    raise CommandException('gsutil requires python 2.7.')
 
   # In gsutil 4.0 and beyond, we don't use the boto library for the JSON
   # API. However, we still store gsutil configuration data in the .boto
@@ -256,6 +255,7 @@ def main():
   trace_token = None
   perf_trace_token = None
   test_exception_traces = False
+  user_project = None
 
   # If user enters no commands just print the usage info.
   if len(sys.argv) == 1:
@@ -275,7 +275,7 @@ def main():
 
   try:
     try:
-      opts, args = getopt.getopt(sys.argv[1:], 'dDvo:h:mq',
+      opts, args = getopt.getopt(sys.argv[1:], 'dDvo:h:u:mq',
                                  ['debug', 'detailedDebug', 'version', 'option',
                                   'help', 'header', 'multithreaded', 'quiet',
                                   'testexceptiontraces', 'trace-token=',
@@ -306,6 +306,8 @@ def main():
         parallel_operations = True
       elif o in ('-q', '--quiet'):
         quiet = True
+      elif o == '-u':
+        user_project = a
       elif o in ('-v', '--version'):
         version = True
       elif o == '--perf-trace-token':
@@ -369,10 +371,6 @@ def main():
 
     _CheckAndWarnForProxyDifferences()
 
-    if not test_exception_traces:
-      # Disable warning for tests, as it interferes with test stderr parsing.
-      _CheckAndWarnForPython26()
-
     if os.environ.get('_ARGCOMPLETE', '0') == '1':
       return _PerformTabCompletion(command_runner)
 
@@ -380,21 +378,11 @@ def main():
         command_runner, command_name, args=args[1:], headers=headers,
         debug_level=debug, trace_token=trace_token,
         parallel_operations=parallel_operations,
-        perf_trace_token=perf_trace_token)
+        perf_trace_token=perf_trace_token, user_project=user_project)
   finally:
     _Cleanup()
 
 
-def _CheckAndWarnForPython26():
-  if (2, 6) == sys.version_info[:2]:
-    sys.stderr.write('\n'.join(textwrap.wrap(
-        'Warning: You are running Python 2.6, which stopped receiving '
-        'security patches as of October 2013. gsutil will stop supporting '
-        'Python 2.6 on September 1, 2016. Please update your Python '
-        'installation to 2.7 to ensure compatibility with future gsutil '
-        'versions.\n')))
-
-
 def _CheckAndWarnForProxyDifferences():
   # If there are both boto config and environment variable config present for
   # proxies, unset the environment variable and warn if it differs.
@@ -555,7 +543,8 @@ def _CheckAndHandleCredentialException(e, args):
 
 def _RunNamedCommandAndHandleExceptions(
     command_runner, command_name, args=None, headers=None, debug_level=0,
-    trace_token=None, parallel_operations=False, perf_trace_token=None):
+    trace_token=None, parallel_operations=False, perf_trace_token=None,
+    user_project=None):
   """Runs the command and handles common exceptions."""
   # pylint: disable=g-import-not-at-top
   from gslib.util import GetConfigFilePaths
@@ -574,7 +563,8 @@ def _RunNamedCommandAndHandleExceptions(
                                           debug_level, trace_token,
                                           parallel_operations,
                                           perf_trace_token=perf_trace_token,
-                                          collect_analytics=True)
+                                          collect_analytics=True,
+                                          user_project=user_project)
   except AttributeError as e:
     if str(e).find('secret_access_key') != -1:
       _OutputAndExit(
diff --git a/gslib/addlhelp/command_opts.py b/gslib/addlhelp/command_opts.py
index 1fd8c0c..82221f9 100644
--- a/gslib/addlhelp/command_opts.py
+++ b/gslib/addlhelp/command_opts.py
@@ -119,6 +119,11 @@ _DETAILED_HELP_TEXT = ("""
               etc. Errors are still reported. This option can be useful for
               running gsutil from a cron job that logs its output to a file, for
               which the only information desired in the log is failures.
+
+  -u          Allows you to specify a user project to be billed for the request.
+              For example:
+
+                gsutil -u "bill-this-project" cp ...
 """)
 
 
diff --git a/gslib/addlhelp/crc32c.py b/gslib/addlhelp/crc32c.py
index a9ea2dd..5485c4d 100644
--- a/gslib/addlhelp/crc32c.py
+++ b/gslib/addlhelp/crc32c.py
@@ -109,7 +109,7 @@ _DETAILED_HELP_TEXT = ("""
 
   https://pypi.python.org/pypi/crcmod/1.7
 
-  MSI installers are available for the 32-bit versions of Python 2.6 and 2.7.
+  MSI installers are available for the 32-bit versions of Python 2.7.
   Make sure to install to a 32-bit Python directory. If you're using 64-bit
   Python it won't work with 32-bit crcmod, and instead you'll need to install
   32-bit Python in order to use crcmod.
diff --git a/gslib/addlhelp/encoding.py b/gslib/addlhelp/encoding.py
index 866b5a3..654d60e 100644
--- a/gslib/addlhelp/encoding.py
+++ b/gslib/addlhelp/encoding.py
@@ -20,12 +20,12 @@ from gslib.help_provider import HelpProvider
 
 _DETAILED_HELP_TEXT = ("""
 <B>OVERVIEW</B>
-  To minimize the chance for `filename encoding interoperability problems
+  To reduce the chance for `filename encoding interoperability problems
   <https://en.wikipedia.org/wiki/Filename#Encoding_indication_interoperability>`_ 
-  gsutil requires use of the `UTF-8 <https://en.wikipedia.org/wiki/UTF-8>`_
-  character encoding when uploading and downloading files. Because UTF-8 is in
-  widespread (and growing) use, for most users nothing needs to be done to use
-  UTF-8. Users with files stored in other encodings (such as
+  gsutil uses `UTF-8 <https://en.wikipedia.org/wiki/UTF-8>`_ character encoding
+  when uploading and downloading files. Because UTF-8 is in widespread (and
+  growing) use, for most users nothing needs to be done to use UTF-8. Users with
+  files stored in other encodings (such as
   `Latin 1 <https://en.wikipedia.org/wiki/ISO/IEC_8859-1>`_) must convert those
   filenames to UTF-8 before attempting to upload the files. 
 
@@ -87,6 +87,25 @@ _DETAILED_HELP_TEXT = ("""
   using cygwin (on Windows) or Linux or MacOS - all of which support Unicode.
 
 
+<B>USING UNICODE FILENAMES ON MAC OS</B>
+  MacOS stores filenames in decomposed form (also known as
+  `NFD normalization <https://en.wikipedia.org/wiki/Unicode_equivalence>`_).
+  For example, if a filename contains an accented "e" character, that character
+  will be converted to an "e" followed by an accent before being saved to the
+  filesystem. As a consequence, it's possible to have different name strings
+  for files uploaded from an operating system that doesn't enforce decomposed
+  form (like Ubuntu) from one that does (like MacOS).
+
+  The following example shows how this behavior could lead to unexpected
+  results. Say you create a file with non-ASCII characters on Ubuntu. Ubuntu
+  stores that filename in its composed form. When you upload the file to the
+  cloud, it is stored as named. But if you use gsutil rysnc to bring the file to
+  a MacOS machine and edit the file, then when you use gsutil rsync to bring
+  this version back to the cloud, you end up with two different objects, instead
+  of overwriting the original. This is because MacOS converted the filename to
+  a decomposed form, and Cloud Storage sees this as a different object name.
+
+
 <B>CROSS-PLATFORM ENCODING PROBLEMS OF WHICH TO BE AWARE</B>
   Using UTF-8 for all object names and filenames will ensure that gsutil doesn't
   encounter character encoding errors while operating on the files.
@@ -96,7 +115,7 @@ _DETAILED_HELP_TEXT = ("""
 
   - Windows filenames are case-insensitive, while Google Cloud Storage, Linux,
     and MacOS are not. Thus, for example, if you have two filenames on Linux
-    differing only in case and upload both to Google Cloud Storage and then 
+    differing only in case and upload both to Google Cloud Storage and then
     subsequently download them to Windows, you will end up with just one file
     whose contents came from the last of these files to be written to the
     filesystem.
diff --git a/gslib/addlhelp/security.py b/gslib/addlhelp/security.py
index 4842fda..8f04db6 100644
--- a/gslib/addlhelp/security.py
+++ b/gslib/addlhelp/security.py
@@ -50,7 +50,7 @@ _DETAILED_HELP_TEXT = ("""
   the files it stores locally:
 
   - When the gsutil config (or gcloud init for Cloud SDK installs) command runs
-    it sets file protection mode 600 ("-rw-------") on the the .boto
+    it sets file protection mode 600 ("-rw-------") on the .boto
     configuration file it generates, so only the user (or superuser) can read
     it. This is important because these files contain security-sensitive
     information, including credentials and proxy configuration.
diff --git a/gslib/boto_translation.py b/gslib/boto_translation.py
index 1a11abf..b25f4a9 100644
--- a/gslib/boto_translation.py
+++ b/gslib/boto_translation.py
@@ -158,11 +158,15 @@ class BotoTranslation(CloudApi):
   This class does not support encryption and ignores encryption and decryption
   parameters. Behavior when encountering encrypted objects is undefined.
   TODO: Implement support.
+
+  This class does not support handling a Requester Pays user project for
+  billing, and any given user project will be ignored.
+  TODO: Support user_project.
   """
 
   def __init__(self, bucket_storage_uri_class, logger, status_queue,
                provider=None, credentials=None, debug=0, trace_token=None,
-               perf_trace_token=None):
+               perf_trace_token=None, user_project=None):
     """Performs necessary setup for interacting with the cloud storage provider.
 
     Args:
@@ -178,6 +182,7 @@ class BotoTranslation(CloudApi):
       trace_token: Unused in this subclass.
       perf_trace_token: Performance trace token to use when making API calls
           ('gs' provider only).
+      user_project: Unused in this subclass
     """
     super(BotoTranslation, self).__init__(
         bucket_storage_uri_class, logger, status_queue, provider=provider,
diff --git a/gslib/cloud_api.py b/gslib/cloud_api.py
index b42a128..e6983b7 100644
--- a/gslib/cloud_api.py
+++ b/gslib/cloud_api.py
@@ -28,7 +28,7 @@ class CloudApi(object):
 
   def __init__(self, bucket_storage_uri_class, logger, status_queue,
                provider=None, debug=0, trace_token=None,
-               perf_trace_token=None):
+               perf_trace_token=None, user_project=None):
     """Performs necessary setup for interacting with the cloud storage provider.
 
     Args:
@@ -42,6 +42,7 @@ class CloudApi(object):
       trace_token: Google internal trace token to pass to the API
                    implementation (string).
       perf_trace_token: Performance trace token to use when making API calls.
+      user_project: Project to be billed for this request.
     """
     self.bucket_storage_uri_class = bucket_storage_uri_class
     self.logger = logger
@@ -50,6 +51,7 @@ class CloudApi(object):
     self.debug = debug
     self.trace_token = trace_token
     self.perf_trace_token = perf_trace_token
+    self.user_project = user_project
 
   def GetBucket(self, bucket_name, provider=None, fields=None):
     """Gets Bucket metadata.
diff --git a/gslib/cloud_api_delegator.py b/gslib/cloud_api_delegator.py
index 377f5fc..1d3fc99 100644
--- a/gslib/cloud_api_delegator.py
+++ b/gslib/cloud_api_delegator.py
@@ -43,7 +43,7 @@ class CloudApiDelegator(CloudApi):
 
   def __init__(self, bucket_storage_uri_class, gsutil_api_map, logger,
                status_queue, provider=None, debug=0, trace_token=None,
-               perf_trace_token=None):
+               perf_trace_token=None, user_project=None):
     """Performs necessary setup for delegating cloud storage requests.
 
     This function has different arguments than the gsutil Cloud API __init__
@@ -61,12 +61,14 @@ class CloudApiDelegator(CloudApi):
       debug: Debug level for the API implementation (0..3).
       trace_token: Apiary trace token to pass to API.
       perf_trace_token: Performance trace token to use when making API calls.
+      user_project: Project to be billed for this project.
     """
     super(CloudApiDelegator, self).__init__(bucket_storage_uri_class, logger,
                                             status_queue,
                                             provider=provider, debug=debug,
                                             trace_token=trace_token,
-                                            perf_trace_token=perf_trace_token)
+                                            perf_trace_token=perf_trace_token,
+                                            user_project=user_project)
     self.api_map = gsutil_api_map
     self.prefer_api = boto.config.get('GSUtil', 'prefer_api', '').upper()
     self.loaded_apis = {}
@@ -127,7 +129,8 @@ class CloudApiDelegator(CloudApi):
             provider=provider,
             debug=self.debug,
             trace_token=self.trace_token,
-            perf_trace_token=self.perf_trace_token))
+            perf_trace_token=self.perf_trace_token,
+            user_project=self.user_project))
 
   def GetApiSelector(self, provider=None):
     """Returns a cs_api_map.ApiSelector based on input and configuration.
diff --git a/gslib/cloud_api_helper.py b/gslib/cloud_api_helper.py
index 7c7935e..4e60bde 100644
--- a/gslib/cloud_api_helper.py
+++ b/gslib/cloud_api_helper.py
@@ -20,6 +20,7 @@ import json
 import re
 
 from gslib.cloud_api import ArgumentException
+from gslib.util import AddQueryParamToUrl
 
 
 def ValidateDstObjectMetadata(dst_obj_metadata):
@@ -42,30 +43,37 @@ def ValidateDstObjectMetadata(dst_obj_metadata):
         'Object metadata supplied for destination object had no bucket name.')
 
 
-def GetDownloadSerializationData(src_obj_metadata, progress=0):
+def GetDownloadSerializationData(
+    src_obj_metadata, progress=0, user_project=None):
   """Returns download serialization data.
 
-  There are four entries:
+  There are five entries:
     auto_transfer: JSON-specific field, always False.
     progress: How much of the download has already been completed.
     total_size: Total object size.
     url: Implementation-specific field used for saving a metadata get call.
          For JSON, this the download URL of the object.
          For XML, this is a pickled boto key.
+    user_project: Project to be billed to, added as query param.
 
   Args:
     src_obj_metadata: Object to be downloaded.
     progress: See above.
+    user_project: User project to add to query string.
 
   Returns:
     Serialization data for use with Cloud API GetObjectMedia.
   """
 
+  url = src_obj_metadata.mediaLink
+  if user_project:
+    url = AddQueryParamToUrl(url, 'userProject', user_project)
+
   serialization_dict = {
       'auto_transfer': 'False',
       'progress': progress,
       'total_size': src_obj_metadata.size,
-      'url': src_obj_metadata.mediaLink
+      'url': url
   }
 
   return json.dumps(serialization_dict)
diff --git a/gslib/command.py b/gslib/command.py
index 9750ca1..03894f9 100644
--- a/gslib/command.py
+++ b/gslib/command.py
@@ -83,7 +83,6 @@ from gslib.ui_controller import UIController
 from gslib.ui_controller import UIThread
 from gslib.util import CheckMultiprocessingAvailableAndInit
 from gslib.util import GetConfigFilePaths
-from gslib.util import GsutilStreamHandler
 from gslib.util import HaveFileUrls
 from gslib.util import HaveProviderUrls
 from gslib.util import IS_WINDOWS
@@ -115,7 +114,7 @@ def CreateGsutilLogger(command_name):
   log = logging.getLogger(command_name)
   log.propagate = False
   log.setLevel(logging.root.level)
-  log_handler = GsutilStreamHandler()
+  log_handler = logging.StreamHandler()
   log_handler.setFormatter(logging.Formatter('%(message)s'))
   # Commands that call other commands (like mv) would cause log handlers to be
   # added more than once, so avoid adding if one is already present.
@@ -519,7 +518,8 @@ class Command(HelpProvider):
   def __init__(self, command_runner, args, headers, debug, trace_token,
                parallel_operations, bucket_storage_uri_class,
                gsutil_api_class_map_factory, logging_filters=None,
-               command_alias_used=None, perf_trace_token=None):
+               command_alias_used=None, perf_trace_token=None,
+               user_project=None):
     """Instantiates a Command.
 
     Args:
@@ -540,6 +540,7 @@ class Command(HelpProvider):
                           which will always correspond to the file name).
       perf_trace_token: Performance measurement trace token to use when making
           API calls.
+      user_project: Project to be billed for this request.
 
     Implementation note: subclasses shouldn't need to define an __init__
     method, and instead depend on the shared initialization that happens
@@ -555,6 +556,7 @@ class Command(HelpProvider):
     self.trace_token = trace_token
     self.perf_trace_token = perf_trace_token
     self.parallel_operations = parallel_operations
+    self.user_project = user_project
     self.bucket_storage_uri_class = bucket_storage_uri_class
     self.gsutil_api_class_map_factory = gsutil_api_class_map_factory
     self.exclude_symlinks = False
@@ -617,7 +619,8 @@ class Command(HelpProvider):
         self.logger,
         MainThreadUIQueue(sys.stderr, ui_controller),
         debug=self.debug, trace_token=self.trace_token,
-        perf_trace_token=self.perf_trace_token)
+        perf_trace_token=self.perf_trace_token,
+        user_project=self.user_project)
     # Cross-platform path to run gsutil binary.
     self.gsutil_cmd = ''
     # If running on Windows, invoke python interpreter explicitly.
@@ -742,7 +745,8 @@ class Command(HelpProvider):
       self.seek_ahead_gsutil_api = CloudApiDelegator(
           self.bucket_storage_uri_class, self.gsutil_api_map,
           logging.getLogger('dummy'), glob_status_queue, debug=self.debug,
-          trace_token=self.trace_token, perf_trace_token=self.perf_trace_token)
+          trace_token=self.trace_token, perf_trace_token=self.perf_trace_token,
+          user_project=self.user_project)
     return self.seek_ahead_gsutil_api
 
   def RunCommand(self):
@@ -1402,7 +1406,7 @@ class Command(HelpProvider):
     # Create a WorkerThread to handle all of the logic needed to actually call
     # the function. Note that this thread will never be started, and all work
     # is done in the current thread.
-    worker_thread = WorkerThread(None, False)
+    worker_thread = WorkerThread(None, False, user_project=self.user_project)
     args_iterator = iter(args_iterator)
     # Count of sequential calls that have been made. Used for producing
     # suggestion to use gsutil -m.
@@ -1542,7 +1546,7 @@ class Command(HelpProvider):
             thread_count, self.logger, task_queue=task_queue,
             bucket_storage_uri_class=self.bucket_storage_uri_class,
             gsutil_api_map=self.gsutil_api_map, debug=self.debug,
-            status_queue=glob_status_queue)
+            status_queue=glob_status_queue, user_project=self.user_project)
 
     if process_count > 1:  # Handle process pool creation.
       # Check whether this call will need a new set of workers.
@@ -1583,7 +1587,7 @@ class Command(HelpProvider):
                 thread_count, self.logger, task_queue=task_queue,
                 bucket_storage_uri_class=self.bucket_storage_uri_class,
                 gsutil_api_map=self.gsutil_api_map, debug=self.debug,
-                status_queue=glob_status_queue)
+                status_queue=glob_status_queue, user_project=self.user_project)
         finally:
           worker_checking_level_lock.release()
 
@@ -1714,7 +1718,7 @@ class Command(HelpProvider):
         thread_count, self.logger, worker_semaphore=worker_semaphore,
         bucket_storage_uri_class=self.bucket_storage_uri_class,
         gsutil_api_map=self.gsutil_api_map, debug=self.debug,
-        status_queue=status_queue)
+        status_queue=status_queue, user_project=self.user_project)
 
     num_enqueued = 0
     while True:
@@ -1987,7 +1991,8 @@ class WorkerPool(object):
 
   def __init__(self, thread_count, logger, worker_semaphore=None,
                task_queue=None, bucket_storage_uri_class=None,
-               gsutil_api_map=None, debug=0, status_queue=None):
+               gsutil_api_map=None, debug=0, status_queue=None,
+               user_project=None):
     # In the multi-process case, a worker sempahore is required to ensure
     # even work distribution.
     #
@@ -1998,6 +2003,7 @@ class WorkerPool(object):
     #
     # Thus, exactly one of task_queue or worker_semaphore must be provided.
     assert (worker_semaphore is None) != (task_queue is None)
+    self.user_project = user_project
 
     self.task_queue = task_queue or _NewThreadsafeQueue()
     self.threads = []
@@ -2005,7 +2011,8 @@ class WorkerPool(object):
       worker_thread = WorkerThread(
           self.task_queue, logger, worker_semaphore=worker_semaphore,
           bucket_storage_uri_class=bucket_storage_uri_class,
-          gsutil_api_map=gsutil_api_map, debug=debug, status_queue=status_queue)
+          gsutil_api_map=gsutil_api_map, debug=debug, status_queue=status_queue,
+          user_project=self.user_project)
       self.threads.append(worker_thread)
       worker_thread.start()
 
@@ -2032,7 +2039,7 @@ class WorkerThread(threading.Thread):
 
   def __init__(self, task_queue, logger, worker_semaphore=None,
                bucket_storage_uri_class=None, gsutil_api_map=None, debug=0,
-               status_queue=None):
+               status_queue=None, user_project=None):
     """Initializes the worker thread.
 
     Args:
@@ -2048,6 +2055,7 @@ class WorkerThread(threading.Thread):
                       Used for the instantiating CloudApiDelegator class.
       debug: debug level for the CloudApiDelegator class.
       status_queue: Queue for reporting status updates.
+      user_project: Project to be billed for this request.
     """
     super(WorkerThread, self).__init__()
 
@@ -2058,6 +2066,7 @@ class WorkerThread(threading.Thread):
     self.daemon = True
     self.cached_classes = {}
     self.shared_vars_updater = _SharedVariablesUpdater()
+    self.user_project = user_project
 
     # Note that thread_gsutil_api is not initialized in the sequential
     # case; task functions should use util.GetCloudApiInstance to
@@ -2066,7 +2075,7 @@ class WorkerThread(threading.Thread):
     if bucket_storage_uri_class and gsutil_api_map:
       self.thread_gsutil_api = CloudApiDelegator(
           bucket_storage_uri_class, gsutil_api_map, logger, status_queue,
-          debug=debug)
+          debug=debug, user_project=self.user_project)
 
   @CaptureThreadStatException
   def _StartBlockedTime(self):
diff --git a/gslib/command_runner.py b/gslib/command_runner.py
index 06b91ba..a4ed0e6 100644
--- a/gslib/command_runner.py
+++ b/gslib/command_runner.py
@@ -221,6 +221,7 @@ class CommandRunner(object):
                       trace_token=None, parallel_operations=False,
                       skip_update_check=False, logging_filters=None,
                       do_shutdown=True, perf_trace_token=None,
+                      user_project=None,
                       collect_analytics=False):
     """Runs the named command.
 
@@ -239,6 +240,7 @@ class CommandRunner(object):
       do_shutdown: Stop all parallelism framework workers iff this is True.
       perf_trace_token: Performance measurement trace token to pass to the
           underlying API.
+      user_project: The project to bill this request to.
       collect_analytics: Set to True to collect an analytics metric logging this
           command.
 
@@ -303,7 +305,7 @@ class CommandRunner(object):
         self, args, headers, debug, trace_token, parallel_operations,
         self.bucket_storage_uri_class, self.gsutil_api_class_map_factory,
         logging_filters, command_alias_used=command_name,
-        perf_trace_token=perf_trace_token)
+        perf_trace_token=perf_trace_token, user_project=user_project)
 
     # Log the command name, command alias, and sub-options after being parsed by
     # RunCommand and the command constructor. For commands with subcommands and
diff --git a/gslib/commands/acl.py b/gslib/commands/acl.py
index 5998996..79abca7 100644
--- a/gslib/commands/acl.py
+++ b/gslib/commands/acl.py
@@ -221,6 +221,10 @@ _CH_DESCRIPTION = """
     W: WRITE
     O: OWNER
 
+  For more information on these roles and the access they grant, see the
+  permissions section of the `Access Control Lists page
+  <https://cloud.google.com/storage/docs/access-control/lists#permissions>`_.
+
 <B>CH ENTITIES</B>
   There are four different entity types: Users, Groups, All Authenticated Users,
   and All Users.
diff --git a/gslib/commands/config.py b/gslib/commands/config.py
index 56b6203..7cfa981 100644
--- a/gslib/commands/config.py
+++ b/gslib/commands/config.py
@@ -793,8 +793,12 @@ class ConfigCommand(Command):
         '# To use a proxy, edit and uncomment the proxy and proxy_port lines.\n'
         '# If you need a user/password with this proxy, edit and uncomment\n'
         '# those lines as well. If your organization also disallows DNS\n'
-        '# lookups by client machines set proxy_rdns = True\n'
-        '# If proxy_host and proxy_port are not specified in this file and\n'
+        '# lookups by client machines, set proxy_rdns to True (the default).\n'
+        '# If you have installed gsutil through the Cloud SDK and have \n'
+        '# configured proxy settings in gcloud, those proxy settings will \n'
+        '# override any other options (including those set here, along with \n'
+        '# any settings in proxy-related environment variables). Otherwise, \n'
+        '# if proxy_host and proxy_port are not specified in this file and\n'
         '# one of the OS environment variables http_proxy, https_proxy, or\n'
         '# HTTPS_PROXY is defined, gsutil will use the proxy server specified\n'
         '# in these environment variables, in order of precedence according\n'
diff --git a/gslib/commands/iam.py b/gslib/commands/iam.py
index 9da8d54..71e8b66 100644
--- a/gslib/commands/iam.py
+++ b/gslib/commands/iam.py
@@ -476,10 +476,6 @@ class IamCommand(Command):
           threaded_wildcards, self.recursion_requested,
           all_versions=self.all_versions)
 
-      # N.B.: Python2.6 support means we can't use a partial function here to
-      # curry the bindings tuples into the wrapper function. We instead pass
-      # the bindings along by zipping them with each name_expansion_iterator
-      # result. See http://bugs.python.org/issue5228.
       serialized_bindings_tuples_it = itertools.repeat(
           [SerializeBindingsTuple(t) for t in patch_bindings_tuples])
       self.Apply(
@@ -582,8 +578,6 @@ class IamCommand(Command):
           threaded_wildcards, self.recursion_requested,
           all_versions=self.all_versions)
 
-      # We cannot curry policy along due to a Python2.6 bug; see comments in
-      # IamCommand._PatchIam for more information.
       policy_it = itertools.repeat(protojson.encode_message(policy))
       self.Apply(
           _SetIamWrapper,
diff --git a/gslib/commands/ls.py b/gslib/commands/ls.py
index 5a69c2d..d2ed0ba 100644
--- a/gslib/commands/ls.py
+++ b/gslib/commands/ls.py
@@ -128,8 +128,8 @@ _DETAILED_HELP_TEXT = ("""
   will print the object size, creation time stamp, and name of each matching
   object, along with the total count and sum of sizes of all matching objects:
 
-       2276224  2012-03-02T19:25:17Z  gs://bucket/obj1
-       3914624  2012-03-02T19:30:27Z  gs://bucket/obj2
+       2276224  2017-03-02T19:25:17Z  gs://bucket/obj1
+       3914624  2017-03-02T19:30:27Z  gs://bucket/obj2
     TOTAL: 2 objects, 6190848 bytes (5.9 MiB)
 
   Note that the total listed in parentheses above is in mebibytes (or gibibytes,
@@ -149,30 +149,38 @@ _DETAILED_HELP_TEXT = ("""
   will print something like:
 
     gs://bucket/obj1:
-            Creation time:                    Fri, 21 Oct 2016 19:25:17 GMT
-            Update time:                      Fri, 21 Oct 2016 21:17:59 GMT
-            Storage class update time:        Fri, 21 Oct 2016 22:12:32 GMT
-            Size:                             2276224
-            Cache-Control:                    private, max-age=0
-            Content-Type:                     application/x-executable
-            ETag:                             5ca6796417570a586723b7344afffc81
+            Creation time:                    Fri, 26 May 2017 22:55:44 GMT
+            Update time:                      Tue, 18 Jul 2017 12:31:18 GMT
+            Storage class:                    MULTI_REGIONAL
+            Content-Length:                   60183
+            Content-Type:                     image/jpeg
+            Hash (crc32c):                    zlUhtg==
+            Hash (md5):                       Bv86IAzFzrD1Z2io/c7yqA==
+            ETag:                             5ca67960a586723b7344afffc81
             Generation:                       1378862725952000
             Metageneration:                   1
-            ACL:
-    [
+            ACL:                              [
       {
-        "entity": "group-00b4903a97163d99003117abe64d292561d2b4074fc90ce5c0e35ac45f66ad70",
-        "entityId": "00b4903a97163d99003117abe64d292561d2b4074fc90ce5c0e35ac45f66ad70",
+        "entity": "project-owners-867484910061",
+        "projectTeam": {
+          "projectNumber": "867484910061",
+          "team": "owners"
+        },
+        "role": "OWNER"
+      },
+      {
+        "email": "jane@gmail.com",
+        "entity": "user-jane@gmail.com",
         "role": "OWNER"
       }
     ]
-    TOTAL: 1 objects, 2276224 bytes (2.17 MiB)
+    TOTAL: 1 objects, 60183 bytes (58.77 KiB)
 
-  Note that some fields above (time updated, storage class update time) are
-  not available with the (non-default) XML API.
+  Note that results may contain additional fields, such as custom metadata or
+  a storage class update time, if they are applicable to the object.
 
-  Also note that the Storage class update time field does not display unless it
-  differs from Creation time.
+  Also note that some fields, such as update time, are not available with the
+  (non-default) XML API.
 
   See also "gsutil help acl" for getting a more readable version of the ACL.
 
@@ -188,28 +196,35 @@ _DETAILED_HELP_TEXT = ("""
     gs://bucket/ :
             Storage class:                MULTI_REGIONAL
             Location constraint:          US
-            Versioning enabled:           True
+            Versioning enabled:           False
             Logging configuration:        None
             Website configuration:        None
-            CORS configuration:           Present
+            CORS configuration:           None
             Lifecycle configuration:      None
+            Requester Pays enabled:       True
             Labels:                       None
-            Time created:                 Fri, 21 Oct 2016 19:25:17 GMT
-            Time updated:                 Fri, 21 Oct 2016 21:17:59 GMT
+            Time created:                 Thu, 14 Jan 2016 19:25:17 GMT
+            Time updated:                 Thu, 08 Jun 2017 21:17:59 GMT
             Metageneration:               1
             ACL:
     [
       {
-        "entity": "group-00b4903a97163d99003117abe64d292561d2b4074fc90ce5c0e35ac45f66ad70",
-        "entityId": "00b4903a97163d99003117abe64d292561d2b4074fc90ce5c0e35ac45f66ad70",
+        "entity": "project-owners-867489160491",
+        "projectTeam": {
+          "projectNumber": "867489160491",
+          "team": "owners"
+        },
         "role": "OWNER"
       }
     ]
             Default ACL:
     [
       {
-        "entity": "group-00b4903a97163d99003117abe64d292561d2b4074fc90ce5c0e35ac45f66ad70",
-        "entityId": "00b4903a97163d99003117abe64d292561d2b4074fc90ce5c0e35ac45f66ad70",
+        "entity": "project-owners-867489160491",
+        "projectTeam": {
+          "projectNumber": "867489160491",
+          "team": "owners"
+        },
         "role": "OWNER"
       }
     ]
@@ -314,6 +329,7 @@ class LsCommand(Command):
     fields['logging_config'] = 'Present' if bucket.logging else 'None'
     fields['cors_config'] = 'Present' if bucket.cors else 'None'
     fields['lifecycle_config'] = 'Present' if bucket.lifecycle else 'None'
+    fields['requester_pays'] = bucket.billing and bucket.billing.requesterPays
     if bucket.labels:
       fields['labels'] = LabelTranslation.JsonFromMessage(
           bucket.labels, pretty_print=True)
@@ -361,6 +377,7 @@ class LsCommand(Command):
            '\tWebsite configuration:\t\t{website_config}\n'
            '\tCORS configuration: \t\t{cors_config}\n'
            '\tLifecycle configuration:\t{lifecycle_config}\n'
+           '\tRequester Pays enabled:\t\t{requester_pays}\n'
            '\tLabels:\t\t\t\t{labels}\n' +
            time_created_line +
            time_updated_line +
@@ -467,6 +484,7 @@ class LsCommand(Command):
         bucket_fields = ['id']
       elif listing_style == ListingStyle.LONG_LONG:
         bucket_fields = ['acl',
+                         'billing',
                          'cors',
                          'defaultObjectAcl',
                          'labels',
diff --git a/gslib/commands/mv.py b/gslib/commands/mv.py
index 743a804..318d024 100644
--- a/gslib/commands/mv.py
+++ b/gslib/commands/mv.py
@@ -155,7 +155,7 @@ class MvCommand(Command):
     unparsed_args.extend(self.unparsed_args)
     self.command_runner.RunNamedCommand(
         'cp', args=unparsed_args, headers=self.headers, debug=self.debug,
-        trace_token=self.trace_token,
+        trace_token=self.trace_token, user_project=self.user_project,
         parallel_operations=self.parallel_operations)
 
     return 0
diff --git a/gslib/commands/notification.py b/gslib/commands/notification.py
index b51b9ec..c3eca6b 100644
--- a/gslib/commands/notification.py
+++ b/gslib/commands/notification.py
@@ -23,6 +23,7 @@ import time
 import uuid
 
 from gslib import metrics
+from gslib import copy_helper
 from gslib.cloud_api import AccessDeniedException
 from gslib.cloud_api import NotFoundException
 from gslib.cloud_api import PublishPermissionDeniedException
@@ -299,9 +300,12 @@ _DESCRIPTION = """
   will then see a notification for each of these components being created and
   deleted. If this is a concern for you, note that parallel composite uploads
   can be disabled by setting "parallel_composite_upload_threshold = 0" in your
-  boto config file.
+  boto config file. Alternately, your subscriber code can filter out gsutil's
+  parallel composite uploads by ignoring any notification about objects whose
+  names contain (but do not start with) the following string:
+    "{composite_namespace}".
 
-"""
+""".format(composite_namespace=copy_helper.PARALLEL_UPLOAD_TEMP_NAMESPACE)
 
 
 NOTIFICATION_AUTHORIZATION_FAILED_MESSAGE = """
diff --git a/gslib/commands/perfdiag.py b/gslib/commands/perfdiag.py
index 292aeed..a1dfe2a 100644
--- a/gslib/commands/perfdiag.py
+++ b/gslib/commands/perfdiag.py
@@ -1343,9 +1343,11 @@ class PerfDiagCommand(Command):
     proxy_port = boto.config.getint('Boto', 'proxy_port', 0)
     sysinfo['using_proxy'] = bool(proxy_host)
 
-    if boto.config.get('Boto', 'proxy_rdns', False):
-      self.logger.info('DNS lookups are disallowed in this environment, so '
-                       'some information is not included in this perfdiag run.')
+    if boto.config.get('Boto', 'proxy_rdns', True if proxy_host else False):
+      self.logger.info(
+          'DNS lookups are disallowed in this environment, so some information '
+          'is not included in this perfdiag run. To allow local DNS lookups '
+          'while using a proxy, set proxy_rdns to False in your boto file.')
 
     # Get the local IP address from socket lib.
     try:
diff --git a/gslib/commands/requesterpays.py b/gslib/commands/requesterpays.py
new file mode 100644
index 0000000..184681e
--- /dev/null
+++ b/gslib/commands/requesterpays.py
@@ -0,0 +1,182 @@
+# -*- coding: utf-8 -*-
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+"""Implementation of requesterpays configuration command for buckets."""
+
+from __future__ import absolute_import
+
+from gslib import metrics
+from gslib.command import Command
+from gslib.command_argument import CommandArgument
+from gslib.cs_api_map import ApiSelector
+from gslib.exception import CommandException
+from gslib.exception import NO_URLS_MATCHED_TARGET
+from gslib.help_provider import CreateHelpText
+from gslib.third_party.storage_apitools import storage_v1_messages as apitools_messages
+from gslib.util import NO_MAX
+
+
+_SET_SYNOPSIS = """
+  gsutil requesterpays set [on|off] bucket_url...
+"""
+
+_GET_SYNOPSIS = """
+  gsutil requesterpays get bucket_url...
+"""
+
+_SYNOPSIS = _SET_SYNOPSIS + _GET_SYNOPSIS.lstrip('\n')
+
+_SET_DESCRIPTION = """
+<B>SET</B>
+  The "set" sub-command requires an additional sub-command, either "on" or
+  "off", which, respectively, will enable or disable requester pays for the
+  specified bucket(s).
+
+"""
+
+_GET_DESCRIPTION = """
+<B>GET</B>
+  The "get" sub-command gets the requester pays configuration for a
+  bucket and displays whether or not it is enabled.
+"""
+
+_DESCRIPTION = """
+  The Requester Pays Configuration feature enables you to configure a Google
+  Cloud Storage bucket to indicate that the requester will pay all costs
+  related to accessing the bucket and its objects.
+
+  The gsutil requesterpays command has two sub-commands:
+""" + _SET_DESCRIPTION + _GET_DESCRIPTION
+
+_DETAILED_HELP_TEXT = CreateHelpText(_SYNOPSIS, _DESCRIPTION)
+
+_get_help_text = CreateHelpText(_GET_SYNOPSIS, _GET_DESCRIPTION)
+_set_help_text = CreateHelpText(_SET_SYNOPSIS, _SET_DESCRIPTION)
+
+
+class RequesterPaysCommand(Command):
+  """Implementation of gsutil requesterpays command."""
+
+  # Command specification. See base class for documentation.
+  command_spec = Command.CreateCommandSpec(
+      'requesterpays',
+      usage_synopsis=_SYNOPSIS,
+      min_args=2,
+      max_args=NO_MAX,
+      supported_sub_args='',
+      file_url_ok=False,
+      provider_url_ok=False,
+      urls_start_arg=2,
+      gs_api_support=[
+          # ApiSelector.XML,  # TODO: Uncomment once boto changes are added.
+          ApiSelector.JSON],
+      gs_default_api=ApiSelector.JSON,
+      argparse_arguments={
+          'set': [
+              CommandArgument('mode', choices=['on', 'off']),
+              CommandArgument.MakeZeroOrMoreCloudBucketURLsArgument()
+          ],
+          'get': [
+              CommandArgument.MakeZeroOrMoreCloudBucketURLsArgument()
+          ]
+      }
+  )
+  # Help specification. See help_provider.py for documentation.
+  help_spec = Command.HelpSpec(
+      help_name='requesterpays',
+      help_name_aliases=[],
+      help_type='command_help',
+      help_one_line_summary=(
+          'Enable or disable requester pays for one or more buckets'),
+      help_text=_DETAILED_HELP_TEXT,
+      subcommand_help_text={'get': _get_help_text, 'set': _set_help_text},
+  )
+
+  def _CalculateUrlsStartArg(self):
+    if not self.args:
+      self.RaiseWrongNumberOfArgumentsException()
+    if self.args[0].lower() == 'set':
+      return 2
+    else:
+      return 1
+
+  def _SetRequesterPays(self):
+    """Gets requesterpays configuration for a bucket."""
+    requesterpays_arg = self.args[0].lower()
+    if requesterpays_arg not in ('on', 'off'):
+      raise CommandException('Argument to "%s set" must be either [on|off]'
+                             % (self.command_name))
+    url_args = self.args[1:]
+    if not url_args:
+      self.RaiseWrongNumberOfArgumentsException()
+
+    # Iterate over URLs, expanding wildcards and set the requesterpays
+    # configuration on each.
+    some_matched = False
+    for url_str in url_args:
+      bucket_iter = self.GetBucketUrlIterFromArg(url_str, bucket_fields=['id'])
+      for blr in bucket_iter:
+        url = blr.storage_url
+        some_matched = True
+        bucket_metadata = apitools_messages.Bucket(
+            billing=apitools_messages.Bucket.BillingValue())
+        if requesterpays_arg == 'on':
+          self.logger.info('Enabling requester pays for %s...', url)
+          bucket_metadata.billing.requesterPays = True
+        else:
+          self.logger.info('Disabling requester pays for %s...', url)
+          bucket_metadata.billing.requesterPays = False
+        self.gsutil_api.PatchBucket(url.bucket_name, bucket_metadata,
+                                    provider=url.scheme, fields=['id'])
+    if not some_matched:
+      raise CommandException(NO_URLS_MATCHED_TARGET % list(url_args))
+
+  def _GetRequesterPays(self):
+    """Gets requesterpays configuration for one or more buckets."""
+    url_args = self.args
+
+    # Iterate over URLs, expanding wildcards and getting the requesterpays
+    # configuration on each.
+    some_matched = False
+    for url_str in url_args:
+      bucket_iter = self.GetBucketUrlIterFromArg(url_str,
+                                                 bucket_fields=['billing'])
+      for blr in bucket_iter:
+        some_matched = True
+        if blr.root_object.billing and blr.root_object.billing.requesterPays:
+          print '%s: Enabled' % blr.url_string.rstrip('/')
+        else:
+          print '%s: Disabled' % blr.url_string.rstrip('/')
+    if not some_matched:
+      raise CommandException(NO_URLS_MATCHED_TARGET % list(url_args))
+
+  def RunCommand(self):
+    """Command entry point for the requesterpays command."""
+    action_subcommand = self.args.pop(0)
+    if action_subcommand == 'get':
+      func = self._GetRequesterPays
+      metrics.LogCommandParams(subcommands=[action_subcommand])
+    elif action_subcommand == 'set':
+      func = self._SetRequesterPays
+      requesterpays_arg = self.args[0].lower()
+      if requesterpays_arg in ('on', 'off'):
+        metrics.LogCommandParams(
+            subcommands=[action_subcommand, requesterpays_arg])
+    else:
+      raise CommandException((
+          'Invalid subcommand "%s" for the %s command.\n'
+          'See "gsutil help %s".') % (
+              action_subcommand, self.command_name, self.command_name))
+    func()
+    return 0
diff --git a/gslib/commands/rsync.py b/gslib/commands/rsync.py
index 59f4b1b..0228dd0 100644
--- a/gslib/commands/rsync.py
+++ b/gslib/commands/rsync.py
@@ -200,24 +200,16 @@ _DETAILED_HELP_TEXT = ("""
      "gsutil help versions".
 
 
-<B>IMPACT OF OBJECT LISTING EVENTUAL CONSISTENCY</B>
-  The rsync command operates by listing the source and destination URLs, and
-  then performing copy and remove operations according to the differences
-  between these listings. Because object listing is eventually (not strongly)
-  consistent within multi-regional locations, if you upload new objects or
-  delete objects from a bucket in a multi-regional location and then
-  immediately run gsutil rsync with that bucket as the source or destination,
-  it's possible the rsync command will not see the recent updates and thus
-  synchronize incorrectly. For example, if you rsync to a ``US`` bucket
-  immediately after uploading to or deleting objects from that bucket, it's
-  possible gsutil will re-upload objects that have already been uploaded or
-  attempt to delete objects that were already deleted. A more troublesome
-  problem can occur if you run gsutil rsync, specifying a bucket as the
-  source immediately after uploading to or deleting objects from that bucket.
-  In that case it's possible rsync will miss copying objects to, or deleting
-  objects from, the destination. If this happens you can rerun the rsync
-  operation again later (after the object listing has "caught up"), to cause
-  the missing objects to be copied and extra objects to be deleted.
+<B>EVENTUAL CONSISTENCY WITH NON-GOOGLE CLOUD PROVIDERS</B>
+  While Google Cloud Storage is strongly consistent, some cloud providers
+  only support eventual consistency. You may encounter scenarios where rsync
+  synchronizes using stale listing data when working with these other cloud
+  providers. For example, if you run rsync immediately after uploading an
+  object to an eventually consistent cloud provider, the added object may not
+  yet appear in the providerâ€™s listing. Consequently, rsync will miss adding
+  the object to the destination. If this happens you can rerun the rsync
+  operation again later (after the object listing has "caught up").
+
 
 
 <B>CHECKSUM VALIDATION AND FAILURE HANDLING</B>
@@ -424,9 +416,8 @@ _DETAILED_HELP_TEXT = ("""
 
                   gsutil rsync -x ".*\.txt$|.*\.jpg$" dir gs://my-bucket
 
-                NOTE: While it will work to surround the regular expression with
-                either single or double quotes on Linux and MacOS, on Windows
-                you need to use double quotes.
+                NOTE: When using this on the Windows command line, use ^ as an
+                escape character instead of \ and escape the | character.
 """)
 
 _NA = '-'
diff --git a/gslib/commands/signurl.py b/gslib/commands/signurl.py
index 36ad9e0..f2dfa14 100644
--- a/gslib/commands/signurl.py
+++ b/gslib/commands/signurl.py
@@ -70,14 +70,13 @@ _DETAILED_HELP_TEXT = ("""
 
 
 <B>DESCRIPTION</B>
-  The signurl command will generate signed urls that can be used to access
-  the specified objects without authentication for a specific period of time.
-
-  Please see the `Signed URLs documentation
+  The signurl command will generate a signed URL that embeds authentication data
+  so the URL can be used by someone who does not have a Google account. Please
+  see the `Signed URLs documentation
   <https://cloud.google.com/storage/docs/access-control/signed-urls>`_ for
   background about signed URLs.
 
-  Multiple gs:// urls may be provided and may contain wildcards.  A signed url
+  Multiple gs:// urls may be provided and may contain wildcards. A signed url
   will be produced for each provided url, authorized
   for the specified HTTP method and valid for the given duration.
 
@@ -86,12 +85,12 @@ _DETAILED_HELP_TEXT = ("""
 
     gsutil signurl <private-key-file> gs://some-bucket/some-object/
 
-  The signurl command uses the private key for a  service account (the
+  The signurl command uses the private key for a service account (the
   '<private-key-file>' argument) to generate the cryptographic
   signature for the generated URL. The private key file must be in PKCS12
   or JSON format. If the private key is encrypted the signed url command will
   prompt for the passphrase used to protect the private key file
-  (default 'notasecret').  For more information regarding generating a private
+  (default 'notasecret'). For more information regarding generating a private
   key for use with the signurl command please see the `Authentication
   documentation.
   <https://cloud.google.com/storage/docs/authentication#generating-a-private-key>`_
diff --git a/gslib/commands/test.py b/gslib/commands/test.py
index d9b1769..39e2a98 100644
--- a/gslib/commands/test.py
+++ b/gslib/commands/test.py
@@ -32,25 +32,12 @@ from gslib.command import ResetFailureCount
 from gslib.exception import CommandException
 from gslib.project_id import PopulateProjectId
 import gslib.tests as tests
+from gslib.tests.util import GetTestNames
+from gslib.tests.util import unittest
 from gslib.util import IS_WINDOWS
 from gslib.util import NO_MAX
 
-
-# For Python 2.6, unittest2 is required to run the tests. If it's not available,
-# display an error if the test command is run instead of breaking the whole
-# program.
 # pylint: disable=g-import-not-at-top
-try:
-  from gslib.tests.util import GetTestNames
-  from gslib.tests.util import unittest
-except ImportError as e:
-  if 'unittest2' in str(e):
-    unittest = None
-    GetTestNames = None  # pylint: disable=invalid-name
-  else:
-    raise
-
-
 try:
   import coverage
 except ImportError:
@@ -464,10 +451,6 @@ class TestCommand(Command):
 
   def RunCommand(self):
     """Command entry point for the test command."""
-    if not unittest:
-      raise CommandException('On Python 2.6, the unittest2 module is required '
-                             'to run the gsutil tests.')
-
     failfast = False
     list_tests = False
     max_parallel_tests = _DEFAULT_TEST_PARALLEL_PROCESSES
diff --git a/gslib/copy_helper.py b/gslib/copy_helper.py
index f44c469..38654e4 100644
--- a/gslib/copy_helper.py
+++ b/gslib/copy_helper.py
@@ -35,7 +35,6 @@ import re
 import shutil
 import stat
 import subprocess
-import sys
 import tempfile
 import textwrap
 import time
@@ -1348,7 +1347,7 @@ def _LogCopyOperation(logger, src_url, dst_url, dst_obj_metadata):
   else:
     content_type_msg = ''
   if src_url.IsFileUrl() and (src_url.IsStream() or src_url.IsFifo()):
-    src_text = "<STDIN>" if src_url.IsStream() else "named pipe"
+    src_text = '<STDIN>' if src_url.IsStream() else 'named pipe'
     logger.info('Copying from %s%s...', src_text, content_type_msg)
   else:
     logger.info('Copying %s%s...', src_url.url_string, content_type_msg)
@@ -1454,6 +1453,7 @@ def _SetContentTypeFromFile(src_url, dst_obj_metadata):
       content_type = DEFAULT_CONTENT_TYPE
     dst_obj_metadata.contentType = content_type
 
+
 # pylint: disable=undefined-variable
 def _UploadFileToObjectNonResumable(src_url, src_obj_filestream,
                                     src_obj_size, dst_url, dst_obj_metadata,
@@ -2377,7 +2377,8 @@ def _DownloadObjectToFileResumable(src_url, src_obj_metadata, dst_url,
     # and size into the download for new downloads so that we can avoid
     # making an extra HTTP call.
     serialization_data = GetDownloadSerializationData(
-        src_obj_metadata, progress=download_start_byte)
+        src_obj_metadata, progress=download_start_byte,
+        user_project=gsutil_api.user_project)
 
     if resuming or download_complete:
       # Catch up our digester with the hash data.
@@ -2478,7 +2479,8 @@ def _DownloadObjectToFileNonResumable(src_url, src_obj_metadata, dst_url,
 
     # This is used to pass the mediaLink and the size into the download so that
     # we can avoid making an extra HTTP call.
-    serialization_data = GetDownloadSerializationData(src_obj_metadata)
+    serialization_data = GetDownloadSerializationData(
+        src_obj_metadata, 0, user_project=gsutil_api.user_project)
 
     progress_callback = FileProgressCallbackHandler(
         gsutil_api.status_queue, src_url=src_url, dst_url=dst_url,
@@ -3155,7 +3157,7 @@ def PerformCopy(logger, src_url, dst_url, gsutil_api,
 
     src_obj_size = src_obj_metadata.size
     dst_obj_metadata.contentType = src_obj_metadata.contentType
-    if global_copy_helper_opts.preserve_acl:
+    if global_copy_helper_opts.preserve_acl and dst_url.IsCloudUrl():
       if src_url.scheme == 'gs' and not src_obj_metadata.acl:
         raise CommandException(
             'No OWNER permission found for object %s. OWNER permission is '
diff --git a/gslib/daisy_chain_wrapper.py b/gslib/daisy_chain_wrapper.py
index 754a06f..58313d7 100644
--- a/gslib/daisy_chain_wrapper.py
+++ b/gslib/daisy_chain_wrapper.py
@@ -146,7 +146,6 @@ class DaisyChainWrapper(object):
     self.download_started = threading.Event()
     self.stop_download = threading.Event()
     self.StartDownloadThread(progress_callback=self.progress_callback)
-    # Python 2.6 will return None on timeout.
     if self.download_started.wait(60) == False:
       raise Exception('Could not start download thread after 60 seconds.')
 
diff --git a/gslib/gcs_json_api.py b/gslib/gcs_json_api.py
index 80209b3..09ac0bb 100644
--- a/gslib/gcs_json_api.py
+++ b/gslib/gcs_json_api.py
@@ -158,7 +158,7 @@ class GcsJsonApi(CloudApi):
 
   def __init__(self, bucket_storage_uri_class, logger, status_queue,
                provider=None, credentials=None, debug=0, trace_token=None,
-               perf_trace_token=None):
+               perf_trace_token=None, user_project=None):
     """Performs necessary setup for interacting with Google Cloud Storage.
 
     Args:
@@ -171,12 +171,14 @@ class GcsJsonApi(CloudApi):
       debug: Debug level for the API implementation (0..3).
       trace_token: Trace token to pass to the API implementation.
       perf_trace_token: Performance trace token to use when making API calls.
+      user_project: Project to be billed for this request.
     """
     # TODO: Plumb host_header for perfdiag / test_perfdiag.
     # TODO: Add jitter to apitools' http_wrapper retry mechanism.
     super(GcsJsonApi, self).__init__(
         bucket_storage_uri_class, logger, status_queue, provider='gs',
-        debug=debug, trace_token=trace_token, perf_trace_token=perf_trace_token)
+        debug=debug, trace_token=trace_token, perf_trace_token=perf_trace_token,
+        user_project=user_project)
     no_op_credentials = False
     if not credentials:
       loaded_credentials = CheckAndGetCredentials(logger)
@@ -310,7 +312,7 @@ class GcsJsonApi(CloudApi):
 
   def GetBucketIamPolicy(self, bucket_name, provider=None, fields=None):
     apitools_request = apitools_messages.StorageBucketsGetIamPolicyRequest(
-        bucket=bucket_name)
+        bucket=bucket_name, userProject=self.user_project)
     global_params = apitools_messages.StandardQueryParameters()
     if fields:
       global_params.fields = ','.join(set(fields))
@@ -322,11 +324,12 @@ class GcsJsonApi(CloudApi):
       self._TranslateExceptionAndRaise(e, bucket_name=bucket_name)
 
   def GetObjectIamPolicy(self, bucket_name, object_name,
-                         generation, provider=None, fields=None):
+                         generation=None, provider=None, fields=None):
     if generation is not None:
       generation = long(generation)
     apitools_request = apitools_messages.StorageObjectsGetIamPolicyRequest(
-        bucket=bucket_name, object=object_name, generation=generation)
+        bucket=bucket_name, object=object_name, generation=generation,
+        userProject=self.user_project)
     global_params = apitools_messages.StandardQueryParameters()
     if fields:
       global_params.fields = ','.join(set(fields))
@@ -345,7 +348,7 @@ class GcsJsonApi(CloudApi):
       generation = long(generation)
     api_request = apitools_messages.StorageObjectsSetIamPolicyRequest(
         bucket=bucket_name, object=object_name, generation=generation,
-        policy=policy)
+        policy=policy, userProject=self.user_project)
     global_params = apitools_messages.StandardQueryParameters()
     try:
       return self.api_client.objects.SetIamPolicy(
@@ -358,7 +361,8 @@ class GcsJsonApi(CloudApi):
   def SetBucketIamPolicy(self, bucket_name, policy, provider=None):
     apitools_request = apitools_messages.StorageBucketsSetIamPolicyRequest(
         bucket=bucket_name,
-        policy=policy)
+        policy=policy,
+        userProject=self.user_project)
     global_params = apitools_messages.StandardQueryParameters()
     try:
       return self.api_client.buckets.SetIamPolicy(
@@ -375,7 +379,8 @@ class GcsJsonApi(CloudApi):
       projection = (apitools_messages.StorageBucketsGetRequest
                     .ProjectionValueValuesEnum.full)
     apitools_request = apitools_messages.StorageBucketsGetRequest(
-        bucket=bucket_name, projection=projection)
+        bucket=bucket_name, projection=projection,
+        userProject=self.user_project)
     global_params = apitools_messages.StandardQueryParameters()
     if fields:
       global_params.fields = ','.join(set(fields))
@@ -406,7 +411,11 @@ class GcsJsonApi(CloudApi):
     # For blank metadata objects, we need to explicitly call
     # them out to apitools so it will send/erase them.
     apitools_include_fields = []
-    for metadata_field in ('metadata', 'lifecycle', 'logging', 'versioning',
+    for metadata_field in ('billing',
+                           'lifecycle',
+                           'logging',
+                           'metadata',
+                           'versioning',
                            'website'):
       attr = getattr(bucket_metadata, metadata_field, None)
       if attr and not encoding.MessageToDict(attr):
@@ -445,7 +454,8 @@ class GcsJsonApi(CloudApi):
         projection=projection,
         ifMetagenerationMatch=preconditions.meta_gen_match,
         predefinedAcl=predefined_acl,
-        predefinedDefaultObjectAcl=predefined_def_acl)
+        predefinedDefaultObjectAcl=predefined_def_acl,
+        userProject=self.user_project)
     global_params = apitools_messages.StandardQueryParameters()
     if fields:
       global_params.fields = ','.join(set(fields))
@@ -476,7 +486,8 @@ class GcsJsonApi(CloudApi):
     project_id = PopulateProjectId(project_id)
 
     apitools_request = apitools_messages.StorageBucketsInsertRequest(
-        bucket=metadata, project=project_id, projection=projection)
+        bucket=metadata, project=project_id, projection=projection,
+        userProject=self.user_project)
     global_params = apitools_messages.StandardQueryParameters()
     if fields:
       global_params.fields = ','.join(set(fields))
@@ -492,7 +503,8 @@ class GcsJsonApi(CloudApi):
       preconditions = Preconditions()
 
     apitools_request = apitools_messages.StorageBucketsDeleteRequest(
-        bucket=bucket_name, ifMetagenerationMatch=preconditions.meta_gen_match)
+        bucket=bucket_name, ifMetagenerationMatch=preconditions.meta_gen_match,
+        userProject=self.user_project)
 
     try:
       self.api_client.buckets.Delete(apitools_request)
@@ -520,7 +532,7 @@ class GcsJsonApi(CloudApi):
 
     apitools_request = apitools_messages.StorageBucketsListRequest(
         project=project_id, maxResults=NUM_BUCKETS_PER_LIST_PAGE,
-        projection=projection)
+        projection=projection, userProject=self.user_project)
     global_params = apitools_messages.StandardQueryParameters()
     if fields:
       if 'nextPageToken' not in fields:
@@ -538,7 +550,8 @@ class GcsJsonApi(CloudApi):
     while bucket_list.nextPageToken:
       apitools_request = apitools_messages.StorageBucketsListRequest(
           project=project_id, pageToken=bucket_list.nextPageToken,
-          maxResults=NUM_BUCKETS_PER_LIST_PAGE, projection=projection)
+          maxResults=NUM_BUCKETS_PER_LIST_PAGE, projection=projection,
+          userProject=self.user_project)
       try:
         bucket_list = self.api_client.buckets.List(apitools_request,
                                                    global_params=global_params)
@@ -565,7 +578,7 @@ class GcsJsonApi(CloudApi):
     apitools_request = apitools_messages.StorageObjectsListRequest(
         bucket=bucket_name, prefix=prefix, delimiter=delimiter,
         versions=all_versions, projection=projection,
-        maxResults=NUM_OBJECTS_PER_LIST_PAGE)
+        maxResults=NUM_OBJECTS_PER_LIST_PAGE, userProject=self.user_project)
     global_params = apitools_messages.StandardQueryParameters()
 
     if fields:
@@ -589,7 +602,8 @@ class GcsJsonApi(CloudApi):
       apitools_request = apitools_messages.StorageObjectsListRequest(
           bucket=bucket_name, prefix=prefix, delimiter=delimiter,
           versions=all_versions, projection=projection,
-          pageToken=next_page_token, maxResults=NUM_OBJECTS_PER_LIST_PAGE)
+          pageToken=next_page_token, maxResults=NUM_OBJECTS_PER_LIST_PAGE,
+          userProject=self.user_project)
       try:
         object_list = self.api_client.objects.List(apitools_request,
                                                    global_params=global_params)
@@ -749,7 +763,7 @@ class GcsJsonApi(CloudApi):
 
     return apitools_messages.StorageObjectsGetRequest(
         bucket=bucket_name, object=object_name, projection=projection,
-        generation=generation)
+        generation=generation, userProject=self.user_project)
 
   def _GetApitoolsObjectMetadataGlobalParams(self, fields=None):
     global_params = apitools_messages.StandardQueryParameters()
@@ -880,7 +894,8 @@ class GcsJsonApi(CloudApi):
 
     apitools_download.bytes_http = self.authorized_download_http
     apitools_request = apitools_messages.StorageObjectsGetRequest(
-        bucket=bucket_name, object=object_name, generation=generation)
+        bucket=bucket_name, object=object_name, generation=generation,
+        userProject=self.user_project)
 
     # Disable retries in apitools. We will handle them explicitly for
     # resumable downloads; one-shot downloads are not retryable as we do
@@ -999,7 +1014,7 @@ class GcsJsonApi(CloudApi):
 
   def PatchObjectMetadata(self, bucket_name, object_name, metadata,
                           canned_acl=None, generation=None, preconditions=None,
-                          provider=None, fields=None):
+                          provider=None, fields=None, user_project=None):
     """See CloudApi class for function doc strings."""
     projection = (apitools_messages.StorageObjectsPatchRequest
                   .ProjectionValueValuesEnum.noAcl)
@@ -1028,7 +1043,7 @@ class GcsJsonApi(CloudApi):
         generation=generation, projection=projection,
         ifGenerationMatch=preconditions.gen_match,
         ifMetagenerationMatch=preconditions.meta_gen_match,
-        predefinedAcl=predefined_acl)
+        predefinedAcl=predefined_acl, userProject=self.user_project)
     global_params = apitools_messages.StandardQueryParameters()
     if fields:
       global_params.fields = ','.join(set(fields))
@@ -1107,7 +1122,7 @@ class GcsJsonApi(CloudApi):
             bucket=object_metadata.bucket, object=object_metadata,
             ifGenerationMatch=preconditions.gen_match,
             ifMetagenerationMatch=preconditions.meta_gen_match,
-            predefinedAcl=predefined_acl)
+            predefinedAcl=predefined_acl, userProject=self.user_project)
         global_params = apitools_messages.StandardQueryParameters()
         if fields:
           global_params.fields = ','.join(set(fields))
@@ -1379,7 +1394,8 @@ class GcsJsonApi(CloudApi):
               ifMetagenerationMatch=preconditions.meta_gen_match,
               destinationPredefinedAcl=predefined_acl,
               rewriteToken=resume_rewrite_token,
-              maxBytesRewrittenPerCall=max_bytes_per_call)
+              maxBytesRewrittenPerCall=max_bytes_per_call,
+              userProject=self.user_project)
           rewrite_response = self.api_client.objects.Rewrite(
               apitools_request, global_params=global_params)
         bytes_written = long(rewrite_response.totalBytesRewritten)
@@ -1422,7 +1438,8 @@ class GcsJsonApi(CloudApi):
     apitools_request = apitools_messages.StorageObjectsDeleteRequest(
         bucket=bucket_name, object=object_name, generation=generation,
         ifGenerationMatch=preconditions.gen_match,
-        ifMetagenerationMatch=preconditions.meta_gen_match)
+        ifMetagenerationMatch=preconditions.meta_gen_match,
+        userProject=self.user_project)
     try:
       return self.api_client.objects.Delete(apitools_request)
     except TRANSLATABLE_APITOOLS_EXCEPTIONS, e:
@@ -1462,7 +1479,8 @@ class GcsJsonApi(CloudApi):
           destinationBucket=dst_bucket_name,
           destinationObject=dst_obj_name,
           ifGenerationMatch=preconditions.gen_match,
-          ifMetagenerationMatch=preconditions.meta_gen_match)
+          ifMetagenerationMatch=preconditions.meta_gen_match,
+          userProject=self.user_project)
       try:
         return self.api_client.objects.Compose(apitools_request,
                                                global_params=global_params)
@@ -1484,7 +1502,8 @@ class GcsJsonApi(CloudApi):
                                         token=token, type='WEB_HOOK')
 
     apitools_request = apitools_messages.StorageObjectsWatchAllRequest(
-        bucket=bucket_name, channel=channel, projection=projection)
+        bucket=bucket_name, channel=channel, projection=projection,
+        userProject=self.user_project)
 
     global_params = apitools_messages.StandardQueryParameters()
     if fields:
@@ -1539,7 +1558,8 @@ class GcsJsonApi(CloudApi):
 
       request = apitools_messages.StorageNotificationsInsertRequest(
           bucket=bucket_name,
-          notification=notification)
+          notification=notification,
+          userProject=self.user_project)
       return self.api_client.notifications.Insert(request)
     except TRANSLATABLE_APITOOLS_EXCEPTIONS, e:
       self._TranslateExceptionAndRaise(e)
@@ -1552,7 +1572,8 @@ class GcsJsonApi(CloudApi):
     try:
       request = apitools_messages.StorageNotificationsDeleteRequest(
           bucket=bucket_name,
-          notification=notification)
+          notification=notification,
+          userProject=self.user_project)
       return self.api_client.notifications.Delete(request)
     except TRANSLATABLE_APITOOLS_EXCEPTIONS, e:
       self._TranslateExceptionAndRaise(e)
@@ -1561,7 +1582,7 @@ class GcsJsonApi(CloudApi):
     """See CloudApi class for function doc strings."""
     try:
       request = apitools_messages.StorageNotificationsListRequest(
-          bucket=bucket_name)
+          bucket=bucket_name, userProject=self.user_project)
       response = self.api_client.notifications.List(request)
       for notification in response.items:
         yield notification
@@ -1698,11 +1719,14 @@ class GcsJsonApi(CloudApi):
             message or 'Bad Request', status=e.status_code)
     if isinstance(e, apitools_exceptions.StreamExhausted):
       return ResumableUploadAbortException(e.message)
-    if (isinstance(e, apitools_exceptions.TransferError) and
-        ('Aborting transfer' in e.message or
-         'Not enough bytes in stream' in e.message or
-         'additional bytes left in stream' in e.message)):
-      return ResumableUploadAbortException(e.message)
+    if isinstance(e, apitools_exceptions.TransferError):
+      if ('Aborting transfer' in e.message or
+          'Not enough bytes in stream' in e.message):
+        return ResumableUploadAbortException(e.message)
+      elif 'additional bytes left in stream' in e.message:
+        return ResumableUploadAbortException(
+            '%s; this can happen if a file changes size while being uploaded' %
+            e.message)
 
   def _TranslateApitoolsException(self, e, bucket_name=None, object_name=None,
                                   generation=None, not_found_exception=None):
diff --git a/gslib/gcs_json_media.py b/gslib/gcs_json_media.py
index 1b872ae..f248eea 100644
--- a/gslib/gcs_json_media.py
+++ b/gslib/gcs_json_media.py
@@ -306,10 +306,12 @@ def WrapDownloadHttpRequest(download_http):
     Wrapped / overridden httplib2.Http object.
   """
 
-  # httplib2 has a bug https://code.google.com/p/httplib2/issues/detail?id=305
-  # where custom connection_type is not respected after redirects.  This
-  # function is copied from httplib2 and overrides the request function so that
-  # the connection_type is properly passed through.
+  # httplib2 has a bug (https://github.com/httplib2/httplib2/issues/75) where
+  # custom connection_type is not respected after redirects.  This function is
+  # copied from httplib2 and overrides the request function so that the
+  # connection_type is properly passed through (everything here should be
+  # identical to the _request method in httplib2, with the exception of the line
+  # below marked by the "BUGFIX" comment).
   # pylint: disable=protected-access,g-inconsistent-quotes,unused-variable
   # pylint: disable=g-equals-none,g-doc-return-or-yield
   # pylint: disable=g-short-docstring-punctuation,g-doc-args
@@ -390,6 +392,7 @@ def WrapDownloadHttpRequest(download_http):
             (response, content) = self.request(
                 location, redirect_method, body=body, headers=headers,
                 redirections=redirections-1,
+                # BUGFIX (see comments at the top of this function):
                 connection_type=conn.__class__)
             response.previous = old_response
         else:
diff --git a/gslib/metrics.py b/gslib/metrics.py
index cc7e5e0..070e625 100644
--- a/gslib/metrics.py
+++ b/gslib/metrics.py
@@ -737,6 +737,11 @@ class MetricsCollector(object):
       # This can happen specifically if the Python executable moves between the
       # start of this process and now.
       self.logger.debug('Metrics reporting process failed to start.')
+      # Delete the tempfile that would normally be cleaned up in the subprocess.
+      try:
+        os.unlink(temp_metrics_file.name)
+      except:  # pylint: disable=bare-except
+        pass
 
 
 def CaptureAndLogException(func):
diff --git a/gslib/plurality_checkable_iterator.py b/gslib/plurality_checkable_iterator.py
index a3ef8d5..23c2e8c 100644
--- a/gslib/plurality_checkable_iterator.py
+++ b/gslib/plurality_checkable_iterator.py
@@ -47,13 +47,18 @@ class PluralityCheckableIterator(object):
     self.base_iterator = None
     self.head = []
     self.underlying_iter_empty = False
-    # Populate first 2 elems into head so we can check whether iterator has
-    # more than 1 item.
-    for _ in range(0, 2):
-      self._PopulateHead()
 
-  def _PopulateHead(self):
-    if not self.underlying_iter_empty:
+  def _PopulateHead(self, num_elements=1):
+    """Populates self.head from the underlying iterator.
+
+    Args:
+      num_elements: Populate until self.head contains this many
+          elements (or until the underlying iterator runs out).
+
+    Returns:
+      Number of elements at self.head after execution complete.
+    """
+    while not self.underlying_iter_empty and len(self.head) < num_elements:
       try:
         if not self.base_iterator:
           self.base_iterator = iter(self.orig_iterator)
@@ -67,20 +72,18 @@ class PluralityCheckableIterator(object):
         # Indicates we can no longer call next() on underlying iterator, but
         # there could still be elements left to iterate in head.
         self.underlying_iter_empty = True
-      except Exception, e:
+      except Exception, e:  # pylint: disable=broad-except
         # Buffer the exception and raise it when the element is accessed.
         # Also, preserve the original stack trace, as the stack trace from
         # within plurality_checkable_iterator.next is not very useful.
         self.head.append(('exception', e, sys.exc_info()[2]))
+    return len(self.head)
 
   def __iter__(self):
     return self
 
   def next(self):
-    # Backfill into head each time we pop an element so we can always check
-    # for emptiness and for HasPlurality().
-    while self.head:
-      self._PopulateHead()
+    if self._PopulateHead():
       item_tuple = self.head.pop(0)
       if item_tuple[0] == 'element':
         return item_tuple[1]
@@ -89,13 +92,15 @@ class PluralityCheckableIterator(object):
     raise StopIteration()
 
   def IsEmpty(self):
-    return not self.head
+    return not self._PopulateHead()
 
   def HasPlurality(self):
-    return len(self.head) > 1
+    # Populate 2 elements (if possible) into head so we can check whether
+    # iterator has more than 1 item remaining.
+    return self._PopulateHead(num_elements=2) > 1
 
   def PeekException(self):
     """Raises an exception if the first iterated element raised."""
-    if self.head and self.head[0][0] == 'exception':
+    if self._PopulateHead() and self.head[0][0] == 'exception':
       exception_tuple = self.head[0]
       raise exception_tuple[1].__class__, exception_tuple[1], exception_tuple[2]
diff --git a/gslib/sig_handling.py b/gslib/sig_handling.py
index 0cb8222..251ca4b 100644
--- a/gslib/sig_handling.py
+++ b/gslib/sig_handling.py
@@ -119,9 +119,8 @@ def KillProcess(pid):
     pid: The process ID.
   """
   try:
-    # os.kill doesn't work in 2.X or 3.Y on Windows for any X < 7 or Y < 2.
-    if IS_WINDOWS and ((2, 6) <= sys.version_info[:3] < (2, 7) or
-                       (3, 0) <= sys.version_info[:3] < (3, 2)):
+    # os.kill doesn't work in Python3 versions before 3.2.
+    if IS_WINDOWS and ((3, 0) <= sys.version_info[:3] < (3, 2)):
       kernel32 = ctypes.windll.kernel32
       handle = kernel32.OpenProcess(1, 0, pid)
       kernel32.TerminateProcess(handle, 0)
diff --git a/gslib/storage_url.py b/gslib/storage_url.py
index 16298b7..35c21db 100644
--- a/gslib/storage_url.py
+++ b/gslib/storage_url.py
@@ -202,7 +202,7 @@ class _CloudUrl(StorageUrl):
         self.object_name = object_match.group('object')
         if self.object_name == '.' or self.object_name == '..':
           raise InvalidUrlError(
-              '%s is an invalid root-level object name.' % self.object_name)
+              '%s is an invalid root-level object name' % self.object_name)
         if self.scheme == 'gs':
           generation_match = GS_GENERATION_REGEX.match(self.object_name)
           if generation_match:
diff --git a/gslib/tests/test_copy_helper_funcs.py b/gslib/tests/test_copy_helper_funcs.py
index 6d8dab9..d26f46d 100644
--- a/gslib/tests/test_copy_helper_funcs.py
+++ b/gslib/tests/test_copy_helper_funcs.py
@@ -333,7 +333,12 @@ class TestCpFuncs(GsUtilUnitTestCase):
 
     exc = apitools_exceptions.TransferError('Aborting transfer')
     translated_exc = gsutil_api._TranslateApitoolsResumableUploadException(exc)
+    self.assertTrue(isinstance(translated_exc, ResumableUploadAbortException)) 
+    exc = apitools_exceptions.TransferError('additional bytes left in stream')
+    translated_exc = gsutil_api._TranslateApitoolsResumableUploadException(exc)
     self.assertTrue(isinstance(translated_exc, ResumableUploadAbortException))
+    self.assertIn('this can happen if a file changes size',
+                  translated_exc.reason)
 
   def testSetContentTypeFromFile(self):
     """Tests that content type is correctly determined for symlinks."""
diff --git a/gslib/tests/test_cors.py b/gslib/tests/test_cors.py
index da9e403..0919824 100644
--- a/gslib/tests/test_cors.py
+++ b/gslib/tests/test_cors.py
@@ -72,6 +72,12 @@ class TestCors(testcase.GsUtilIntegrationTestCase):
       '"responseHeader": ["foo2", "bar2"], "method": ["GET", "DELETE"]}]\n')
   cors_json_obj = json.loads(cors_doc)
 
+  cors_doc_not_nested_in_list = (
+      '{"origin": ["http://origin.example.com", "http://origin2.example.com"], '
+      '"responseHeader": ["foo", "bar"], '
+      '"method": ["GET", "PUT", "POST"], '
+      '"maxAgeSeconds": 3600}')
+
   cors_doc2 = (
       '[{"origin": ["http://origin1.example.com", '
       '"http://origin2.example.com"], '
@@ -132,6 +138,13 @@ class TestCors(testcase.GsUtilIntegrationTestCase):
                             expected_status=1, return_stderr=True)
     self.assertNotIn('XML CORS data provided', stderr)
 
+  def test_cors_doc_not_wrapped_in_json_list(self):
+    bucket_uri = self.CreateBucket()
+    fpath = self.CreateTempFile(contents=self.cors_doc_not_nested_in_list)
+    stderr = self.RunGsUtil(self._set_cmd_prefix + [fpath, suri(bucket_uri)],
+                            expected_status=1, return_stderr=True)
+    self.assertIn('should be formatted as a list', stderr)
+
   def set_cors_and_reset(self):
     """Tests setting CORS then removing it."""
     bucket_uri = self.CreateBucket()
diff --git a/gslib/tests/test_hash.py b/gslib/tests/test_hash.py
index c3de1d1..c166c34 100644
--- a/gslib/tests/test_hash.py
+++ b/gslib/tests/test_hash.py
@@ -46,7 +46,6 @@ class TestHashUnit(testcase.GsUtilUnitTestCase):
       self.RunCommand('hash', args=['non-existent-file'])
       self.fail('Did not get expected CommandException')
     except CommandException, e:
-      # assertRaisesRegexp causes issues with python 2.6.
       self.assertIn('No files matched', e.reason)
 
   def testHashHexFormat(self):
diff --git a/gslib/tests/test_ls.py b/gslib/tests/test_ls.py
index 48bc53b..8ad7dd2 100644
--- a/gslib/tests/test_ls.py
+++ b/gslib/tests/test_ls.py
@@ -26,6 +26,7 @@ import gslib
 from gslib.cs_api_map import ApiSelector
 import gslib.tests.testcase as testcase
 from gslib.tests.testcase.integration_testcase import SkipForS3
+from gslib.tests.testcase.integration_testcase import SkipForXML
 from gslib.tests.util import CaptureStdout
 from gslib.tests.util import ObjectToURI as suri
 from gslib.tests.util import SetBotoConfigForTest
@@ -499,6 +500,35 @@ class TestLs(testcase.GsUtilIntegrationTestCase):
                             return_stdout=True)
     self.assertIn('Website configuration:\t\tNone', stdout)
 
+  @SkipForS3('S3 bucket configuration values are not supported via ls.')
+  @SkipForXML('Requester Pays is not supported for the XML API.')
+  def test_requesterpays(self):
+    """Tests listing a bucket with requester pays (billing) config."""
+    bucket_uri = self.CreateBucket()
+    bucket_suri = suri(bucket_uri)
+
+    # No requester pays configuration
+    stdout = self.RunGsUtil(['ls', '-lb', bucket_suri],
+                            return_stdout=True)
+    self.assertNotIn('Requester Pays enabled', stdout)
+
+    # Requester Pays configuration is absent by default
+    stdout = self.RunGsUtil(['ls', '-Lb', bucket_suri],
+                            return_stdout=True)
+    self.assertIn('Requester Pays enabled:\t\tNone', stdout)
+
+    # Initialize and check
+    self.RunGsUtil(['requesterpays', 'set', 'on', bucket_suri])
+    stdout = self.RunGsUtil(['ls', '-Lb', bucket_suri],
+                            return_stdout=True)
+    self.assertIn('Requester Pays enabled:\t\tTrue', stdout)
+
+    # Clear and check
+    self.RunGsUtil(['requesterpays', 'set', 'off', bucket_suri])
+    stdout = self.RunGsUtil(['ls', '-Lb', bucket_suri],
+                            return_stdout=True)
+    self.assertIn('Requester Pays enabled:\t\tFalse', stdout)
+
   def test_list_sizes(self):
     """Tests various size listing options."""
     bucket_uri = self.CreateBucket()
@@ -778,4 +808,3 @@ class TestLs(testcase.GsUtilIntegrationTestCase):
                             expected_status=1,
                             return_stderr=True)
     self.assertIn('Invalid non-ASCII', stderr)
-
diff --git a/gslib/tests/test_parallelism_framework.py b/gslib/tests/test_parallelism_framework.py
index f4b0bb7..0c096ac 100644
--- a/gslib/tests/test_parallelism_framework.py
+++ b/gslib/tests/test_parallelism_framework.py
@@ -234,6 +234,7 @@ class FakeCommand(Command):
     self.multiprocessing_is_available = (
         CheckMultiprocessingAvailableAndInit().is_available)
     self.debug = 0
+    self.user_project = None
 
 
 class FakeCommandWithoutMultiprocessingModule(FakeCommand):
diff --git a/gslib/tests/test_plurality_checkable_iterator.py b/gslib/tests/test_plurality_checkable_iterator.py
index 31be317..3fecb58 100755
--- a/gslib/tests/test_plurality_checkable_iterator.py
+++ b/gslib/tests/test_plurality_checkable_iterator.py
@@ -157,7 +157,7 @@ class PluralityCheckableIteratorTests(testcase.GsUtilUnitTestCase):
       self.fail('Expected StopIteration')
 
   def testPluralityCheckableIteratorWithYieldedException(self):
-    """Tests PluralityCheckableIterator an iterator that yields an exception.
+    """Tests PCI with an iterator that yields an exception.
 
     The yielded exception is in the form of a tuple and must also contain a
     stack trace.
@@ -185,6 +185,7 @@ class PluralityCheckableIteratorTests(testcase.GsUtilUnitTestCase):
           raise StopIteration()
 
     pcit = PluralityCheckableIterator(IterTest())
+    iterated_value = None
     try:
       for _ in pcit:
         pass
@@ -194,3 +195,43 @@ class PluralityCheckableIteratorTests(testcase.GsUtilUnitTestCase):
     for value in pcit:
       iterated_value = value
     self.assertEqual(iterated_value, 1)
+
+  def testPluralityCheckableIteratorReadsAheadAsNeeded(self):
+    """Tests that the PCI does not unnecessarily read new elements."""
+
+    class IterTest(object):
+
+      def __init__(self):
+        self.position = 0
+
+      def __iter__(self):
+        return self
+
+      def next(self):
+        if self.position == 3:
+          raise StopIteration()
+        self.position += 1
+
+    # IsEmpty and PeekException should retrieve only 1 element from the
+    # underlying iterator.
+    pcit = PluralityCheckableIterator(IterTest())
+    pcit.IsEmpty()
+    pcit.PeekException()
+    self.assertEquals(pcit.orig_iterator.position, 1)
+    # HasPlurality requires populating 2 elements into the iterator.
+    pcit.HasPlurality()
+    self.assertEquals(pcit.orig_iterator.position, 2)
+    # next should yield already-populated elements without advancing the
+    # iterator.
+    pcit.next()  # Yields element 1
+    self.assertEquals(pcit.orig_iterator.position, 2)
+    pcit.next()  # Yields element 2
+    self.assertEquals(pcit.orig_iterator.position, 2)
+    pcit.next()  # Yields element 3
+    self.assertEquals(pcit.orig_iterator.position, 3)
+    try:
+      pcit.next()  # Underlying iterator is empty
+      self.fail('Expected StopIteration')
+    except StopIteration:
+      pass
+
diff --git a/gslib/tests/test_requester_pays.py b/gslib/tests/test_requester_pays.py
new file mode 100644
index 0000000..e111cd8
--- /dev/null
+++ b/gslib/tests/test_requester_pays.py
@@ -0,0 +1,284 @@
+# -*- coding: utf-8 -*-
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+"""Integration tests for notification command."""
+
+from __future__ import absolute_import
+
+import re
+
+from gslib.util import Retry
+
+import gslib.tests.testcase as testcase
+from gslib.project_id import PopulateProjectId
+from gslib.tests.testcase.integration_testcase import SkipForS3
+from gslib.tests.testcase.integration_testcase import SkipForXML
+from gslib.tests.util import ObjectToURI as suri
+
+OBJECT_CONTENTS = 'innards'
+
+
+@SkipForS3('gsutil doesn\'t support S3 Requester Pays.')
+@SkipForXML('Requester Pays is not supported for the XML API.')
+class TestRequesterPays(testcase.GsUtilIntegrationTestCase):
+  """Integration tests for Requester Pays.
+
+  Passing in a user project should succeed for operations on Requester Pays
+  buckets, and with the GA release will also succeed for non-Requester Pays
+  buckets.
+  """
+
+  _set_rp_cmd = ['requesterpays', 'set']
+  _get_rp_cmd = ['requesterpays', 'get']
+
+  def setUp(self):
+    super(TestRequesterPays, self).setUp()
+    self.non_requester_pays_bucket_uri = self.CreateBucket()
+    self.requester_pays_bucket_uri = self.CreateBucket()
+    self._set_requester_pays(self.requester_pays_bucket_uri)
+    self.non_requester_pays_object_uri = self.CreateObject(
+        bucket_uri=self.non_requester_pays_bucket_uri, contents=OBJECT_CONTENTS)
+    self.requester_pays_object_uri = self.CreateObject(
+        bucket_uri=self.requester_pays_bucket_uri, contents=OBJECT_CONTENTS)
+    self.user_project_flag = ['-u', PopulateProjectId()]
+
+  def _set_requester_pays(self, bucket_uri):
+    self.RunGsUtil(['requesterpays', 'set', 'on', suri(bucket_uri)])
+
+  def _run_requester_pays_test(self, command_list, regex=None):
+    """Test a command with a user project.
+
+    Run a command with a user project on a Requester Pays bucket. The command is
+    expected to pass because the source bucket is Requester Pays. If a regex
+    pattern is supplied, also assert that stdout of the command matches it.
+    """
+    stdout = self.RunGsUtil(self.user_project_flag + command_list,
+                            return_stdout=True)
+    if regex:
+      self.assertRegexpMatchesWithFlags(stdout, regex, flags=re.IGNORECASE)
+
+  def _run_non_requester_pays_test(self, command_list):
+    """Test a command with a user project on a non-Requester Pays bucket.
+
+    Run a command with a user project on a non-Requester Pays bucket. The
+    command will still succeed, because with GA user project is accepted for
+    all requests.
+    """
+    stdout = self.RunGsUtil(self.user_project_flag + command_list,
+                            return_stdout=True)
+
+  def test_off_default(self):
+    bucket_uri = self.CreateBucket()
+    stdout = self.RunGsUtil(
+        self._get_rp_cmd + [suri(bucket_uri)], return_stdout=True)
+    self.assertEqual(stdout.strip(), '%s: Disabled' % suri(bucket_uri))
+
+  def test_turning_on(self):
+    bucket_uri = self.CreateBucket()
+    self.RunGsUtil(self._set_rp_cmd + ['on', suri(bucket_uri)])
+
+    def _Check1():
+      stdout = self.RunGsUtil(
+          self._get_rp_cmd + [suri(bucket_uri)], return_stdout=True)
+      self.assertEqual(stdout.strip(), '%s: Enabled' % suri(bucket_uri))
+    _Check1()
+
+  def test_turning_off(self):
+    bucket_uri = self.CreateBucket()
+    self.RunGsUtil(self._set_rp_cmd + ['on', suri(bucket_uri)])
+
+    def _Check1():
+      stdout = self.RunGsUtil(
+          self._get_rp_cmd + [suri(bucket_uri)], return_stdout=True)
+      self.assertEqual(stdout.strip(), '%s: Enabled' % suri(bucket_uri))
+    _Check1()
+
+    self.RunGsUtil(self._set_rp_cmd + ['off', suri(bucket_uri)])
+
+    def _Check2():
+      stdout = self.RunGsUtil(
+          self._get_rp_cmd + [suri(bucket_uri)], return_stdout=True)
+      self.assertEqual(stdout.strip(), '%s: Disabled' % suri(bucket_uri))
+    _Check2()
+
+  def testTooFewArgumentsFails(self):
+    """Ensures requesterpays commands fail with too few arguments."""
+    # No arguments for set, but valid subcommand.
+    stderr = self.RunGsUtil(self._set_rp_cmd, return_stderr=True,
+                            expected_status=1)
+    self.assertIn('command requires at least', stderr)
+
+    # No arguments for get, but valid subcommand.
+    stderr = self.RunGsUtil(self._get_rp_cmd, return_stderr=True,
+                            expected_status=1)
+    self.assertIn('command requires at least', stderr)
+
+    # Neither arguments nor subcommand.
+    stderr = self.RunGsUtil(['requesterpays'], return_stderr=True,
+                            expected_status=1)
+    self.assertIn('command requires at least', stderr)
+
+  def test_acl(self):
+    requester_pays_bucket_uri = self.CreateBucket()
+    self._set_requester_pays(requester_pays_bucket_uri)
+    self._run_requester_pays_test(
+        ['acl', 'set', 'public-read', suri(requester_pays_bucket_uri)])
+    self._run_requester_pays_test(
+        ['acl', 'get', suri(requester_pays_bucket_uri)])
+
+    non_requester_pays_bucket_uri = self.CreateBucket()
+    self._run_non_requester_pays_test(
+        ['acl', 'set', 'public-read', suri(non_requester_pays_bucket_uri)])
+    self._run_non_requester_pays_test(
+        ['acl', 'get', suri(non_requester_pays_bucket_uri)])
+
+  def test_ls(self):
+    self._run_requester_pays_test(
+        ['ls', suri(self.requester_pays_bucket_uri)])
+    self._run_non_requester_pays_test(
+        ['ls', suri(self.non_requester_pays_bucket_uri)])
+
+  def test_rb(self):
+    rp_bucket_uri = self.CreateBucket()
+    self._set_requester_pays(rp_bucket_uri)
+    self._run_requester_pays_test(
+        ['rb', suri(rp_bucket_uri)])
+
+    non_rp_bucket_uri = self.CreateBucket()
+    self._run_non_requester_pays_test(
+        ['rb', suri(non_rp_bucket_uri)])
+
+  def test_copy(self):
+    dest_bucket_uri = self.CreateBucket()
+
+    self._run_requester_pays_test(
+        ['cp', suri(self.requester_pays_object_uri), suri(dest_bucket_uri)])
+    self._run_non_requester_pays_test(
+        ['cp', suri(self.non_requester_pays_object_uri), suri(dest_bucket_uri)])
+
+  def test_compose(self):
+    data_list = ['apple', 'orange', 'banana']
+
+    bucket_uri = self.CreateBucket()
+    components = [self.CreateObject(bucket_uri=bucket_uri, contents=data).uri
+                  for data in data_list]
+    composite = bucket_uri.clone_replace_name(self.MakeTempName('obj'))
+    self._run_non_requester_pays_test(
+        ['compose'] + components + [composite.uri])
+
+    rp_bucket_uri = self.CreateBucket()
+    self._set_requester_pays(rp_bucket_uri)
+    rp_components = [self.CreateObject(bucket_uri=rp_bucket_uri,
+                                       contents=data).uri
+                     for data in data_list]
+    rp_composite = suri(rp_bucket_uri) + '/composite.txt'
+    self._run_requester_pays_test(['compose'] + rp_components + [rp_composite])
+
+  def test_cat(self):
+    self._run_requester_pays_test(
+        ['cat', suri(self.requester_pays_object_uri)],
+        regex=OBJECT_CONTENTS)
+    self._run_non_requester_pays_test(
+        ['cat', suri(self.non_requester_pays_object_uri)])
+
+  def test_du_obj(self):
+    @Retry(AssertionError, tries=3, timeout_secs=1)
+    # Use @Retry as hedge against bucket listing eventual consistency.
+    def _check():
+      self._run_requester_pays_test(
+          ['du', suri(self.requester_pays_object_uri)])
+      self._run_non_requester_pays_test(
+          ['du', suri(self.non_requester_pays_object_uri)])
+    _check()
+
+  def test_hash(self):
+    self._run_requester_pays_test(
+        ['hash', '-c', suri(self.requester_pays_object_uri)],
+        regex=r'Hash \(crc32c\)')
+    self._run_non_requester_pays_test(
+        ['hash', '-c', suri(self.non_requester_pays_object_uri)])
+
+  def test_iam(self):
+    self._run_requester_pays_test(
+        ['iam', 'get', str(self.requester_pays_object_uri)])
+    self._run_non_requester_pays_test(
+        ['iam', 'get', str(self.non_requester_pays_object_uri)])
+
+  def test_mv(self):
+    requester_pays_bucket_uri = self.CreateBucket()
+    object1_uri = self.CreateObject(bucket_uri=requester_pays_bucket_uri,
+                                    contents='foo')
+    object2_uri = self.CreateObject(bucket_uri=requester_pays_bucket_uri,
+                                    contents='oOOo')
+    self.AssertNObjectsInBucket(requester_pays_bucket_uri, 2)
+    self._set_requester_pays(requester_pays_bucket_uri)
+    dest_bucket_uri = self.CreateBucket()
+
+    # Move two objects from bucket1 to Requester Pays bucket.
+    for obj in [object1_uri, object2_uri]:
+      self._run_requester_pays_test(['mv', suri(obj), suri(dest_bucket_uri)])
+    self.AssertNObjectsInBucket(requester_pays_bucket_uri, 0)
+
+    bucket_uri = self.CreateBucket()
+    object1_uri = self.CreateObject(bucket_uri=bucket_uri, contents='bar')
+    object2_uri = self.CreateObject(bucket_uri=bucket_uri, contents='baz')
+    self.AssertNObjectsInBucket(bucket_uri, 2)
+    for obj in [object1_uri, object2_uri]:
+      self._run_non_requester_pays_test(
+          ['mv', suri(obj), suri(dest_bucket_uri)])
+    self.AssertNObjectsInBucket(bucket_uri, 0)
+
+  def test_rewrite(self):
+    object_uri = self.CreateObject(contents='bar')
+    self._run_non_requester_pays_test(
+        ['rewrite', '-s', 'dra', suri(object_uri)])
+
+    req_pays_bucket_uri = self.CreateBucket()
+    self._set_requester_pays(req_pays_bucket_uri)
+    req_pays_obj_uri = self.CreateObject(bucket_uri=req_pays_bucket_uri,
+                                         contents='baz')
+    self._run_requester_pays_test(
+        ['rewrite', '-s', 'dra', suri(req_pays_obj_uri)])
+
+  def test_rsync(self):
+    req_pays_bucket_uri = self.CreateBucket(test_objects=2)
+    self._set_requester_pays(req_pays_bucket_uri)
+    bucket_uri = self.CreateBucket(test_objects=1)
+    self._run_requester_pays_test(
+        ['rsync', '-d', suri(req_pays_bucket_uri),
+         suri(self.requester_pays_bucket_uri)])
+
+    bucket_uri1 = self.CreateBucket(test_objects=2)
+    bucket_uri2 = self.CreateBucket(test_objects=1)
+    self._run_non_requester_pays_test(
+        ['rsync', '-d', suri(bucket_uri1), suri(bucket_uri2)])
+
+  def test_setmeta(self):
+    req_pays_obj_uri = self.CreateObject(
+        bucket_uri=self.requester_pays_bucket_uri,
+        contents='<html><body>text</body></html>')
+    self._run_requester_pays_test(
+        ['setmeta', '-h', 'content-type:text/html', suri(req_pays_obj_uri)])
+
+    obj_uri = self.CreateObject(
+        bucket_uri=self.non_requester_pays_bucket_uri,
+        contents='<html><body>text</body></html>')
+    self._run_non_requester_pays_test(
+        ['setmeta', '-h', 'content-type:text/html', suri(obj_uri)])
+
+  def test_stat(self):
+    self._run_requester_pays_test(
+        ['stat', suri(self.requester_pays_object_uri)])
+    self._run_non_requester_pays_test(
+        ['stat', suri(self.non_requester_pays_object_uri)])
diff --git a/gslib/tests/test_util.py b/gslib/tests/test_util.py
index c4f2461..02361cf 100644
--- a/gslib/tests/test_util.py
+++ b/gslib/tests/test_util.py
@@ -296,3 +296,35 @@ class TestUtil(testcase.GsUtilUnitTestCase):
     self.assertEqual('0 B', HumanReadableWithDecimalPlaces(0, 0))
     self.assertEqual('0.00 B', HumanReadableWithDecimalPlaces(0, 2))
     self.assertEqual('0.00000 B', HumanReadableWithDecimalPlaces(0, 5))
+
+  def DoTestAddQueryParamToUrl(self, url, param_name, param_val, expected_url):
+    new_url = util.AddQueryParamToUrl(url, param_name, param_val)
+    self.assertEqual(new_url, expected_url)
+
+  def testAddQueryParamToUrlWorksForASCIIValues(self):
+    # Note that the params here contain empty values and duplicates.
+    old_url = 'http://foo.bar/path/endpoint?a=1&a=2&b=3&c='
+    param_name = 'newparam'
+    param_val = 'nevalue'
+    expected_url = '{}&{}={}'.format(old_url, param_name, param_val)
+
+    self.DoTestAddQueryParamToUrl(old_url, param_name, param_val, expected_url)
+
+  def testAddQueryParamToUrlWorksForUTF8Values(self):
+    old_url = u'http://foo.bar/path/Ãªndpoint?Ã‚=1&a=2&ÃŸ=3&c='.encode('utf-8')
+    param_name = u'nÃªwparam'.encode('utf-8')
+    param_val = u'nÃªwvalue'.encode('utf-8')
+    # Expected return value is a UTF-8 encoded `str`.
+    expected_url = '{}&{}={}'.format(old_url, param_name, param_val)
+
+    self.DoTestAddQueryParamToUrl(old_url, param_name, param_val, expected_url)
+
+  def testAddQueryParamToUrlWorksForRawUnicodeValues(self):
+    old_url = u'http://foo.bar/path/Ãªndpoint?Ã‚=1&a=2&ÃŸ=3&c='
+    param_name = u'nÃªwparam'
+    param_val = u'nÃªwvalue'
+    # Since the original URL was a `unicode`, the returned URL should also be.
+    expected_url = u'{}&{}={}'.format(old_url, param_name, param_val)
+
+    self.DoTestAddQueryParamToUrl(old_url, param_name, param_val, expected_url)
+
diff --git a/gslib/tests/testcase/unit_testcase.py b/gslib/tests/testcase/unit_testcase.py
index 9e4dd8b..ac06367 100644
--- a/gslib/tests/testcase/unit_testcase.py
+++ b/gslib/tests/testcase/unit_testcase.py
@@ -34,7 +34,6 @@ import gslib.tests.util as util
 from gslib.tests.util import unittest
 from gslib.tests.util import WorkingDirectory
 from gslib.util import DiscardMessagesQueue
-from gslib.util import GsutilStreamHandler
 
 
 class GsutilApiUnitTestClassMapFactory(object):
@@ -93,7 +92,7 @@ class GsUtilUnitTestCase(base.GsUtilTestCase):
     self.log_handlers_save = self.root_logger.handlers
     fd, self.log_handler_file = tempfile.mkstemp()
     self.log_handler_stream = os.fdopen(fd, 'w+')
-    self.temp_log_handler = GsutilStreamHandler(self.log_handler_stream)
+    self.temp_log_handler = logging.StreamHandler(self.log_handler_stream)
     self.root_logger.handlers = [self.temp_log_handler]
 
   def tearDown(self):
diff --git a/gslib/tests/util.py b/gslib/tests/util.py
index 4d9b5b2..b6bc662 100644
--- a/gslib/tests/util.py
+++ b/gslib/tests/util.py
@@ -39,10 +39,6 @@ from gslib.util import LazyWrapper
 from gslib.util import MakeHumanReadable
 from gslib.util import UsingCrcmodExtension
 
-if not hasattr(unittest.TestCase, 'assertIsNone'):
-  # external dependency unittest2 required for Python <= 2.6
-  import unittest2 as unittest  # pylint: disable=g-import-not-at-top
-
 # pylint: disable=g-import-not-at-top, g-long-lambda
 if not IS_WINDOWS:
   import grp
diff --git a/gslib/third_party/storage_apitools/storage_v1_client.py b/gslib/third_party/storage_apitools/storage_v1_client.py
index efc155d..da9c21a 100644
--- a/gslib/third_party/storage_apitools/storage_v1_client.py
+++ b/gslib/third_party/storage_apitools/storage_v1_client.py
@@ -82,81 +82,6 @@ class StorageV1(base_api.BaseApiClient):
 
     def __init__(self, client):
       super(StorageV1.BucketAccessControlsService, self).__init__(client)
-      self._method_configs = {
-          'Delete': base_api.ApiMethodInfo(
-              http_method=u'DELETE',
-              method_id=u'storage.bucketAccessControls.delete',
-              ordered_params=[u'bucket', u'entity'],
-              path_params=[u'bucket', u'entity'],
-              query_params=[],
-              relative_path=u'b/{bucket}/acl/{entity}',
-              request_field='',
-              request_type_name=u'StorageBucketAccessControlsDeleteRequest',
-              response_type_name=u'StorageBucketAccessControlsDeleteResponse',
-              supports_download=False,
-          ),
-          'Get': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.bucketAccessControls.get',
-              ordered_params=[u'bucket', u'entity'],
-              path_params=[u'bucket', u'entity'],
-              query_params=[],
-              relative_path=u'b/{bucket}/acl/{entity}',
-              request_field='',
-              request_type_name=u'StorageBucketAccessControlsGetRequest',
-              response_type_name=u'BucketAccessControl',
-              supports_download=False,
-          ),
-          'Insert': base_api.ApiMethodInfo(
-              http_method=u'POST',
-              method_id=u'storage.bucketAccessControls.insert',
-              ordered_params=[u'bucket'],
-              path_params=[u'bucket'],
-              query_params=[],
-              relative_path=u'b/{bucket}/acl',
-              request_field='<request>',
-              request_type_name=u'BucketAccessControl',
-              response_type_name=u'BucketAccessControl',
-              supports_download=False,
-          ),
-          'List': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.bucketAccessControls.list',
-              ordered_params=[u'bucket'],
-              path_params=[u'bucket'],
-              query_params=[],
-              relative_path=u'b/{bucket}/acl',
-              request_field='',
-              request_type_name=u'StorageBucketAccessControlsListRequest',
-              response_type_name=u'BucketAccessControls',
-              supports_download=False,
-          ),
-          'Patch': base_api.ApiMethodInfo(
-              http_method=u'PATCH',
-              method_id=u'storage.bucketAccessControls.patch',
-              ordered_params=[u'bucket', u'entity'],
-              path_params=[u'bucket', u'entity'],
-              query_params=[],
-              relative_path=u'b/{bucket}/acl/{entity}',
-              request_field='<request>',
-              request_type_name=u'BucketAccessControl',
-              response_type_name=u'BucketAccessControl',
-              supports_download=False,
-          ),
-          'Update': base_api.ApiMethodInfo(
-              http_method=u'PUT',
-              method_id=u'storage.bucketAccessControls.update',
-              ordered_params=[u'bucket', u'entity'],
-              path_params=[u'bucket', u'entity'],
-              query_params=[],
-              relative_path=u'b/{bucket}/acl/{entity}',
-              request_field='<request>',
-              request_type_name=u'BucketAccessControl',
-              response_type_name=u'BucketAccessControl',
-              supports_download=False,
-          ),
-          }
-
       self._upload_configs = {
           }
 
@@ -173,6 +98,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Delete.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'DELETE',
+        method_id=u'storage.bucketAccessControls.delete',
+        ordered_params=[u'bucket', u'entity'],
+        path_params=[u'bucket', u'entity'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/acl/{entity}',
+        request_field='',
+        request_type_name=u'StorageBucketAccessControlsDeleteRequest',
+        response_type_name=u'StorageBucketAccessControlsDeleteResponse',
+        supports_download=False,
+    )
+
     def Get(self, request, global_params=None):
       """Returns the ACL entry for the specified entity on the specified bucket.
 
@@ -186,11 +124,24 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Get.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.bucketAccessControls.get',
+        ordered_params=[u'bucket', u'entity'],
+        path_params=[u'bucket', u'entity'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/acl/{entity}',
+        request_field='',
+        request_type_name=u'StorageBucketAccessControlsGetRequest',
+        response_type_name=u'BucketAccessControl',
+        supports_download=False,
+    )
+
     def Insert(self, request, global_params=None):
       """Creates a new ACL entry on the specified bucket.
 
       Args:
-        request: (BucketAccessControl) input message
+        request: (StorageBucketAccessControlsInsertRequest) input message
         global_params: (StandardQueryParameters, default: None) global arguments
       Returns:
         (BucketAccessControl) The response message.
@@ -199,6 +150,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Insert.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'POST',
+        method_id=u'storage.bucketAccessControls.insert',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/acl',
+        request_field=u'bucketAccessControl',
+        request_type_name=u'StorageBucketAccessControlsInsertRequest',
+        response_type_name=u'BucketAccessControl',
+        supports_download=False,
+    )
+
     def List(self, request, global_params=None):
       """Retrieves ACL entries on the specified bucket.
 
@@ -212,11 +176,24 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    List.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.bucketAccessControls.list',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/acl',
+        request_field='',
+        request_type_name=u'StorageBucketAccessControlsListRequest',
+        response_type_name=u'BucketAccessControls',
+        supports_download=False,
+    )
+
     def Patch(self, request, global_params=None):
       """Updates an ACL entry on the specified bucket. This method supports patch semantics.
 
       Args:
-        request: (BucketAccessControl) input message
+        request: (StorageBucketAccessControlsPatchRequest) input message
         global_params: (StandardQueryParameters, default: None) global arguments
       Returns:
         (BucketAccessControl) The response message.
@@ -225,11 +202,24 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Patch.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'PATCH',
+        method_id=u'storage.bucketAccessControls.patch',
+        ordered_params=[u'bucket', u'entity'],
+        path_params=[u'bucket', u'entity'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/acl/{entity}',
+        request_field=u'bucketAccessControl',
+        request_type_name=u'StorageBucketAccessControlsPatchRequest',
+        response_type_name=u'BucketAccessControl',
+        supports_download=False,
+    )
+
     def Update(self, request, global_params=None):
       """Updates an ACL entry on the specified bucket.
 
       Args:
-        request: (BucketAccessControl) input message
+        request: (StorageBucketAccessControlsUpdateRequest) input message
         global_params: (StandardQueryParameters, default: None) global arguments
       Returns:
         (BucketAccessControl) The response message.
@@ -238,6 +228,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Update.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'PUT',
+        method_id=u'storage.bucketAccessControls.update',
+        ordered_params=[u'bucket', u'entity'],
+        path_params=[u'bucket', u'entity'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/acl/{entity}',
+        request_field=u'bucketAccessControl',
+        request_type_name=u'StorageBucketAccessControlsUpdateRequest',
+        response_type_name=u'BucketAccessControl',
+        supports_download=False,
+    )
+
   class BucketsService(base_api.BaseApiService):
     """Service class for the buckets resource."""
 
@@ -245,117 +248,6 @@ class StorageV1(base_api.BaseApiClient):
 
     def __init__(self, client):
       super(StorageV1.BucketsService, self).__init__(client)
-      self._method_configs = {
-          'Delete': base_api.ApiMethodInfo(
-              http_method=u'DELETE',
-              method_id=u'storage.buckets.delete',
-              ordered_params=[u'bucket'],
-              path_params=[u'bucket'],
-              query_params=[u'ifMetagenerationMatch', u'ifMetagenerationNotMatch'],
-              relative_path=u'b/{bucket}',
-              request_field='',
-              request_type_name=u'StorageBucketsDeleteRequest',
-              response_type_name=u'StorageBucketsDeleteResponse',
-              supports_download=False,
-          ),
-          'Get': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.buckets.get',
-              ordered_params=[u'bucket'],
-              path_params=[u'bucket'],
-              query_params=[u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'projection'],
-              relative_path=u'b/{bucket}',
-              request_field='',
-              request_type_name=u'StorageBucketsGetRequest',
-              response_type_name=u'Bucket',
-              supports_download=False,
-          ),
-          'GetIamPolicy': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.buckets.getIamPolicy',
-              ordered_params=[u'bucket'],
-              path_params=[u'bucket'],
-              query_params=[],
-              relative_path=u'b/{bucket}/iam',
-              request_field='',
-              request_type_name=u'StorageBucketsGetIamPolicyRequest',
-              response_type_name=u'Policy',
-              supports_download=False,
-          ),
-          'Insert': base_api.ApiMethodInfo(
-              http_method=u'POST',
-              method_id=u'storage.buckets.insert',
-              ordered_params=[u'project'],
-              path_params=[],
-              query_params=[u'predefinedAcl', u'predefinedDefaultObjectAcl', u'project', u'projection'],
-              relative_path=u'b',
-              request_field=u'bucket',
-              request_type_name=u'StorageBucketsInsertRequest',
-              response_type_name=u'Bucket',
-              supports_download=False,
-          ),
-          'List': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.buckets.list',
-              ordered_params=[u'project'],
-              path_params=[],
-              query_params=[u'maxResults', u'pageToken', u'prefix', u'project', u'projection'],
-              relative_path=u'b',
-              request_field='',
-              request_type_name=u'StorageBucketsListRequest',
-              response_type_name=u'Buckets',
-              supports_download=False,
-          ),
-          'Patch': base_api.ApiMethodInfo(
-              http_method=u'PATCH',
-              method_id=u'storage.buckets.patch',
-              ordered_params=[u'bucket'],
-              path_params=[u'bucket'],
-              query_params=[u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'predefinedAcl', u'predefinedDefaultObjectAcl', u'projection'],
-              relative_path=u'b/{bucket}',
-              request_field=u'bucketResource',
-              request_type_name=u'StorageBucketsPatchRequest',
-              response_type_name=u'Bucket',
-              supports_download=False,
-          ),
-          'SetIamPolicy': base_api.ApiMethodInfo(
-              http_method=u'PUT',
-              method_id=u'storage.buckets.setIamPolicy',
-              ordered_params=[u'bucket'],
-              path_params=[u'bucket'],
-              query_params=[],
-              relative_path=u'b/{bucket}/iam',
-              request_field=u'policy',
-              request_type_name=u'StorageBucketsSetIamPolicyRequest',
-              response_type_name=u'Policy',
-              supports_download=False,
-          ),
-          'TestIamPermissions': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.buckets.testIamPermissions',
-              ordered_params=[u'bucket', u'permissions'],
-              path_params=[u'bucket'],
-              query_params=[u'permissions'],
-              relative_path=u'b/{bucket}/iam/testPermissions',
-              request_field='',
-              request_type_name=u'StorageBucketsTestIamPermissionsRequest',
-              response_type_name=u'TestIamPermissionsResponse',
-              supports_download=False,
-          ),
-          'Update': base_api.ApiMethodInfo(
-              http_method=u'PUT',
-              method_id=u'storage.buckets.update',
-              ordered_params=[u'bucket'],
-              path_params=[u'bucket'],
-              query_params=[u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'predefinedAcl', u'predefinedDefaultObjectAcl', u'projection'],
-              relative_path=u'b/{bucket}',
-              request_field=u'bucketResource',
-              request_type_name=u'StorageBucketsUpdateRequest',
-              response_type_name=u'Bucket',
-              supports_download=False,
-          ),
-          }
-
       self._upload_configs = {
           }
 
@@ -372,6 +264,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Delete.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'DELETE',
+        method_id=u'storage.buckets.delete',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'userProject'],
+        relative_path=u'b/{bucket}',
+        request_field='',
+        request_type_name=u'StorageBucketsDeleteRequest',
+        response_type_name=u'StorageBucketsDeleteResponse',
+        supports_download=False,
+    )
+
     def Get(self, request, global_params=None):
       """Returns metadata for the specified bucket.
 
@@ -385,6 +290,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Get.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.buckets.get',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'projection', u'userProject'],
+        relative_path=u'b/{bucket}',
+        request_field='',
+        request_type_name=u'StorageBucketsGetRequest',
+        response_type_name=u'Bucket',
+        supports_download=False,
+    )
+
     def GetIamPolicy(self, request, global_params=None):
       """Returns an IAM policy for the specified bucket.
 
@@ -398,6 +316,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    GetIamPolicy.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.buckets.getIamPolicy',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/iam',
+        request_field='',
+        request_type_name=u'StorageBucketsGetIamPolicyRequest',
+        response_type_name=u'Policy',
+        supports_download=False,
+    )
+
     def Insert(self, request, global_params=None):
       """Creates a new bucket.
 
@@ -411,6 +342,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Insert.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'POST',
+        method_id=u'storage.buckets.insert',
+        ordered_params=[u'project'],
+        path_params=[],
+        query_params=[u'predefinedAcl', u'predefinedDefaultObjectAcl', u'project', u'projection', u'userProject'],
+        relative_path=u'b',
+        request_field=u'bucket',
+        request_type_name=u'StorageBucketsInsertRequest',
+        response_type_name=u'Bucket',
+        supports_download=False,
+    )
+
     def List(self, request, global_params=None):
       """Retrieves a list of buckets for a given project.
 
@@ -424,8 +368,21 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    List.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.buckets.list',
+        ordered_params=[u'project'],
+        path_params=[],
+        query_params=[u'maxResults', u'pageToken', u'prefix', u'project', u'projection', u'userProject'],
+        relative_path=u'b',
+        request_field='',
+        request_type_name=u'StorageBucketsListRequest',
+        response_type_name=u'Buckets',
+        supports_download=False,
+    )
+
     def Patch(self, request, global_params=None):
-      """Updates a bucket. This method supports patch semantics.
+      """Updates a bucket. Changes to the bucket will be readable immediately after writing, but configuration changes may take time to propagate. This method supports patch semantics.
 
       Args:
         request: (StorageBucketsPatchRequest) input message
@@ -437,6 +394,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Patch.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'PATCH',
+        method_id=u'storage.buckets.patch',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'predefinedAcl', u'predefinedDefaultObjectAcl', u'projection', u'userProject'],
+        relative_path=u'b/{bucket}',
+        request_field=u'bucketResource',
+        request_type_name=u'StorageBucketsPatchRequest',
+        response_type_name=u'Bucket',
+        supports_download=False,
+    )
+
     def SetIamPolicy(self, request, global_params=None):
       """Updates an IAM policy for the specified bucket.
 
@@ -450,6 +420,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    SetIamPolicy.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'PUT',
+        method_id=u'storage.buckets.setIamPolicy',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/iam',
+        request_field=u'policy',
+        request_type_name=u'StorageBucketsSetIamPolicyRequest',
+        response_type_name=u'Policy',
+        supports_download=False,
+    )
+
     def TestIamPermissions(self, request, global_params=None):
       """Tests a set of permissions on the given bucket to see which, if any, are held by the caller.
 
@@ -463,8 +446,21 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    TestIamPermissions.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.buckets.testIamPermissions',
+        ordered_params=[u'bucket', u'permissions'],
+        path_params=[u'bucket'],
+        query_params=[u'permissions', u'userProject'],
+        relative_path=u'b/{bucket}/iam/testPermissions',
+        request_field='',
+        request_type_name=u'StorageBucketsTestIamPermissionsRequest',
+        response_type_name=u'TestIamPermissionsResponse',
+        supports_download=False,
+    )
+
     def Update(self, request, global_params=None):
-      """Updates a bucket.
+      """Updates a bucket. Changes to the bucket will be readable immediately after writing, but configuration changes may take time to propagate.
 
       Args:
         request: (StorageBucketsUpdateRequest) input message
@@ -476,6 +472,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Update.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'PUT',
+        method_id=u'storage.buckets.update',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'predefinedAcl', u'predefinedDefaultObjectAcl', u'projection', u'userProject'],
+        relative_path=u'b/{bucket}',
+        request_field=u'bucketResource',
+        request_type_name=u'StorageBucketsUpdateRequest',
+        response_type_name=u'Bucket',
+        supports_download=False,
+    )
+
   class ChannelsService(base_api.BaseApiService):
     """Service class for the channels resource."""
 
@@ -483,21 +492,6 @@ class StorageV1(base_api.BaseApiClient):
 
     def __init__(self, client):
       super(StorageV1.ChannelsService, self).__init__(client)
-      self._method_configs = {
-          'Stop': base_api.ApiMethodInfo(
-              http_method=u'POST',
-              method_id=u'storage.channels.stop',
-              ordered_params=[],
-              path_params=[],
-              query_params=[],
-              relative_path=u'channels/stop',
-              request_field='<request>',
-              request_type_name=u'Channel',
-              response_type_name=u'StorageChannelsStopResponse',
-              supports_download=False,
-          ),
-          }
-
       self._upload_configs = {
           }
 
@@ -514,6 +508,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Stop.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'POST',
+        method_id=u'storage.channels.stop',
+        ordered_params=[],
+        path_params=[],
+        query_params=[],
+        relative_path=u'channels/stop',
+        request_field='<request>',
+        request_type_name=u'Channel',
+        response_type_name=u'StorageChannelsStopResponse',
+        supports_download=False,
+    )
+
   class DefaultObjectAccessControlsService(base_api.BaseApiService):
     """Service class for the defaultObjectAccessControls resource."""
 
@@ -521,81 +528,6 @@ class StorageV1(base_api.BaseApiClient):
 
     def __init__(self, client):
       super(StorageV1.DefaultObjectAccessControlsService, self).__init__(client)
-      self._method_configs = {
-          'Delete': base_api.ApiMethodInfo(
-              http_method=u'DELETE',
-              method_id=u'storage.defaultObjectAccessControls.delete',
-              ordered_params=[u'bucket', u'entity'],
-              path_params=[u'bucket', u'entity'],
-              query_params=[],
-              relative_path=u'b/{bucket}/defaultObjectAcl/{entity}',
-              request_field='',
-              request_type_name=u'StorageDefaultObjectAccessControlsDeleteRequest',
-              response_type_name=u'StorageDefaultObjectAccessControlsDeleteResponse',
-              supports_download=False,
-          ),
-          'Get': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.defaultObjectAccessControls.get',
-              ordered_params=[u'bucket', u'entity'],
-              path_params=[u'bucket', u'entity'],
-              query_params=[],
-              relative_path=u'b/{bucket}/defaultObjectAcl/{entity}',
-              request_field='',
-              request_type_name=u'StorageDefaultObjectAccessControlsGetRequest',
-              response_type_name=u'ObjectAccessControl',
-              supports_download=False,
-          ),
-          'Insert': base_api.ApiMethodInfo(
-              http_method=u'POST',
-              method_id=u'storage.defaultObjectAccessControls.insert',
-              ordered_params=[u'bucket'],
-              path_params=[u'bucket'],
-              query_params=[],
-              relative_path=u'b/{bucket}/defaultObjectAcl',
-              request_field='<request>',
-              request_type_name=u'ObjectAccessControl',
-              response_type_name=u'ObjectAccessControl',
-              supports_download=False,
-          ),
-          'List': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.defaultObjectAccessControls.list',
-              ordered_params=[u'bucket'],
-              path_params=[u'bucket'],
-              query_params=[u'ifMetagenerationMatch', u'ifMetagenerationNotMatch'],
-              relative_path=u'b/{bucket}/defaultObjectAcl',
-              request_field='',
-              request_type_name=u'StorageDefaultObjectAccessControlsListRequest',
-              response_type_name=u'ObjectAccessControls',
-              supports_download=False,
-          ),
-          'Patch': base_api.ApiMethodInfo(
-              http_method=u'PATCH',
-              method_id=u'storage.defaultObjectAccessControls.patch',
-              ordered_params=[u'bucket', u'entity'],
-              path_params=[u'bucket', u'entity'],
-              query_params=[],
-              relative_path=u'b/{bucket}/defaultObjectAcl/{entity}',
-              request_field='<request>',
-              request_type_name=u'ObjectAccessControl',
-              response_type_name=u'ObjectAccessControl',
-              supports_download=False,
-          ),
-          'Update': base_api.ApiMethodInfo(
-              http_method=u'PUT',
-              method_id=u'storage.defaultObjectAccessControls.update',
-              ordered_params=[u'bucket', u'entity'],
-              path_params=[u'bucket', u'entity'],
-              query_params=[],
-              relative_path=u'b/{bucket}/defaultObjectAcl/{entity}',
-              request_field='<request>',
-              request_type_name=u'ObjectAccessControl',
-              response_type_name=u'ObjectAccessControl',
-              supports_download=False,
-          ),
-          }
-
       self._upload_configs = {
           }
 
@@ -612,6 +544,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Delete.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'DELETE',
+        method_id=u'storage.defaultObjectAccessControls.delete',
+        ordered_params=[u'bucket', u'entity'],
+        path_params=[u'bucket', u'entity'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/defaultObjectAcl/{entity}',
+        request_field='',
+        request_type_name=u'StorageDefaultObjectAccessControlsDeleteRequest',
+        response_type_name=u'StorageDefaultObjectAccessControlsDeleteResponse',
+        supports_download=False,
+    )
+
     def Get(self, request, global_params=None):
       """Returns the default object ACL entry for the specified entity on the specified bucket.
 
@@ -625,11 +570,24 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Get.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.defaultObjectAccessControls.get',
+        ordered_params=[u'bucket', u'entity'],
+        path_params=[u'bucket', u'entity'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/defaultObjectAcl/{entity}',
+        request_field='',
+        request_type_name=u'StorageDefaultObjectAccessControlsGetRequest',
+        response_type_name=u'ObjectAccessControl',
+        supports_download=False,
+    )
+
     def Insert(self, request, global_params=None):
       """Creates a new default object ACL entry on the specified bucket.
 
       Args:
-        request: (ObjectAccessControl) input message
+        request: (StorageDefaultObjectAccessControlsInsertRequest) input message
         global_params: (StandardQueryParameters, default: None) global arguments
       Returns:
         (ObjectAccessControl) The response message.
@@ -638,6 +596,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Insert.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'POST',
+        method_id=u'storage.defaultObjectAccessControls.insert',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/defaultObjectAcl',
+        request_field=u'objectAccessControl',
+        request_type_name=u'StorageDefaultObjectAccessControlsInsertRequest',
+        response_type_name=u'ObjectAccessControl',
+        supports_download=False,
+    )
+
     def List(self, request, global_params=None):
       """Retrieves default object ACL entries on the specified bucket.
 
@@ -651,11 +622,24 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    List.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.defaultObjectAccessControls.list',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'userProject'],
+        relative_path=u'b/{bucket}/defaultObjectAcl',
+        request_field='',
+        request_type_name=u'StorageDefaultObjectAccessControlsListRequest',
+        response_type_name=u'ObjectAccessControls',
+        supports_download=False,
+    )
+
     def Patch(self, request, global_params=None):
       """Updates a default object ACL entry on the specified bucket. This method supports patch semantics.
 
       Args:
-        request: (ObjectAccessControl) input message
+        request: (StorageDefaultObjectAccessControlsPatchRequest) input message
         global_params: (StandardQueryParameters, default: None) global arguments
       Returns:
         (ObjectAccessControl) The response message.
@@ -664,11 +648,24 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Patch.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'PATCH',
+        method_id=u'storage.defaultObjectAccessControls.patch',
+        ordered_params=[u'bucket', u'entity'],
+        path_params=[u'bucket', u'entity'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/defaultObjectAcl/{entity}',
+        request_field=u'objectAccessControl',
+        request_type_name=u'StorageDefaultObjectAccessControlsPatchRequest',
+        response_type_name=u'ObjectAccessControl',
+        supports_download=False,
+    )
+
     def Update(self, request, global_params=None):
       """Updates a default object ACL entry on the specified bucket.
 
       Args:
-        request: (ObjectAccessControl) input message
+        request: (StorageDefaultObjectAccessControlsUpdateRequest) input message
         global_params: (StandardQueryParameters, default: None) global arguments
       Returns:
         (ObjectAccessControl) The response message.
@@ -677,6 +674,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Update.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'PUT',
+        method_id=u'storage.defaultObjectAccessControls.update',
+        ordered_params=[u'bucket', u'entity'],
+        path_params=[u'bucket', u'entity'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/defaultObjectAcl/{entity}',
+        request_field=u'objectAccessControl',
+        request_type_name=u'StorageDefaultObjectAccessControlsUpdateRequest',
+        response_type_name=u'ObjectAccessControl',
+        supports_download=False,
+    )
+
   class NotificationsService(base_api.BaseApiService):
     """Service class for the notifications resource."""
 
@@ -686,55 +696,6 @@ class StorageV1(base_api.BaseApiClient):
       super(StorageV1.NotificationsService, self).__init__(client)
       self._upload_configs = {
           }
-      self._method_configs = {
-          'Delete': base_api.ApiMethodInfo(
-               http_method=u'DELETE',
-               method_id=u'storage.notifications.delete',
-               ordered_params=[u'bucket', u'notification'],
-               path_params=[u'bucket', u'notification'],
-               query_params=[u'requesterPaysBillingProjectId'],
-               relative_path=u'b/{bucket}/notificationConfigs/{notification}',
-               request_field='',
-               request_type_name=u'StorageNotificationsDeleteRequest',
-               response_type_name=u'StorageNotificationsDeleteResponse',
-               supports_download=False,
-          ),
-          'Get': base_api.ApiMethodInfo(
-             http_method=u'GET',
-             method_id=u'storage.notifications.get',
-             ordered_params=[u'bucket', u'notification'],
-             path_params=[u'bucket', u'notification'],
-             query_params=[u'requesterPaysBillingProjectId'],
-             relative_path=u'b/{bucket}/notificationConfigs/{notification}',
-             request_field='',
-             request_type_name=u'StorageNotificationsGetRequest',
-             response_type_name=u'Notification',
-             supports_download=False,
-          ),
-          'Insert': base_api.ApiMethodInfo(
-             http_method=u'POST',
-             method_id=u'storage.notifications.insert',
-             ordered_params=[u'bucket'],
-             path_params=[u'bucket'],
-             query_params=[u'requesterPaysBillingProjectId'],
-             relative_path=u'b/{bucket}/notificationConfigs',
-             request_field=u'notification',
-             request_type_name=u'StorageNotificationsInsertRequest',
-             response_type_name=u'Notification',
-             supports_download=False,
-         ),
-         'List': base_api.ApiMethodInfo(
-             http_method=u'GET',
-             method_id=u'storage.notifications.list',
-             ordered_params=[u'bucket'],
-             path_params=[u'bucket'],
-             query_params=[u'requesterPaysBillingProjectId'],
-             relative_path=u'b/{bucket}/notificationConfigs',
-             request_field='',
-             request_type_name=u'StorageNotificationsListRequest',
-             response_type_name=u'Notifications',
-             supports_download=False,
-         )}
 
     def Delete(self, request, global_params=None):
       """Permanently deletes a notification subscription.
@@ -749,6 +710,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Delete.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'DELETE',
+        method_id=u'storage.notifications.delete',
+        ordered_params=[u'bucket', u'notification'],
+        path_params=[u'bucket', u'notification'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/notificationConfigs/{notification}',
+        request_field='',
+        request_type_name=u'StorageNotificationsDeleteRequest',
+        response_type_name=u'StorageNotificationsDeleteResponse',
+        supports_download=False,
+    )
+
     def Get(self, request, global_params=None):
       """View a notification configuration.
 
@@ -762,6 +736,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Get.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.notifications.get',
+        ordered_params=[u'bucket', u'notification'],
+        path_params=[u'bucket', u'notification'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/notificationConfigs/{notification}',
+        request_field='',
+        request_type_name=u'StorageNotificationsGetRequest',
+        response_type_name=u'Notification',
+        supports_download=False,
+    )
+
     def Insert(self, request, global_params=None):
       """Creates a notification subscription for a given bucket.
 
@@ -775,6 +762,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Insert.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'POST',
+        method_id=u'storage.notifications.insert',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/notificationConfigs',
+        request_field=u'notification',
+        request_type_name=u'StorageNotificationsInsertRequest',
+        response_type_name=u'Notification',
+        supports_download=False,
+    )
+
     def List(self, request, global_params=None):
       """Retrieves a list of notification subscriptions for a given bucket.
 
@@ -788,6 +788,18 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    List.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.notifications.list',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'userProject'],
+        relative_path=u'b/{bucket}/notificationConfigs',
+        request_field='',
+        request_type_name=u'StorageNotificationsListRequest',
+        response_type_name=u'Notifications',
+        supports_download=False,
+    )
 
   class ObjectAccessControlsService(base_api.BaseApiService):
     """Service class for the objectAccessControls resource."""
@@ -796,81 +808,6 @@ class StorageV1(base_api.BaseApiClient):
 
     def __init__(self, client):
       super(StorageV1.ObjectAccessControlsService, self).__init__(client)
-      self._method_configs = {
-          'Delete': base_api.ApiMethodInfo(
-              http_method=u'DELETE',
-              method_id=u'storage.objectAccessControls.delete',
-              ordered_params=[u'bucket', u'object', u'entity'],
-              path_params=[u'bucket', u'entity', u'object'],
-              query_params=[u'generation'],
-              relative_path=u'b/{bucket}/o/{object}/acl/{entity}',
-              request_field='',
-              request_type_name=u'StorageObjectAccessControlsDeleteRequest',
-              response_type_name=u'StorageObjectAccessControlsDeleteResponse',
-              supports_download=False,
-          ),
-          'Get': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.objectAccessControls.get',
-              ordered_params=[u'bucket', u'object', u'entity'],
-              path_params=[u'bucket', u'entity', u'object'],
-              query_params=[u'generation'],
-              relative_path=u'b/{bucket}/o/{object}/acl/{entity}',
-              request_field='',
-              request_type_name=u'StorageObjectAccessControlsGetRequest',
-              response_type_name=u'ObjectAccessControl',
-              supports_download=False,
-          ),
-          'Insert': base_api.ApiMethodInfo(
-              http_method=u'POST',
-              method_id=u'storage.objectAccessControls.insert',
-              ordered_params=[u'bucket', u'object'],
-              path_params=[u'bucket', u'object'],
-              query_params=[u'generation'],
-              relative_path=u'b/{bucket}/o/{object}/acl',
-              request_field=u'objectAccessControl',
-              request_type_name=u'StorageObjectAccessControlsInsertRequest',
-              response_type_name=u'ObjectAccessControl',
-              supports_download=False,
-          ),
-          'List': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.objectAccessControls.list',
-              ordered_params=[u'bucket', u'object'],
-              path_params=[u'bucket', u'object'],
-              query_params=[u'generation'],
-              relative_path=u'b/{bucket}/o/{object}/acl',
-              request_field='',
-              request_type_name=u'StorageObjectAccessControlsListRequest',
-              response_type_name=u'ObjectAccessControls',
-              supports_download=False,
-          ),
-          'Patch': base_api.ApiMethodInfo(
-              http_method=u'PATCH',
-              method_id=u'storage.objectAccessControls.patch',
-              ordered_params=[u'bucket', u'object', u'entity'],
-              path_params=[u'bucket', u'entity', u'object'],
-              query_params=[u'generation'],
-              relative_path=u'b/{bucket}/o/{object}/acl/{entity}',
-              request_field=u'objectAccessControl',
-              request_type_name=u'StorageObjectAccessControlsPatchRequest',
-              response_type_name=u'ObjectAccessControl',
-              supports_download=False,
-          ),
-          'Update': base_api.ApiMethodInfo(
-              http_method=u'PUT',
-              method_id=u'storage.objectAccessControls.update',
-              ordered_params=[u'bucket', u'object', u'entity'],
-              path_params=[u'bucket', u'entity', u'object'],
-              query_params=[u'generation'],
-              relative_path=u'b/{bucket}/o/{object}/acl/{entity}',
-              request_field=u'objectAccessControl',
-              request_type_name=u'StorageObjectAccessControlsUpdateRequest',
-              response_type_name=u'ObjectAccessControl',
-              supports_download=False,
-          ),
-          }
-
       self._upload_configs = {
           }
 
@@ -887,6 +824,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Delete.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'DELETE',
+        method_id=u'storage.objectAccessControls.delete',
+        ordered_params=[u'bucket', u'object', u'entity'],
+        path_params=[u'bucket', u'entity', u'object'],
+        query_params=[u'generation', u'userProject'],
+        relative_path=u'b/{bucket}/o/{object}/acl/{entity}',
+        request_field='',
+        request_type_name=u'StorageObjectAccessControlsDeleteRequest',
+        response_type_name=u'StorageObjectAccessControlsDeleteResponse',
+        supports_download=False,
+    )
+
     def Get(self, request, global_params=None):
       """Returns the ACL entry for the specified entity on the specified object.
 
@@ -900,6 +850,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Get.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.objectAccessControls.get',
+        ordered_params=[u'bucket', u'object', u'entity'],
+        path_params=[u'bucket', u'entity', u'object'],
+        query_params=[u'generation', u'userProject'],
+        relative_path=u'b/{bucket}/o/{object}/acl/{entity}',
+        request_field='',
+        request_type_name=u'StorageObjectAccessControlsGetRequest',
+        response_type_name=u'ObjectAccessControl',
+        supports_download=False,
+    )
+
     def Insert(self, request, global_params=None):
       """Creates a new ACL entry on the specified object.
 
@@ -913,6 +876,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Insert.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'POST',
+        method_id=u'storage.objectAccessControls.insert',
+        ordered_params=[u'bucket', u'object'],
+        path_params=[u'bucket', u'object'],
+        query_params=[u'generation', u'userProject'],
+        relative_path=u'b/{bucket}/o/{object}/acl',
+        request_field=u'objectAccessControl',
+        request_type_name=u'StorageObjectAccessControlsInsertRequest',
+        response_type_name=u'ObjectAccessControl',
+        supports_download=False,
+    )
+
     def List(self, request, global_params=None):
       """Retrieves ACL entries on the specified object.
 
@@ -926,6 +902,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    List.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.objectAccessControls.list',
+        ordered_params=[u'bucket', u'object'],
+        path_params=[u'bucket', u'object'],
+        query_params=[u'generation', u'userProject'],
+        relative_path=u'b/{bucket}/o/{object}/acl',
+        request_field='',
+        request_type_name=u'StorageObjectAccessControlsListRequest',
+        response_type_name=u'ObjectAccessControls',
+        supports_download=False,
+    )
+
     def Patch(self, request, global_params=None):
       """Updates an ACL entry on the specified object. This method supports patch semantics.
 
@@ -939,6 +928,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Patch.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'PATCH',
+        method_id=u'storage.objectAccessControls.patch',
+        ordered_params=[u'bucket', u'object', u'entity'],
+        path_params=[u'bucket', u'entity', u'object'],
+        query_params=[u'generation', u'userProject'],
+        relative_path=u'b/{bucket}/o/{object}/acl/{entity}',
+        request_field=u'objectAccessControl',
+        request_type_name=u'StorageObjectAccessControlsPatchRequest',
+        response_type_name=u'ObjectAccessControl',
+        supports_download=False,
+    )
+
     def Update(self, request, global_params=None):
       """Updates an ACL entry on the specified object.
 
@@ -952,6 +954,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Update.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'PUT',
+        method_id=u'storage.objectAccessControls.update',
+        ordered_params=[u'bucket', u'object', u'entity'],
+        path_params=[u'bucket', u'entity', u'object'],
+        query_params=[u'generation', u'userProject'],
+        relative_path=u'b/{bucket}/o/{object}/acl/{entity}',
+        request_field=u'objectAccessControl',
+        request_type_name=u'StorageObjectAccessControlsUpdateRequest',
+        response_type_name=u'ObjectAccessControl',
+        supports_download=False,
+    )
+
   class ObjectsService(base_api.BaseApiService):
     """Service class for the objects resource."""
 
@@ -959,165 +974,6 @@ class StorageV1(base_api.BaseApiClient):
 
     def __init__(self, client):
       super(StorageV1.ObjectsService, self).__init__(client)
-      self._method_configs = {
-          'Compose': base_api.ApiMethodInfo(
-              http_method=u'POST',
-              method_id=u'storage.objects.compose',
-              ordered_params=[u'destinationBucket', u'destinationObject'],
-              path_params=[u'destinationBucket', u'destinationObject'],
-              query_params=[u'destinationPredefinedAcl', u'ifGenerationMatch', u'ifMetagenerationMatch'],
-              relative_path=u'b/{destinationBucket}/o/{destinationObject}/compose',
-              request_field=u'composeRequest',
-              request_type_name=u'StorageObjectsComposeRequest',
-              response_type_name=u'Object',
-              supports_download=True,
-          ),
-          'Copy': base_api.ApiMethodInfo(
-              http_method=u'POST',
-              method_id=u'storage.objects.copy',
-              ordered_params=[u'sourceBucket', u'sourceObject', u'destinationBucket', u'destinationObject'],
-              path_params=[u'destinationBucket', u'destinationObject', u'sourceBucket', u'sourceObject'],
-              query_params=[u'destinationPredefinedAcl', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'ifSourceGenerationMatch', u'ifSourceGenerationNotMatch', u'ifSourceMetagenerationMatch', u'ifSourceMetagenerationNotMatch', u'projection', u'sourceGeneration'],
-              relative_path=u'b/{sourceBucket}/o/{sourceObject}/copyTo/b/{destinationBucket}/o/{destinationObject}',
-              request_field=u'object',
-              request_type_name=u'StorageObjectsCopyRequest',
-              response_type_name=u'Object',
-              supports_download=True,
-          ),
-          'Delete': base_api.ApiMethodInfo(
-              http_method=u'DELETE',
-              method_id=u'storage.objects.delete',
-              ordered_params=[u'bucket', u'object'],
-              path_params=[u'bucket', u'object'],
-              query_params=[u'generation', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch'],
-              relative_path=u'b/{bucket}/o/{object}',
-              request_field='',
-              request_type_name=u'StorageObjectsDeleteRequest',
-              response_type_name=u'StorageObjectsDeleteResponse',
-              supports_download=False,
-          ),
-          'Get': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.objects.get',
-              ordered_params=[u'bucket', u'object'],
-              path_params=[u'bucket', u'object'],
-              query_params=[u'generation', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'projection'],
-              relative_path=u'b/{bucket}/o/{object}',
-              request_field='',
-              request_type_name=u'StorageObjectsGetRequest',
-              response_type_name=u'Object',
-              supports_download=True,
-          ),
-          'GetIamPolicy': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.objects.getIamPolicy',
-              ordered_params=[u'bucket', u'object'],
-              path_params=[u'bucket', u'object'],
-              query_params=[u'generation'],
-              relative_path=u'b/{bucket}/o/{object}/iam',
-              request_field='',
-              request_type_name=u'StorageObjectsGetIamPolicyRequest',
-              response_type_name=u'Policy',
-              supports_download=False,
-          ),
-          'Insert': base_api.ApiMethodInfo(
-              http_method=u'POST',
-              method_id=u'storage.objects.insert',
-              ordered_params=[u'bucket'],
-              path_params=[u'bucket'],
-              query_params=[u'contentEncoding', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'name', u'predefinedAcl', u'projection'],
-              relative_path=u'b/{bucket}/o',
-              request_field=u'object',
-              request_type_name=u'StorageObjectsInsertRequest',
-              response_type_name=u'Object',
-              supports_download=True,
-          ),
-          'List': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.objects.list',
-              ordered_params=[u'bucket'],
-              path_params=[u'bucket'],
-              query_params=[u'delimiter', u'maxResults', u'pageToken', u'prefix', u'projection', u'versions'],
-              relative_path=u'b/{bucket}/o',
-              request_field='',
-              request_type_name=u'StorageObjectsListRequest',
-              response_type_name=u'Objects',
-              supports_download=False,
-          ),
-          'Patch': base_api.ApiMethodInfo(
-              http_method=u'PATCH',
-              method_id=u'storage.objects.patch',
-              ordered_params=[u'bucket', u'object'],
-              path_params=[u'bucket', u'object'],
-              query_params=[u'generation', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'predefinedAcl', u'projection'],
-              relative_path=u'b/{bucket}/o/{object}',
-              request_field=u'objectResource',
-              request_type_name=u'StorageObjectsPatchRequest',
-              response_type_name=u'Object',
-              supports_download=False,
-          ),
-          'Rewrite': base_api.ApiMethodInfo(
-              http_method=u'POST',
-              method_id=u'storage.objects.rewrite',
-              ordered_params=[u'sourceBucket', u'sourceObject', u'destinationBucket', u'destinationObject'],
-              path_params=[u'destinationBucket', u'destinationObject', u'sourceBucket', u'sourceObject'],
-              query_params=[u'destinationPredefinedAcl', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'ifSourceGenerationMatch', u'ifSourceGenerationNotMatch', u'ifSourceMetagenerationMatch', u'ifSourceMetagenerationNotMatch', u'maxBytesRewrittenPerCall', u'projection', u'rewriteToken', u'sourceGeneration'],
-              relative_path=u'b/{sourceBucket}/o/{sourceObject}/rewriteTo/b/{destinationBucket}/o/{destinationObject}',
-              request_field=u'object',
-              request_type_name=u'StorageObjectsRewriteRequest',
-              response_type_name=u'RewriteResponse',
-              supports_download=False,
-          ),
-          'SetIamPolicy': base_api.ApiMethodInfo(
-              http_method=u'PUT',
-              method_id=u'storage.objects.setIamPolicy',
-              ordered_params=[u'bucket', u'object'],
-              path_params=[u'bucket', u'object'],
-              query_params=[u'generation'],
-              relative_path=u'b/{bucket}/o/{object}/iam',
-              request_field=u'policy',
-              request_type_name=u'StorageObjectsSetIamPolicyRequest',
-              response_type_name=u'Policy',
-              supports_download=False,
-          ),
-          'TestIamPermissions': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.objects.testIamPermissions',
-              ordered_params=[u'bucket', u'object', u'permissions'],
-              path_params=[u'bucket', u'object'],
-              query_params=[u'generation', u'permissions'],
-              relative_path=u'b/{bucket}/o/{object}/iam/testPermissions',
-              request_field='',
-              request_type_name=u'StorageObjectsTestIamPermissionsRequest',
-              response_type_name=u'TestIamPermissionsResponse',
-              supports_download=False,
-          ),
-          'Update': base_api.ApiMethodInfo(
-              http_method=u'PUT',
-              method_id=u'storage.objects.update',
-              ordered_params=[u'bucket', u'object'],
-              path_params=[u'bucket', u'object'],
-              query_params=[u'generation', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'predefinedAcl', u'projection'],
-              relative_path=u'b/{bucket}/o/{object}',
-              request_field=u'objectResource',
-              request_type_name=u'StorageObjectsUpdateRequest',
-              response_type_name=u'Object',
-              supports_download=True,
-          ),
-          'WatchAll': base_api.ApiMethodInfo(
-              http_method=u'POST',
-              method_id=u'storage.objects.watchAll',
-              ordered_params=[u'bucket'],
-              path_params=[u'bucket'],
-              query_params=[u'delimiter', u'maxResults', u'pageToken', u'prefix', u'projection', u'versions'],
-              relative_path=u'b/{bucket}/o/watch',
-              request_field=u'channel',
-              request_type_name=u'StorageObjectsWatchAllRequest',
-              response_type_name=u'Channel',
-              supports_download=False,
-          ),
-          }
-
       self._upload_configs = {
           'Insert': base_api.ApiUploadInfo(
               accept=['*/*'],
@@ -1145,6 +1001,19 @@ class StorageV1(base_api.BaseApiClient):
           config, request, global_params=global_params,
           download=download)
 
+    Compose.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'POST',
+        method_id=u'storage.objects.compose',
+        ordered_params=[u'destinationBucket', u'destinationObject'],
+        path_params=[u'destinationBucket', u'destinationObject'],
+        query_params=[u'destinationPredefinedAcl', u'ifGenerationMatch', u'ifMetagenerationMatch', u'userProject'],
+        relative_path=u'b/{destinationBucket}/o/{destinationObject}/compose',
+        request_field=u'composeRequest',
+        request_type_name=u'StorageObjectsComposeRequest',
+        response_type_name=u'Object',
+        supports_download=True,
+    )
+
     def Copy(self, request, global_params=None, download=None):
       """Copies a source object to a destination object. Optionally overrides metadata.
 
@@ -1161,6 +1030,19 @@ class StorageV1(base_api.BaseApiClient):
           config, request, global_params=global_params,
           download=download)
 
+    Copy.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'POST',
+        method_id=u'storage.objects.copy',
+        ordered_params=[u'sourceBucket', u'sourceObject', u'destinationBucket', u'destinationObject'],
+        path_params=[u'destinationBucket', u'destinationObject', u'sourceBucket', u'sourceObject'],
+        query_params=[u'destinationPredefinedAcl', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'ifSourceGenerationMatch', u'ifSourceGenerationNotMatch', u'ifSourceMetagenerationMatch', u'ifSourceMetagenerationNotMatch', u'projection', u'sourceGeneration', u'userProject'],
+        relative_path=u'b/{sourceBucket}/o/{sourceObject}/copyTo/b/{destinationBucket}/o/{destinationObject}',
+        request_field=u'object',
+        request_type_name=u'StorageObjectsCopyRequest',
+        response_type_name=u'Object',
+        supports_download=True,
+    )
+
     def Delete(self, request, global_params=None):
       """Deletes an object and its metadata. Deletions are permanent if versioning is not enabled for the bucket, or if the generation parameter is used.
 
@@ -1174,6 +1056,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Delete.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'DELETE',
+        method_id=u'storage.objects.delete',
+        ordered_params=[u'bucket', u'object'],
+        path_params=[u'bucket', u'object'],
+        query_params=[u'generation', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'userProject'],
+        relative_path=u'b/{bucket}/o/{object}',
+        request_field='',
+        request_type_name=u'StorageObjectsDeleteRequest',
+        response_type_name=u'StorageObjectsDeleteResponse',
+        supports_download=False,
+    )
+
     def Get(self, request, global_params=None, download=None):
       """Retrieves an object or its metadata.
 
@@ -1190,6 +1085,19 @@ class StorageV1(base_api.BaseApiClient):
           config, request, global_params=global_params,
           download=download)
 
+    Get.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.objects.get',
+        ordered_params=[u'bucket', u'object'],
+        path_params=[u'bucket', u'object'],
+        query_params=[u'generation', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'projection', u'userProject'],
+        relative_path=u'b/{bucket}/o/{object}',
+        request_field='',
+        request_type_name=u'StorageObjectsGetRequest',
+        response_type_name=u'Object',
+        supports_download=True,
+    )
+
     def GetIamPolicy(self, request, global_params=None):
       """Returns an IAM policy for the specified object.
 
@@ -1203,6 +1111,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    GetIamPolicy.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.objects.getIamPolicy',
+        ordered_params=[u'bucket', u'object'],
+        path_params=[u'bucket', u'object'],
+        query_params=[u'generation', u'userProject'],
+        relative_path=u'b/{bucket}/o/{object}/iam',
+        request_field='',
+        request_type_name=u'StorageObjectsGetIamPolicyRequest',
+        response_type_name=u'Policy',
+        supports_download=False,
+    )
+
     def Insert(self, request, global_params=None, upload=None, download=None):
       """Stores a new object and metadata.
 
@@ -1223,6 +1144,19 @@ class StorageV1(base_api.BaseApiClient):
           upload=upload, upload_config=upload_config,
           download=download)
 
+    Insert.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'POST',
+        method_id=u'storage.objects.insert',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'contentEncoding', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'name', u'predefinedAcl', u'projection', u'userProject'],
+        relative_path=u'b/{bucket}/o',
+        request_field=u'object',
+        request_type_name=u'StorageObjectsInsertRequest',
+        response_type_name=u'Object',
+        supports_download=True,
+    )
+
     def List(self, request, global_params=None):
       """Retrieves a list of objects matching the criteria.
 
@@ -1236,6 +1170,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    List.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.objects.list',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'delimiter', u'maxResults', u'pageToken', u'prefix', u'projection', u'userProject', u'versions'],
+        relative_path=u'b/{bucket}/o',
+        request_field='',
+        request_type_name=u'StorageObjectsListRequest',
+        response_type_name=u'Objects',
+        supports_download=False,
+    )
+
     def Patch(self, request, global_params=None):
       """Updates an object's metadata. This method supports patch semantics.
 
@@ -1249,6 +1196,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Patch.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'PATCH',
+        method_id=u'storage.objects.patch',
+        ordered_params=[u'bucket', u'object'],
+        path_params=[u'bucket', u'object'],
+        query_params=[u'generation', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'predefinedAcl', u'projection', u'userProject'],
+        relative_path=u'b/{bucket}/o/{object}',
+        request_field=u'objectResource',
+        request_type_name=u'StorageObjectsPatchRequest',
+        response_type_name=u'Object',
+        supports_download=False,
+    )
+
     def Rewrite(self, request, global_params=None):
       """Rewrites a source object to a destination object. Optionally overrides metadata.
 
@@ -1262,6 +1222,18 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Rewrite.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'POST',
+        method_id=u'storage.objects.rewrite',
+        ordered_params=[u'sourceBucket', u'sourceObject', u'destinationBucket', u'destinationObject'],
+        path_params=[u'destinationBucket', u'destinationObject', u'sourceBucket', u'sourceObject'],
+        query_params=[u'destinationPredefinedAcl', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'ifSourceGenerationMatch', u'ifSourceGenerationNotMatch', u'ifSourceMetagenerationMatch', u'ifSourceMetagenerationNotMatch', u'maxBytesRewrittenPerCall', u'projection', u'rewriteToken', u'sourceGeneration', u'userProject'],
+        relative_path=u'b/{sourceBucket}/o/{sourceObject}/rewriteTo/b/{destinationBucket}/o/{destinationObject}',
+        request_field=u'object',
+        request_type_name=u'StorageObjectsRewriteRequest',
+        response_type_name=u'RewriteResponse',
+        supports_download=False,
+    )
 
     def SetIamPolicy(self, request, global_params=None):
       """Updates an IAM policy for the specified object.
@@ -1276,6 +1248,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    SetIamPolicy.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'PUT',
+        method_id=u'storage.objects.setIamPolicy',
+        ordered_params=[u'bucket', u'object'],
+        path_params=[u'bucket', u'object'],
+        query_params=[u'generation', u'userProject'],
+        relative_path=u'b/{bucket}/o/{object}/iam',
+        request_field=u'policy',
+        request_type_name=u'StorageObjectsSetIamPolicyRequest',
+        response_type_name=u'Policy',
+        supports_download=False,
+    )
+
     def TestIamPermissions(self, request, global_params=None):
       """Tests a set of permissions on the given object to see which, if any, are held by the caller.
 
@@ -1289,6 +1274,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    TestIamPermissions.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.objects.testIamPermissions',
+        ordered_params=[u'bucket', u'object', u'permissions'],
+        path_params=[u'bucket', u'object'],
+        query_params=[u'generation', u'permissions', u'userProject'],
+        relative_path=u'b/{bucket}/o/{object}/iam/testPermissions',
+        request_field='',
+        request_type_name=u'StorageObjectsTestIamPermissionsRequest',
+        response_type_name=u'TestIamPermissionsResponse',
+        supports_download=False,
+    )
+
     def Update(self, request, global_params=None, download=None):
       """Updates an object's metadata.
 
@@ -1305,6 +1303,19 @@ class StorageV1(base_api.BaseApiClient):
           config, request, global_params=global_params,
           download=download)
 
+    Update.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'PUT',
+        method_id=u'storage.objects.update',
+        ordered_params=[u'bucket', u'object'],
+        path_params=[u'bucket', u'object'],
+        query_params=[u'generation', u'ifGenerationMatch', u'ifGenerationNotMatch', u'ifMetagenerationMatch', u'ifMetagenerationNotMatch', u'predefinedAcl', u'projection', u'userProject'],
+        relative_path=u'b/{bucket}/o/{object}',
+        request_field=u'objectResource',
+        request_type_name=u'StorageObjectsUpdateRequest',
+        response_type_name=u'Object',
+        supports_download=True,
+    )
+
     def WatchAll(self, request, global_params=None):
       """Watch for changes on all objects in a bucket.
 
@@ -1318,6 +1329,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    WatchAll.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'POST',
+        method_id=u'storage.objects.watchAll',
+        ordered_params=[u'bucket'],
+        path_params=[u'bucket'],
+        query_params=[u'delimiter', u'maxResults', u'pageToken', u'prefix', u'projection', u'userProject', u'versions'],
+        relative_path=u'b/{bucket}/o/watch',
+        request_field=u'channel',
+        request_type_name=u'StorageObjectsWatchAllRequest',
+        response_type_name=u'Channel',
+        supports_download=False,
+    )
+
   class ProjectsServiceAccountService(base_api.BaseApiService):
     """Service class for the projects_serviceAccount resource."""
 
@@ -1325,25 +1349,11 @@ class StorageV1(base_api.BaseApiClient):
 
     def __init__(self, client):
       super(StorageV1.ProjectsServiceAccountService, self).__init__(client)
-      self._method_configs = {
-          'Get': base_api.ApiMethodInfo(
-              http_method=u'GET',
-              method_id=u'storage.projects.serviceAccount.get',
-              ordered_params=[u'projectId'],
-              path_params=[u'projectId'],
-              query_params=[],
-              relative_path=u'projects/{projectId}/serviceAccount',
-              request_field='',
-              request_type_name=u'StorageProjectsServiceAccountGetRequest',
-              response_type_name=u'ServiceAccount',
-              supports_download=False,
-          ),
-      }
       self._upload_configs = {
           }
 
     def Get(self, request, global_params=None):
-      """Get the email address of this project's GCS service account.
+      """Get the email address of this project's Google Cloud Storage service account.
 
       Args:
         request: (StorageProjectsServiceAccountGetRequest) input message
@@ -1355,6 +1365,19 @@ class StorageV1(base_api.BaseApiClient):
       return self._RunMethod(
           config, request, global_params=global_params)
 
+    Get.method_config = lambda: base_api.ApiMethodInfo(
+        http_method=u'GET',
+        method_id=u'storage.projects.serviceAccount.get',
+        ordered_params=[u'projectId'],
+        path_params=[u'projectId'],
+        query_params=[u'userProject'],
+        relative_path=u'projects/{projectId}/serviceAccount',
+        request_field='',
+        request_type_name=u'StorageProjectsServiceAccountGetRequest',
+        response_type_name=u'ServiceAccount',
+        supports_download=False,
+    )
+
   class ProjectsService(base_api.BaseApiService):
     """Service class for the projects resource."""
 
diff --git a/gslib/third_party/storage_apitools/storage_v1_messages.py b/gslib/third_party/storage_apitools/storage_v1_messages.py
index fabe420..5b1c2fb 100644
--- a/gslib/third_party/storage_apitools/storage_v1_messages.py
+++ b/gslib/third_party/storage_apitools/storage_v1_messages.py
@@ -30,7 +30,9 @@ class Bucket(_messages.Message):
   """A bucket.
 
   Messages:
+    BillingValue: The bucket's billing configuration.
     CorsValueListEntry: A CorsValueListEntry object.
+    LabelsValue: User-provided labels, in key/value pairs.
     LifecycleValue: The bucket's lifecycle configuration. See lifecycle
       management for more information.
     LoggingValue: The bucket's logging configuration, which defines the
@@ -45,11 +47,13 @@ class Bucket(_messages.Message):
 
   Fields:
     acl: Access controls on the bucket.
+    billing: The bucket's billing configuration.
     cors: The bucket's Cross-Origin Resource Sharing (CORS) configuration.
     defaultObjectAcl: Default access controls to apply to new objects when no
       ACL is provided.
     etag: HTTP 1.1 Entity tag for the bucket.
-    id: The ID of the bucket.
+    id: The ID of the bucket. For buckets, the id and name properities are the
+      same.
     kind: The kind of item this is. For buckets, this is always
       storage#bucket.
     labels: User-provided labels, in key/value pairs.
@@ -81,6 +85,15 @@ class Bucket(_messages.Message):
       Website Examples for more information.
   """
 
+  class BillingValue(_messages.Message):
+    """The bucket's billing configuration.
+
+    Fields:
+      requesterPays: When set to true, bucket is requester pays.
+    """
+
+    requesterPays = _messages.BooleanField(1)
+
   class CorsValueListEntry(_messages.Message):
     """A CorsValueListEntry object.
 
@@ -248,25 +261,26 @@ class Bucket(_messages.Message):
     notFoundPage = _messages.StringField(2)
 
   acl = _messages.MessageField('BucketAccessControl', 1, repeated=True)
-  cors = _messages.MessageField('CorsValueListEntry', 2, repeated=True)
-  defaultObjectAcl = _messages.MessageField('ObjectAccessControl', 3, repeated=True)
-  etag = _messages.StringField(4)
-  id = _messages.StringField(5)
-  kind = _messages.StringField(6, default=u'storage#bucket')
-  labels = _messages.MessageField('LabelsValue', 7)
-  lifecycle = _messages.MessageField('LifecycleValue', 8)
-  location = _messages.StringField(9)
-  logging = _messages.MessageField('LoggingValue', 10)
-  metageneration = _messages.IntegerField(11)
-  name = _messages.StringField(12)
-  owner = _messages.MessageField('OwnerValue', 13)
-  projectNumber = _messages.IntegerField(14, variant=_messages.Variant.UINT64)
-  selfLink = _messages.StringField(15)
-  storageClass = _messages.StringField(16)
-  timeCreated = _message_types.DateTimeField(17)
-  updated = _message_types.DateTimeField(18)
-  versioning = _messages.MessageField('VersioningValue', 19)
-  website = _messages.MessageField('WebsiteValue', 20)
+  billing = _messages.MessageField('BillingValue', 2)
+  cors = _messages.MessageField('CorsValueListEntry', 3, repeated=True)
+  defaultObjectAcl = _messages.MessageField('ObjectAccessControl', 4, repeated=True)
+  etag = _messages.StringField(5)
+  id = _messages.StringField(6)
+  kind = _messages.StringField(7, default=u'storage#bucket')
+  labels = _messages.MessageField('LabelsValue', 8)
+  lifecycle = _messages.MessageField('LifecycleValue', 9)
+  location = _messages.StringField(10)
+  logging = _messages.MessageField('LoggingValue', 11)
+  metageneration = _messages.IntegerField(12)
+  name = _messages.StringField(13)
+  owner = _messages.MessageField('OwnerValue', 14)
+  projectNumber = _messages.IntegerField(15, variant=_messages.Variant.UINT64)
+  selfLink = _messages.StringField(16)
+  storageClass = _messages.StringField(17)
+  timeCreated = _message_types.DateTimeField(18)
+  updated = _message_types.DateTimeField(19)
+  versioning = _messages.MessageField('VersioningValue', 20)
+  website = _messages.MessageField('WebsiteValue', 21)
 
 
 class BucketAccessControl(_messages.Message):
@@ -422,6 +436,8 @@ class ComposeRequest(_messages.Message):
     kind: The kind of item this is.
     sourceObjects: The list of source objects that will be concatenated into a
       single object.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   class SourceObjectsValueListEntry(_messages.Message):
@@ -458,6 +474,7 @@ class ComposeRequest(_messages.Message):
   destination = _messages.MessageField('Object', 1)
   kind = _messages.StringField(2, default=u'storage#composeRequest')
   sourceObjects = _messages.MessageField('SourceObjectsValueListEntry', 3, repeated=True)
+  userProject = _messages.StringField(4)
 
 
 class Notification(_messages.Message):
@@ -479,7 +496,7 @@ class Notification(_messages.Message):
       storage#notification.
     object_name_prefix: If present, only apply this notification configuration
       to object names that begin with this prefix.
-    payload_format: The desired payload format for incoming notifications.
+    payload_format: The desired content of the Payload.
     selfLink: The canonical URL of this notification.
     topic: The Cloud PubSub topic to which this subscription publishes.
       Formatted as: '//pubsub.googleapis.com/projects/{project-
@@ -558,8 +575,8 @@ class Object(_messages.Message):
     contentDisposition: Content-Disposition of the object data.
     contentEncoding: Content-Encoding of the object data.
     contentLanguage: Content-Language of the object data.
-    contentType: Content-Type of the object data. If contentType is not
-      specified, object downloads will be served as application/octet-stream.
+    contentType: Content-Type of the object data. If an object is stored
+      without a Content-Type, it is served as application/octet-stream.
     crc32c: CRC32c checksum, as described in RFC 4960, Appendix B; encoded
       using base64 in big-endian byte order. For more information about using
       the CRC32c checksum, see Hashes and ETags: Best Practices.
@@ -579,7 +596,7 @@ class Object(_messages.Message):
       generation. Used for preconditions and for detecting changes in
       metadata. A metageneration number is only meaningful in the context of a
       particular generation of a particular object.
-    name: The name of this object. Required if not specified by URL parameter.
+    name: The name of the object. Required if not specified by URL parameter.
     owner: The owner of the object. This will always be the uploader of the
       object.
     selfLink: The link to this object.
@@ -772,17 +789,19 @@ class Policy(_messages.Message):
     kind: The kind of item this is. For policies, this is always
       storage#policy. This field is ignored on input.
     resourceId: The ID of the resource to which this policy belongs. Will be
-      of the form buckets/bucket for buckets, and
-      buckets/bucket/objects/object for objects. A specific generation may be
-      specified by appending #generationNumber to the end of the object name,
-      e.g. buckets/my-bucket/objects/data.txt#17. The current generation can
-      be denoted with #0. This field is ignored on input.
+      of the form projects/_/buckets/bucket for buckets, and
+      projects/_/buckets/bucket/objects/object for objects. A specific
+      generation may be specified by appending #generationNumber to the end of
+      the object name, e.g. projects/_/buckets/my-bucket/objects/data.txt#17.
+      The current generation can be denoted with #0. This field is ignored on
+      input.
   """
 
   class BindingsValueListEntry(_messages.Message):
     """A BindingsValueListEntry object.
 
     Fields:
+      condition: A extra_types.JsonValue attribute.
       members: A collection of identifiers for members who may assume the
         provided role. Recognized identifiers are as follows:   - allUsers \u2014 A
         special identifier that represents anyone on the internet; with or
@@ -826,8 +845,9 @@ class Policy(_messages.Message):
         entry on a bucket with the OWNER role.
     """
 
-    members = _messages.StringField(1, repeated=True)
-    role = _messages.StringField(2)
+    condition = _messages.MessageField('extra_types.JsonValue', 1)
+    members = _messages.StringField(2, repeated=True)
+    role = _messages.StringField(3)
 
   bindings = _messages.MessageField('BindingsValueListEntry', 1, repeated=True)
   etag = _messages.BytesField(2)
@@ -924,10 +944,13 @@ class StorageBucketAccessControlsDeleteRequest(_messages.Message):
     entity: The entity holding the permission. Can be user-userId, user-
       emailAddress, group-groupId, group-emailAddress, allUsers, or
       allAuthenticatedUsers.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   entity = _messages.StringField(2, required=True)
+  userProject = _messages.StringField(3)
 
 
 class StorageBucketAccessControlsDeleteResponse(_messages.Message):
@@ -942,10 +965,29 @@ class StorageBucketAccessControlsGetRequest(_messages.Message):
     entity: The entity holding the permission. Can be user-userId, user-
       emailAddress, group-groupId, group-emailAddress, allUsers, or
       allAuthenticatedUsers.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   entity = _messages.StringField(2, required=True)
+  userProject = _messages.StringField(3)
+
+
+class StorageBucketAccessControlsInsertRequest(_messages.Message):
+  """A StorageBucketAccessControlsInsertRequest object.
+
+  Fields:
+    bucket: Name of a bucket.
+    bucketAccessControl: A BucketAccessControl resource to be passed as the
+      request body.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
+  """
+
+  bucket = _messages.StringField(1, required=True)
+  bucketAccessControl = _messages.MessageField('BucketAccessControl', 2)
+  userProject = _messages.StringField(3)
 
 
 class StorageBucketAccessControlsListRequest(_messages.Message):
@@ -953,9 +995,52 @@ class StorageBucketAccessControlsListRequest(_messages.Message):
 
   Fields:
     bucket: Name of a bucket.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
+  """
+
+  bucket = _messages.StringField(1, required=True)
+  userProject = _messages.StringField(2)
+
+
+class StorageBucketAccessControlsPatchRequest(_messages.Message):
+  """A StorageBucketAccessControlsPatchRequest object.
+
+  Fields:
+    bucket: Name of a bucket.
+    bucketAccessControl: A BucketAccessControl resource to be passed as the
+      request body.
+    entity: The entity holding the permission. Can be user-userId, user-
+      emailAddress, group-groupId, group-emailAddress, allUsers, or
+      allAuthenticatedUsers.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
+  """
+
+  bucket = _messages.StringField(1, required=True)
+  bucketAccessControl = _messages.MessageField('BucketAccessControl', 2)
+  entity = _messages.StringField(3, required=True)
+  userProject = _messages.StringField(4)
+
+
+class StorageBucketAccessControlsUpdateRequest(_messages.Message):
+  """A StorageBucketAccessControlsUpdateRequest object.
+
+  Fields:
+    bucket: Name of a bucket.
+    bucketAccessControl: A BucketAccessControl resource to be passed as the
+      request body.
+    entity: The entity holding the permission. Can be user-userId, user-
+      emailAddress, group-groupId, group-emailAddress, allUsers, or
+      allAuthenticatedUsers.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
+  bucketAccessControl = _messages.MessageField('BucketAccessControl', 2)
+  entity = _messages.StringField(3, required=True)
+  userProject = _messages.StringField(4)
 
 
 class StorageBucketsDeleteRequest(_messages.Message):
@@ -967,11 +1052,14 @@ class StorageBucketsDeleteRequest(_messages.Message):
       metageneration matches this value.
     ifMetagenerationNotMatch: If set, only deletes the bucket if its
       metageneration does not match this value.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   ifMetagenerationMatch = _messages.IntegerField(2)
   ifMetagenerationNotMatch = _messages.IntegerField(3)
+  userProject = _messages.StringField(4)
 
 
 class StorageBucketsDeleteResponse(_messages.Message):
@@ -983,8 +1071,12 @@ class StorageBucketsGetIamPolicyRequest(_messages.Message):
 
   Fields:
     bucket: Name of a bucket.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
+
   bucket = _messages.StringField(1, required=True)
+  userProject = _messages.StringField(2)
 
 
 class StorageBucketsGetRequest(_messages.Message):
@@ -1001,6 +1093,8 @@ class StorageBucketsGetRequest(_messages.Message):
       conditional on whether the bucket's current metageneration does not
       match the given value.
     projection: Set of properties to return. Defaults to noAcl.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   class ProjectionValueValuesEnum(_messages.Enum):
@@ -1017,6 +1111,7 @@ class StorageBucketsGetRequest(_messages.Message):
   ifMetagenerationMatch = _messages.IntegerField(2)
   ifMetagenerationNotMatch = _messages.IntegerField(3)
   projection = _messages.EnumField('ProjectionValueValuesEnum', 4)
+  userProject = _messages.StringField(5)
 
 
 class StorageBucketsInsertRequest(_messages.Message):
@@ -1040,6 +1135,8 @@ class StorageBucketsInsertRequest(_messages.Message):
     projection: Set of properties to return. Defaults to noAcl, unless the
       bucket resource specifies acl or defaultObjectAcl properties, when it
       defaults to full.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   class PredefinedAclValueValuesEnum(_messages.Enum):
@@ -1103,6 +1200,7 @@ class StorageBucketsInsertRequest(_messages.Message):
   predefinedDefaultObjectAcl = _messages.EnumField('PredefinedDefaultObjectAclValueValuesEnum', 3)
   project = _messages.StringField(4, required=True)
   projection = _messages.EnumField('ProjectionValueValuesEnum', 5)
+  userProject = _messages.StringField(6)
 
 
 class StorageBucketsListRequest(_messages.Message):
@@ -1112,12 +1210,15 @@ class StorageBucketsListRequest(_messages.Message):
     ProjectionValueValuesEnum: Set of properties to return. Defaults to noAcl.
 
   Fields:
-    maxResults: Maximum number of buckets to return.
+    maxResults: Maximum number of buckets to return in a single response. The
+      service will use this parameter or 1,000 items, whichever is smaller.
     pageToken: A previously-returned page token representing part of the
       larger set of results to view.
     prefix: Filter results to buckets whose names begin with this prefix.
     project: A valid API project identifier.
     projection: Set of properties to return. Defaults to noAcl.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   class ProjectionValueValuesEnum(_messages.Enum):
@@ -1130,11 +1231,12 @@ class StorageBucketsListRequest(_messages.Message):
     full = 0
     noAcl = 1
 
-  maxResults = _messages.IntegerField(1, variant=_messages.Variant.UINT32)
+  maxResults = _messages.IntegerField(1, variant=_messages.Variant.UINT32, default=1000)
   pageToken = _messages.StringField(2)
   prefix = _messages.StringField(3)
   project = _messages.StringField(4, required=True)
   projection = _messages.EnumField('ProjectionValueValuesEnum', 5)
+  userProject = _messages.StringField(6)
 
 
 class StorageBucketsPatchRequest(_messages.Message):
@@ -1159,6 +1261,8 @@ class StorageBucketsPatchRequest(_messages.Message):
     predefinedDefaultObjectAcl: Apply a predefined set of default object
       access controls to this bucket.
     projection: Set of properties to return. Defaults to full.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   class PredefinedAclValueValuesEnum(_messages.Enum):
@@ -1222,6 +1326,7 @@ class StorageBucketsPatchRequest(_messages.Message):
   predefinedAcl = _messages.EnumField('PredefinedAclValueValuesEnum', 5)
   predefinedDefaultObjectAcl = _messages.EnumField('PredefinedDefaultObjectAclValueValuesEnum', 6)
   projection = _messages.EnumField('ProjectionValueValuesEnum', 7)
+  userProject = _messages.StringField(8)
 
 
 class StorageBucketsSetIamPolicyRequest(_messages.Message):
@@ -1230,10 +1335,13 @@ class StorageBucketsSetIamPolicyRequest(_messages.Message):
   Fields:
     bucket: Name of a bucket.
     policy: A Policy resource to be passed as the request body.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   policy = _messages.MessageField('Policy', 2)
+  userProject = _messages.StringField(3)
 
 
 class StorageBucketsTestIamPermissionsRequest(_messages.Message):
@@ -1242,10 +1350,13 @@ class StorageBucketsTestIamPermissionsRequest(_messages.Message):
   Fields:
     bucket: Name of a bucket.
     permissions: Permissions to test.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   permissions = _messages.StringField(2, required=True)
+  userProject = _messages.StringField(3)
 
 
 class StorageBucketsUpdateRequest(_messages.Message):
@@ -1270,6 +1381,8 @@ class StorageBucketsUpdateRequest(_messages.Message):
     predefinedDefaultObjectAcl: Apply a predefined set of default object
       access controls to this bucket.
     projection: Set of properties to return. Defaults to full.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   class PredefinedAclValueValuesEnum(_messages.Enum):
@@ -1333,6 +1446,7 @@ class StorageBucketsUpdateRequest(_messages.Message):
   predefinedAcl = _messages.EnumField('PredefinedAclValueValuesEnum', 5)
   predefinedDefaultObjectAcl = _messages.EnumField('PredefinedDefaultObjectAclValueValuesEnum', 6)
   projection = _messages.EnumField('ProjectionValueValuesEnum', 7)
+  userProject = _messages.StringField(8)
 
 
 class StorageChannelsStopResponse(_messages.Message):
@@ -1347,10 +1461,13 @@ class StorageDefaultObjectAccessControlsDeleteRequest(_messages.Message):
     entity: The entity holding the permission. Can be user-userId, user-
       emailAddress, group-groupId, group-emailAddress, allUsers, or
       allAuthenticatedUsers.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   entity = _messages.StringField(2, required=True)
+  userProject = _messages.StringField(3)
 
 
 class StorageDefaultObjectAccessControlsDeleteResponse(_messages.Message):
@@ -1365,10 +1482,29 @@ class StorageDefaultObjectAccessControlsGetRequest(_messages.Message):
     entity: The entity holding the permission. Can be user-userId, user-
       emailAddress, group-groupId, group-emailAddress, allUsers, or
       allAuthenticatedUsers.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   entity = _messages.StringField(2, required=True)
+  userProject = _messages.StringField(3)
+
+
+class StorageDefaultObjectAccessControlsInsertRequest(_messages.Message):
+  """A StorageDefaultObjectAccessControlsInsertRequest object.
+
+  Fields:
+    bucket: Name of a bucket.
+    objectAccessControl: A ObjectAccessControl resource to be passed as the
+      request body.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
+  """
+
+  bucket = _messages.StringField(1, required=True)
+  objectAccessControl = _messages.MessageField('ObjectAccessControl', 2)
+  userProject = _messages.StringField(3)
 
 
 class StorageDefaultObjectAccessControlsListRequest(_messages.Message):
@@ -1380,11 +1516,54 @@ class StorageDefaultObjectAccessControlsListRequest(_messages.Message):
       bucket's current metageneration matches this value.
     ifMetagenerationNotMatch: If present, only return default ACL listing if
       the bucket's current metageneration does not match the given value.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   ifMetagenerationMatch = _messages.IntegerField(2)
   ifMetagenerationNotMatch = _messages.IntegerField(3)
+  userProject = _messages.StringField(4)
+
+
+class StorageDefaultObjectAccessControlsPatchRequest(_messages.Message):
+  """A StorageDefaultObjectAccessControlsPatchRequest object.
+
+  Fields:
+    bucket: Name of a bucket.
+    entity: The entity holding the permission. Can be user-userId, user-
+      emailAddress, group-groupId, group-emailAddress, allUsers, or
+      allAuthenticatedUsers.
+    objectAccessControl: A ObjectAccessControl resource to be passed as the
+      request body.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
+  """
+
+  bucket = _messages.StringField(1, required=True)
+  entity = _messages.StringField(2, required=True)
+  objectAccessControl = _messages.MessageField('ObjectAccessControl', 3)
+  userProject = _messages.StringField(4)
+
+
+class StorageDefaultObjectAccessControlsUpdateRequest(_messages.Message):
+  """A StorageDefaultObjectAccessControlsUpdateRequest object.
+
+  Fields:
+    bucket: Name of a bucket.
+    entity: The entity holding the permission. Can be user-userId, user-
+      emailAddress, group-groupId, group-emailAddress, allUsers, or
+      allAuthenticatedUsers.
+    objectAccessControl: A ObjectAccessControl resource to be passed as the
+      request body.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
+  """
+
+  bucket = _messages.StringField(1, required=True)
+  entity = _messages.StringField(2, required=True)
+  objectAccessControl = _messages.MessageField('ObjectAccessControl', 3)
+  userProject = _messages.StringField(4)
 
 
 class StorageNotificationsDeleteRequest(_messages.Message):
@@ -1393,13 +1572,13 @@ class StorageNotificationsDeleteRequest(_messages.Message):
   Fields:
     bucket: The parent bucket of the notification.
     notification: ID of the notification to delete.
-    requesterPaysBillingProjectId: The project number to be billed for this
-      request, for Requester Pays buckets.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   notification = _messages.StringField(2, required=True)
-  requesterPaysBillingProjectId = _messages.StringField(3)
+  userProject = _messages.StringField(3)
 
 
 class StorageNotificationsDeleteResponse(_messages.Message):
@@ -1412,13 +1591,13 @@ class StorageNotificationsGetRequest(_messages.Message):
   Fields:
     bucket: The parent bucket of the notification.
     notification: Notification ID
-    requesterPaysBillingProjectId: The project number to be billed for this
-      request, for Requester Pays buckets.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   notification = _messages.StringField(2, required=True)
-  requesterPaysBillingProjectId = _messages.StringField(3)
+  userProject = _messages.StringField(3)
 
 
 class StorageNotificationsInsertRequest(_messages.Message):
@@ -1427,26 +1606,26 @@ class StorageNotificationsInsertRequest(_messages.Message):
   Fields:
     bucket: The parent bucket of the notification.
     notification: A Notification resource to be passed as the request body.
-    requesterPaysBillingProjectId: The project number to be billed for this
-      request, for Requester Pays buckets.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   notification = _messages.MessageField('Notification', 2)
-  requesterPaysBillingProjectId = _messages.StringField(3)
+  userProject = _messages.StringField(3)
 
 
 class StorageNotificationsListRequest(_messages.Message):
   """A StorageNotificationsListRequest object.
 
   Fields:
-    bucket: Name of a GCS bucket.
-    requesterPaysBillingProjectId: The project number to be billed for this
-      request, for Requester Pays buckets.
+    bucket: Name of a Google Cloud Storage bucket.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
-  requesterPaysBillingProjectId = _messages.StringField(2)
+  userProject = _messages.StringField(2)
 
 
 class StorageObjectAccessControlsDeleteRequest(_messages.Message):
@@ -1461,12 +1640,15 @@ class StorageObjectAccessControlsDeleteRequest(_messages.Message):
       opposed to the latest version, the default).
     object: Name of the object. For information about how to URL encode object
       names to be path safe, see Encoding URI Path Parts.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   entity = _messages.StringField(2, required=True)
   generation = _messages.IntegerField(3)
   object = _messages.StringField(4, required=True)
+  userProject = _messages.StringField(5)
 
 
 class StorageObjectAccessControlsDeleteResponse(_messages.Message):
@@ -1485,12 +1667,15 @@ class StorageObjectAccessControlsGetRequest(_messages.Message):
       opposed to the latest version, the default).
     object: Name of the object. For information about how to URL encode object
       names to be path safe, see Encoding URI Path Parts.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   entity = _messages.StringField(2, required=True)
   generation = _messages.IntegerField(3)
   object = _messages.StringField(4, required=True)
+  userProject = _messages.StringField(5)
 
 
 class StorageObjectAccessControlsInsertRequest(_messages.Message):
@@ -1504,12 +1689,15 @@ class StorageObjectAccessControlsInsertRequest(_messages.Message):
       names to be path safe, see Encoding URI Path Parts.
     objectAccessControl: A ObjectAccessControl resource to be passed as the
       request body.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   generation = _messages.IntegerField(2)
   object = _messages.StringField(3, required=True)
   objectAccessControl = _messages.MessageField('ObjectAccessControl', 4)
+  userProject = _messages.StringField(5)
 
 
 class StorageObjectAccessControlsListRequest(_messages.Message):
@@ -1521,11 +1709,14 @@ class StorageObjectAccessControlsListRequest(_messages.Message):
       opposed to the latest version, the default).
     object: Name of the object. For information about how to URL encode object
       names to be path safe, see Encoding URI Path Parts.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   generation = _messages.IntegerField(2)
   object = _messages.StringField(3, required=True)
+  userProject = _messages.StringField(4)
 
 
 class StorageObjectAccessControlsPatchRequest(_messages.Message):
@@ -1542,6 +1733,8 @@ class StorageObjectAccessControlsPatchRequest(_messages.Message):
       names to be path safe, see Encoding URI Path Parts.
     objectAccessControl: A ObjectAccessControl resource to be passed as the
       request body.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
@@ -1549,6 +1742,7 @@ class StorageObjectAccessControlsPatchRequest(_messages.Message):
   generation = _messages.IntegerField(3)
   object = _messages.StringField(4, required=True)
   objectAccessControl = _messages.MessageField('ObjectAccessControl', 5)
+  userProject = _messages.StringField(6)
 
 
 class StorageObjectAccessControlsUpdateRequest(_messages.Message):
@@ -1565,6 +1759,8 @@ class StorageObjectAccessControlsUpdateRequest(_messages.Message):
       names to be path safe, see Encoding URI Path Parts.
     objectAccessControl: A ObjectAccessControl resource to be passed as the
       request body.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
@@ -1572,6 +1768,7 @@ class StorageObjectAccessControlsUpdateRequest(_messages.Message):
   generation = _messages.IntegerField(3)
   object = _messages.StringField(4, required=True)
   objectAccessControl = _messages.MessageField('ObjectAccessControl', 5)
+  userProject = _messages.StringField(6)
 
 
 class StorageObjectsComposeRequest(_messages.Message):
@@ -1590,9 +1787,12 @@ class StorageObjectsComposeRequest(_messages.Message):
     destinationPredefinedAcl: Apply a predefined set of access controls to the
       destination object.
     ifGenerationMatch: Makes the operation conditional on whether the object's
-      current generation matches the given value.
+      current generation matches the given value. Setting to 0 makes the
+      operation succeed only if there are no live versions of the object.
     ifMetagenerationMatch: Makes the operation conditional on whether the
       object's current metageneration matches the given value.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   class DestinationPredefinedAclValueValuesEnum(_messages.Enum):
@@ -1624,6 +1824,7 @@ class StorageObjectsComposeRequest(_messages.Message):
   destinationPredefinedAcl = _messages.EnumField('DestinationPredefinedAclValueValuesEnum', 4)
   ifGenerationMatch = _messages.IntegerField(5)
   ifMetagenerationMatch = _messages.IntegerField(6)
+  userProject = _messages.StringField(7)
 
 
 class StorageObjectsCopyRequest(_messages.Message):
@@ -1647,18 +1848,22 @@ class StorageObjectsCopyRequest(_messages.Message):
     destinationPredefinedAcl: Apply a predefined set of access controls to the
       destination object.
     ifGenerationMatch: Makes the operation conditional on whether the
-      destination object's current generation matches the given value.
+      destination object's current generation matches the given value. Setting
+      to 0 makes the operation succeed only if there are no live versions of
+      the object.
     ifGenerationNotMatch: Makes the operation conditional on whether the
       destination object's current generation does not match the given value.
+      If no live object exists, the precondition fails. Setting to 0 makes the
+      operation succeed only if there is a live version of the object.
     ifMetagenerationMatch: Makes the operation conditional on whether the
       destination object's current metageneration matches the given value.
     ifMetagenerationNotMatch: Makes the operation conditional on whether the
       destination object's current metageneration does not match the given
       value.
     ifSourceGenerationMatch: Makes the operation conditional on whether the
-      source object's generation matches the given value.
+      source object's current generation matches the given value.
     ifSourceGenerationNotMatch: Makes the operation conditional on whether the
-      source object's generation does not match the given value.
+      source object's current generation does not match the given value.
     ifSourceMetagenerationMatch: Makes the operation conditional on whether
       the source object's current metageneration matches the given value.
     ifSourceMetagenerationNotMatch: Makes the operation conditional on whether
@@ -1672,6 +1877,8 @@ class StorageObjectsCopyRequest(_messages.Message):
       object (as opposed to the latest version, the default).
     sourceObject: Name of the source object. For information about how to URL
       encode object names to be path safe, see Encoding URI Path Parts.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   class DestinationPredefinedAclValueValuesEnum(_messages.Enum):
@@ -1724,6 +1931,7 @@ class StorageObjectsCopyRequest(_messages.Message):
   sourceBucket = _messages.StringField(14, required=True)
   sourceGeneration = _messages.IntegerField(15)
   sourceObject = _messages.StringField(16, required=True)
+  userProject = _messages.StringField(17)
 
 
 class StorageObjectsDeleteRequest(_messages.Message):
@@ -1734,15 +1942,20 @@ class StorageObjectsDeleteRequest(_messages.Message):
     generation: If present, permanently deletes a specific revision of this
       object (as opposed to the latest version, the default).
     ifGenerationMatch: Makes the operation conditional on whether the object's
-      current generation matches the given value.
+      current generation matches the given value. Setting to 0 makes the
+      operation succeed only if there are no live versions of the object.
     ifGenerationNotMatch: Makes the operation conditional on whether the
-      object's current generation does not match the given value.
+      object's current generation does not match the given value. If no live
+      object exists, the precondition fails. Setting to 0 makes the operation
+      succeed only if there is a live version of the object.
     ifMetagenerationMatch: Makes the operation conditional on whether the
       object's current metageneration matches the given value.
     ifMetagenerationNotMatch: Makes the operation conditional on whether the
       object's current metageneration does not match the given value.
     object: Name of the object. For information about how to URL encode object
       names to be path safe, see Encoding URI Path Parts.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
@@ -1752,6 +1965,7 @@ class StorageObjectsDeleteRequest(_messages.Message):
   ifMetagenerationMatch = _messages.IntegerField(5)
   ifMetagenerationNotMatch = _messages.IntegerField(6)
   object = _messages.StringField(7, required=True)
+  userProject = _messages.StringField(8)
 
 
 class StorageObjectsDeleteResponse(_messages.Message):
@@ -1767,11 +1981,14 @@ class StorageObjectsGetIamPolicyRequest(_messages.Message):
       opposed to the latest version, the default).
     object: Name of the object. For information about how to URL encode object
       names to be path safe, see Encoding URI Path Parts.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   generation = _messages.IntegerField(2)
   object = _messages.StringField(3, required=True)
+  userProject = _messages.StringField(4)
 
 
 class StorageObjectsGetRequest(_messages.Message):
@@ -1785,9 +2002,12 @@ class StorageObjectsGetRequest(_messages.Message):
     generation: If present, selects a specific revision of this object (as
       opposed to the latest version, the default).
     ifGenerationMatch: Makes the operation conditional on whether the object's
-      generation matches the given value.
+      current generation matches the given value. Setting to 0 makes the
+      operation succeed only if there are no live versions of the object.
     ifGenerationNotMatch: Makes the operation conditional on whether the
-      object's generation does not match the given value.
+      object's current generation does not match the given value. If no live
+      object exists, the precondition fails. Setting to 0 makes the operation
+      succeed only if there is a live version of the object.
     ifMetagenerationMatch: Makes the operation conditional on whether the
       object's current metageneration matches the given value.
     ifMetagenerationNotMatch: Makes the operation conditional on whether the
@@ -1795,6 +2015,8 @@ class StorageObjectsGetRequest(_messages.Message):
     object: Name of the object. For information about how to URL encode object
       names to be path safe, see Encoding URI Path Parts.
     projection: Set of properties to return. Defaults to noAcl.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   class ProjectionValueValuesEnum(_messages.Enum):
@@ -1815,6 +2037,7 @@ class StorageObjectsGetRequest(_messages.Message):
   ifMetagenerationNotMatch = _messages.IntegerField(6)
   object = _messages.StringField(7, required=True)
   projection = _messages.EnumField('ProjectionValueValuesEnum', 8)
+  userProject = _messages.StringField(9)
 
 
 class StorageObjectsInsertRequest(_messages.Message):
@@ -1836,9 +2059,12 @@ class StorageObjectsInsertRequest(_messages.Message):
       an object with uploadType=media to indicate the encoding of the content
       being uploaded.
     ifGenerationMatch: Makes the operation conditional on whether the object's
-      current generation matches the given value.
+      current generation matches the given value. Setting to 0 makes the
+      operation succeed only if there are no live versions of the object.
     ifGenerationNotMatch: Makes the operation conditional on whether the
-      object's current generation does not match the given value.
+      object's current generation does not match the given value. If no live
+      object exists, the precondition fails. Setting to 0 makes the operation
+      succeed only if there is a live version of the object.
     ifMetagenerationMatch: Makes the operation conditional on whether the
       object's current metageneration matches the given value.
     ifMetagenerationNotMatch: Makes the operation conditional on whether the
@@ -1851,6 +2077,8 @@ class StorageObjectsInsertRequest(_messages.Message):
     predefinedAcl: Apply a predefined set of access controls to this object.
     projection: Set of properties to return. Defaults to noAcl, unless the
       object resource specifies the acl property, when it defaults to full.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   class PredefinedAclValueValuesEnum(_messages.Enum):
@@ -1897,6 +2125,7 @@ class StorageObjectsInsertRequest(_messages.Message):
   object = _messages.MessageField('Object', 8)
   predefinedAcl = _messages.EnumField('PredefinedAclValueValuesEnum', 9)
   projection = _messages.EnumField('ProjectionValueValuesEnum', 10)
+  userProject = _messages.StringField(11)
 
 
 class StorageObjectsListRequest(_messages.Message):
@@ -1912,13 +2141,16 @@ class StorageObjectsListRequest(_messages.Message):
       delimiter. Objects whose names, aside from the prefix, contain delimiter
       will have their name, truncated after the delimiter, returned in
       prefixes. Duplicate prefixes are omitted.
-    maxResults: Maximum number of items plus prefixes to return. As duplicate
-      prefixes are omitted, fewer total results may be returned than
-      requested. The default value of this parameter is 1,000 items.
+    maxResults: Maximum number of items plus prefixes to return in a single
+      page of responses. As duplicate prefixes are omitted, fewer total
+      results may be returned than requested. The service will use this
+      parameter or 1,000 items, whichever is smaller.
     pageToken: A previously-returned page token representing part of the
       larger set of results to view.
     prefix: Filter results to objects whose names begin with this prefix.
     projection: Set of properties to return. Defaults to noAcl.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
     versions: If true, lists all versions of an object as distinct results.
       The default is false. For more information, see Object Versioning.
   """
@@ -1935,11 +2167,12 @@ class StorageObjectsListRequest(_messages.Message):
 
   bucket = _messages.StringField(1, required=True)
   delimiter = _messages.StringField(2)
-  maxResults = _messages.IntegerField(3, variant=_messages.Variant.UINT32)
+  maxResults = _messages.IntegerField(3, variant=_messages.Variant.UINT32, default=1000)
   pageToken = _messages.StringField(4)
   prefix = _messages.StringField(5)
   projection = _messages.EnumField('ProjectionValueValuesEnum', 6)
-  versions = _messages.BooleanField(7)
+  userProject = _messages.StringField(7)
+  versions = _messages.BooleanField(8)
 
 
 class StorageObjectsPatchRequest(_messages.Message):
@@ -1955,9 +2188,12 @@ class StorageObjectsPatchRequest(_messages.Message):
     generation: If present, selects a specific revision of this object (as
       opposed to the latest version, the default).
     ifGenerationMatch: Makes the operation conditional on whether the object's
-      current generation matches the given value.
+      current generation matches the given value. Setting to 0 makes the
+      operation succeed only if there are no live versions of the object.
     ifGenerationNotMatch: Makes the operation conditional on whether the
-      object's current generation does not match the given value.
+      object's current generation does not match the given value. If no live
+      object exists, the precondition fails. Setting to 0 makes the operation
+      succeed only if there is a live version of the object.
     ifMetagenerationMatch: Makes the operation conditional on whether the
       object's current metageneration matches the given value.
     ifMetagenerationNotMatch: Makes the operation conditional on whether the
@@ -1967,6 +2203,8 @@ class StorageObjectsPatchRequest(_messages.Message):
     objectResource: A Object resource to be passed as the request body.
     predefinedAcl: Apply a predefined set of access controls to this object.
     projection: Set of properties to return. Defaults to full.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   class PredefinedAclValueValuesEnum(_messages.Enum):
@@ -2012,6 +2250,7 @@ class StorageObjectsPatchRequest(_messages.Message):
   objectResource = _messages.MessageField('Object', 8)
   predefinedAcl = _messages.EnumField('PredefinedAclValueValuesEnum', 9)
   projection = _messages.EnumField('ProjectionValueValuesEnum', 10)
+  userProject = _messages.StringField(11)
 
 
 class StorageObjectsRewriteRequest(_messages.Message):
@@ -2033,19 +2272,22 @@ class StorageObjectsRewriteRequest(_messages.Message):
       be path safe, see Encoding URI Path Parts.
     destinationPredefinedAcl: Apply a predefined set of access controls to the
       destination object.
-    ifGenerationMatch: Makes the operation conditional on whether the
-      destination object's current generation matches the given value.
+    ifGenerationMatch: Makes the operation conditional on whether the object's
+      current generation matches the given value. Setting to 0 makes the
+      operation succeed only if there are no live versions of the object.
     ifGenerationNotMatch: Makes the operation conditional on whether the
-      destination object's current generation does not match the given value.
+      object's current generation does not match the given value. If no live
+      object exists, the precondition fails. Setting to 0 makes the operation
+      succeed only if there is a live version of the object.
     ifMetagenerationMatch: Makes the operation conditional on whether the
       destination object's current metageneration matches the given value.
     ifMetagenerationNotMatch: Makes the operation conditional on whether the
       destination object's current metageneration does not match the given
       value.
     ifSourceGenerationMatch: Makes the operation conditional on whether the
-      source object's generation matches the given value.
+      source object's current generation matches the given value.
     ifSourceGenerationNotMatch: Makes the operation conditional on whether the
-      source object's generation does not match the given value.
+      source object's current generation does not match the given value.
     ifSourceMetagenerationMatch: Makes the operation conditional on whether
       the source object's current metageneration matches the given value.
     ifSourceMetagenerationNotMatch: Makes the operation conditional on whether
@@ -2072,6 +2314,8 @@ class StorageObjectsRewriteRequest(_messages.Message):
       object (as opposed to the latest version, the default).
     sourceObject: Name of the source object. For information about how to URL
       encode object names to be path safe, see Encoding URI Path Parts.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   class DestinationPredefinedAclValueValuesEnum(_messages.Enum):
@@ -2126,6 +2370,7 @@ class StorageObjectsRewriteRequest(_messages.Message):
   sourceBucket = _messages.StringField(16, required=True)
   sourceGeneration = _messages.IntegerField(17)
   sourceObject = _messages.StringField(18, required=True)
+  userProject = _messages.StringField(19)
 
 
 class StorageObjectsSetIamPolicyRequest(_messages.Message):
@@ -2138,12 +2383,15 @@ class StorageObjectsSetIamPolicyRequest(_messages.Message):
     object: Name of the object. For information about how to URL encode object
       names to be path safe, see Encoding URI Path Parts.
     policy: A Policy resource to be passed as the request body.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   generation = _messages.IntegerField(2)
   object = _messages.StringField(3, required=True)
   policy = _messages.MessageField('Policy', 4)
+  userProject = _messages.StringField(5)
 
 
 class StorageObjectsTestIamPermissionsRequest(_messages.Message):
@@ -2156,12 +2404,15 @@ class StorageObjectsTestIamPermissionsRequest(_messages.Message):
     object: Name of the object. For information about how to URL encode object
       names to be path safe, see Encoding URI Path Parts.
     permissions: Permissions to test.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   bucket = _messages.StringField(1, required=True)
   generation = _messages.IntegerField(2)
   object = _messages.StringField(3, required=True)
   permissions = _messages.StringField(4, required=True)
+  userProject = _messages.StringField(5)
 
 
 class StorageObjectsUpdateRequest(_messages.Message):
@@ -2177,9 +2428,12 @@ class StorageObjectsUpdateRequest(_messages.Message):
     generation: If present, selects a specific revision of this object (as
       opposed to the latest version, the default).
     ifGenerationMatch: Makes the operation conditional on whether the object's
-      current generation matches the given value.
+      current generation matches the given value. Setting to 0 makes the
+      operation succeed only if there are no live versions of the object.
     ifGenerationNotMatch: Makes the operation conditional on whether the
-      object's current generation does not match the given value.
+      object's current generation does not match the given value. If no live
+      object exists, the precondition fails. Setting to 0 makes the operation
+      succeed only if there is a live version of the object.
     ifMetagenerationMatch: Makes the operation conditional on whether the
       object's current metageneration matches the given value.
     ifMetagenerationNotMatch: Makes the operation conditional on whether the
@@ -2189,6 +2443,8 @@ class StorageObjectsUpdateRequest(_messages.Message):
     objectResource: A Object resource to be passed as the request body.
     predefinedAcl: Apply a predefined set of access controls to this object.
     projection: Set of properties to return. Defaults to full.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
   """
 
   class PredefinedAclValueValuesEnum(_messages.Enum):
@@ -2234,6 +2490,7 @@ class StorageObjectsUpdateRequest(_messages.Message):
   objectResource = _messages.MessageField('Object', 8)
   predefinedAcl = _messages.EnumField('PredefinedAclValueValuesEnum', 9)
   projection = _messages.EnumField('ProjectionValueValuesEnum', 10)
+  userProject = _messages.StringField(11)
 
 
 class StorageObjectsWatchAllRequest(_messages.Message):
@@ -2250,13 +2507,16 @@ class StorageObjectsWatchAllRequest(_messages.Message):
       delimiter. Objects whose names, aside from the prefix, contain delimiter
       will have their name, truncated after the delimiter, returned in
       prefixes. Duplicate prefixes are omitted.
-    maxResults: Maximum number of items plus prefixes to return. As duplicate
-      prefixes are omitted, fewer total results may be returned than
-      requested. The default value of this parameter is 1,000 items.
+    maxResults: Maximum number of items plus prefixes to return in a single
+      page of responses. As duplicate prefixes are omitted, fewer total
+      results may be returned than requested. The service will use this
+      parameter or 1,000 items, whichever is smaller.
     pageToken: A previously-returned page token representing part of the
       larger set of results to view.
     prefix: Filter results to objects whose names begin with this prefix.
     projection: Set of properties to return. Defaults to noAcl.
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
     versions: If true, lists all versions of an object as distinct results.
       The default is false. For more information, see Object Versioning.
   """
@@ -2274,15 +2534,30 @@ class StorageObjectsWatchAllRequest(_messages.Message):
   bucket = _messages.StringField(1, required=True)
   channel = _messages.MessageField('Channel', 2)
   delimiter = _messages.StringField(3)
-  maxResults = _messages.IntegerField(4, variant=_messages.Variant.UINT32)
+  maxResults = _messages.IntegerField(4, variant=_messages.Variant.UINT32, default=1000)
   pageToken = _messages.StringField(5)
   prefix = _messages.StringField(6)
   projection = _messages.EnumField('ProjectionValueValuesEnum', 7)
-  versions = _messages.BooleanField(8)
+  userProject = _messages.StringField(8)
+  versions = _messages.BooleanField(9)
+
+
+class StorageProjectsServiceAccountGetRequest(_messages.Message):
+  """A StorageProjectsServiceAccountGetRequest object.
+
+  Fields:
+    projectId: Project ID
+    userProject: The project to be billed for this request, for Requester Pays
+      buckets.
+  """
+
+  projectId = _messages.StringField(1, required=True)
+  userProject = _messages.StringField(2)
 
 
 class TestIamPermissionsResponse(_messages.Message):
   """A storage.(buckets|objects).testIamPermissions response.
+
   Fields:
     kind: The kind of item this is.
     permissions: The permissions held by the caller. Permissions are always of
@@ -2291,7 +2566,7 @@ class TestIamPermissionsResponse(_messages.Message):
       storage.buckets.delete \u2014 Delete bucket.   - storage.buckets.get \u2014 Read
       bucket metadata.   - storage.buckets.getIamPolicy \u2014 Read bucket IAM
       policy.   - storage.buckets.create \u2014 Create bucket.   -
-     storage.buckets.list \u2014 List buckets.   - storage.buckets.setIamPolicy \u2014
+      storage.buckets.list \u2014 List buckets.   - storage.buckets.setIamPolicy \u2014
       Update bucket IAM policy.   - storage.buckets.update \u2014 Update bucket
       metadata.   - storage.objects.delete \u2014 Delete object.   -
       storage.objects.get \u2014 Read object data and metadata.   -
@@ -2305,13 +2580,3 @@ class TestIamPermissionsResponse(_messages.Message):
   permissions = _messages.StringField(2, repeated=True)
 
 
-class StorageProjectsServiceAccountGetRequest(_messages.Message):
-  """A StorageProjectsServiceAccountGetRequest object.
-
-  Fields:
-    projectId: Project ID
-  """
-
-  projectId = _messages.StringField(1, required=True)
-
-
diff --git a/gslib/translation_helper.py b/gslib/translation_helper.py
index 2c2a5a8..2a4660f 100644
--- a/gslib/translation_helper.py
+++ b/gslib/translation_helper.py
@@ -21,6 +21,7 @@ import json
 import re
 import textwrap
 import xml.etree.ElementTree
+from xml.etree.ElementTree import ParseError as XmlParseError
 
 from apitools.base.py import encoding
 import boto
@@ -44,13 +45,6 @@ from gslib.cloud_api import Preconditions
 from gslib.exception import CommandException
 from gslib.third_party.storage_apitools import storage_v1_messages as apitools_messages
 
-# In Python 2.6, ElementTree raises ExpatError instead of ParseError.
-# pylint: disable=g-import-not-at-top
-try:
-  from xml.etree.ElementTree import ParseError as XmlParseError
-except ImportError:
-  from xml.parsers.expat import ExpatError as XmlParseError
-
 CACHE_CONTROL_REGEX = re.compile(r'^cache-control', re.I)
 CONTENT_DISPOSITION_REGEX = re.compile(r'^content-disposition', re.I)
 CONTENT_ENCODING_REGEX = re.compile(r'^content-encoding', re.I)
@@ -635,20 +629,30 @@ class CorsTranslation(object):
     Args:
       json_cors: JSON string representing CORS configuration.
 
+    Raises:
+      ArgumentException on invalid CORS JSON data.
+
     Returns:
       List of apitools Bucket.CorsValueListEntry. An empty list represents
       no CORS configuration.
     """
+    deserialized_cors = None
     try:
       deserialized_cors = json.loads(json_cors)
-      cors = []
-      for cors_entry in deserialized_cors:
-        cors.append(encoding.DictToMessage(
-            cors_entry, apitools_messages.Bucket.CorsValueListEntry))
-      return cors
     except ValueError:
       CheckForXmlConfigurationAndRaise('CORS', json_cors)
 
+    if not isinstance(deserialized_cors, list):
+      raise ArgumentException(
+          'CORS JSON should be formatted as a list containing one or more JSON '
+          'objects.\nSee "gsutil help cors".')
+
+    cors = []
+    for cors_entry in deserialized_cors:
+      cors.append(encoding.DictToMessage(
+          cors_entry, apitools_messages.Bucket.CorsValueListEntry))
+    return cors
+
   @classmethod
   def MessageEntriesToJson(cls, cors_message):
     """Translates an apitools message to CORS JSON."""
diff --git a/gslib/util.py b/gslib/util.py
index 7011e87..4749de4 100644
--- a/gslib/util.py
+++ b/gslib/util.py
@@ -34,6 +34,7 @@ import textwrap
 import threading
 import time
 import traceback
+import urlparse
 import xml.etree.ElementTree as ElementTree
 
 from apitools.base.py import http_wrapper
@@ -783,13 +784,16 @@ def GetNewHttp(http_class=httplib2.Http, **kwargs):
   Returns:
     An initialized httplib2.Http instance.
   """
+  proxy_host = boto.config.get('Boto', 'proxy', None)
   proxy_info = httplib2.ProxyInfo(
       proxy_type=3,
-      proxy_host=boto.config.get('Boto', 'proxy', None),
+      proxy_host=proxy_host,
       proxy_port=boto.config.getint('Boto', 'proxy_port', 0),
       proxy_user=boto.config.get('Boto', 'proxy_user', None),
       proxy_pass=boto.config.get('Boto', 'proxy_pass', None),
-      proxy_rdns=boto.config.get('Boto', 'proxy_rdns', False))
+      proxy_rdns=boto.config.get('Boto',
+                                 'proxy_rdns',
+                                 True if proxy_host else False))
 
   if not (proxy_info.proxy_host and proxy_info.proxy_port):
     # Fall back to using the environment variable.
@@ -1738,24 +1742,6 @@ def LogAndHandleRetries(is_data_transfer=False, status_queue=None):
   return WarnAfterManyRetriesHandler
 
 
-class GsutilStreamHandler(logging.StreamHandler):
-  """A subclass of StreamHandler for use in gsutil."""
-
-  def flush(self):
-    # Note: we override the flush method here due to a python 2.6 bug. The
-    # python logging module will try to flush all stream handlers at exit.
-    # If the StreamHandler is pointing to a file that is already closed, the
-    # method throws an exception. Our unit tests temporarily redirect stderr,
-    # which causes the default StreamHandler to open its stream against a
-    # temporary file. By the time the process shuts down, the underlying file
-    # is closed, causing an exception. This was fixed in Python 2.7, but to
-    # remove the flake from Python 2.6, we maintain this here.
-    try:
-      logging.StreamHandler.flush(self)
-    except ValueError:
-      pass
-
-
 def StdinIterator():
   """A generator function that returns lines from stdin."""
   for line in sys.stdin:
@@ -1796,6 +1782,49 @@ def NormalizeStorageClass(sc):
   return sc
 
 
+def AddQueryParamToUrl(url_str, param_name, param_value):
+  """Adds a query parameter to a URL string.
+
+  Appends a query parameter to the query string portion of a url. If a parameter
+  with the given name was already present, it is not removed; the new name/value
+  pair will be appended to the end of the query string. It is assumed that all
+  arguments will be of type `str` (either ASCII or UTF-8 encoded) or `unicode`.
+
+  Note that this method performs no URL-encoding. It is the caller's
+  responsibility to ensure proper URL encoding of the entire URL; i.e. if the
+  URL is already URL-encoded, you should pass in URL-encoded values for
+  param_name and param_value. If the URL is not URL-encoded, you should not pass
+  in URL-encoded parameters; instead, you could perform URL-encoding using the
+  URL string returned from this function.
+
+  Args:
+    url_str: String representing the URL.
+    param_name: String key of the query parameter.
+    param_value: String value of the query parameter.
+
+  Returns:
+    A string representing the modified url, of type `unicode` if the url_str
+    argument was a `unicode`, otherwise a `str` encoded in UTF-8.
+  """
+  url_was_unicode = isinstance(url_str, unicode)
+  if isinstance(url_str, unicode):
+    url_str = url_str.encode('utf-8')
+  if isinstance(param_name, unicode):
+    param_name = param_name.encode('utf-8')
+  if isinstance(param_value, unicode):
+    param_value = param_value.encode('utf-8')
+  scheme, netloc, path, query_str, fragment = urlparse.urlsplit(url_str)
+
+  query_params = urlparse.parse_qsl(query_str, keep_blank_values=True)
+  query_params.append((param_name, param_value))
+  new_query_str = '&'.join(['%s=%s' % (k, v) for (k, v) in query_params])
+
+  new_url = urlparse.urlunsplit((scheme, netloc, path, new_query_str, fragment))
+  if url_was_unicode:
+    new_url = new_url.decode('utf-8')
+  return new_url
+
+
 class RsyncDiffToApply(object):
   """Class that encapsulates info needed to apply diff for one object."""
 
diff --git a/setup.py b/setup.py
index 5561de3..475e66f 100755
--- a/setup.py
+++ b/setup.py
@@ -36,11 +36,11 @@ management tasks, including:
 
 requires = [
     'argcomplete>=1.8.2',
-    'boto==2.47.0',
+    'boto==2.48.0',
     'crcmod>=1.7',
     'gcs-oauth2-boto-plugin>=1.14',
-    'google-apitools==0.5.3',
-    'httplib2>=0.8',
+    'google-apitools==0.5.16',
+    'httplib2>=0.10.3',
     # TODO: Sync submodule with tag referenced here once #339 is fixed in mock.
     'mock==2.0.0',
     'oauth2client==2.2.0',
@@ -57,7 +57,7 @@ dependency_links = [
     # Note: this commit ID should be kept in sync with the 'third_party/boto'
     # entry in 'git submodule status'.
     # pylint: disable=line-too-long
-    'https://github.com/boto/boto/archive/af045f93d70fbb4cdac2a8e57d040ce59935d45b.tar.gz#egg=boto-2.47.0',
+    'https://github.com/boto/boto/archive/6c5b98861d726fdd5e05702972b14692e73e84f4.tar.gz#egg=boto-2.48.0',
     # pylint: enable=line-too-long
 ]
 
